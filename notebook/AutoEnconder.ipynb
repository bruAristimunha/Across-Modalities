{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abordagem Inicial \n",
    "\n",
    "## Objetivo \n",
    "\n",
    "### Propor método para:\n",
    "* encontrar representações comuns de diferentes modalidades sensoriais\n",
    "* aumentar a quantidade de dados utilizados para redução de dimensionalidade do sinal\n",
    "* melhorar a sensibilidade de análises MVPA posteriores \n",
    "\n",
    "### Inicialmente codificar cada instante de tempo (sem usar janelas no tempo)\n",
    "### Decodificar o momento que estava na mesma e na outra modalidade a partir do estado reduzido\n",
    "* Comparar com decodificação usando: (1) Sinais originais, (2) PCA geral, (3) PCA em cada ponto, (4) Auto-encoder\n",
    "### Ver sobre use da auto-encoders e VAEs\n",
    "### Checar sobre predição da reprodução do intervalo temporal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_FOLDER = '../data/processed/' "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "aud_1 =  pd.read_csv(PATH_FOLDER+'auditory_exposure_1_autoenconder.csv')\n",
    "aud_2 =  pd.read_csv(PATH_FOLDER+'auditory_exposure_2_autoenconder.csv') \n",
    "vis_1 =  pd.read_csv(PATH_FOLDER+'visual_exposure_1_autoenconder.csv') \n",
    "vis_2 =  pd.read_csv(PATH_FOLDER+'visual_exposure_2_autoenconder.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "aud_1 =  pd.read_csv(PATH_FOLDER+'auditory_exposure_1.csv')\n",
    "aud_2 =  pd.read_csv(PATH_FOLDER+'auditory_exposure_2.csv') \n",
    "vis_1 =  pd.read_csv(PATH_FOLDER+'visual_exposure_1.csv') \n",
    "vis_2 =  pd.read_csv(PATH_FOLDER+'visual_exposure_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passo 1: treinar com dados completos capturados do experimento\n",
    "* Entrada e saída como o mesmo sinal (um número para cada eletrodo)\n",
    "* Usar uma rede fully connected e auto-encoder padrão\n",
    "    * 64(E) - 32 - 16 - 8 - 16 - 32 - 64(S)\n",
    "    * Fazer testes verificando o erro de reconstrução\n",
    "* Uma rede por voluntário e por modalidade\n",
    "* Pouca quantidade de dados -> incluir regularização, como dropout, para evitar overfitting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Por voluntário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src/models\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_autoenconder import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brain/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/ipykernel_launcher.py:1: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "from tqdm.autonotebook import tqdm\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import LeaveOneOut\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_autoEncoder(dataFrame, categoria, exposure):\n",
    "    '''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    '''\n",
    "\n",
    "    dataFrame_result = []\n",
    "    history = []\n",
    "    loo = LeaveOneOut()\n",
    "\n",
    "    pbar = tqdm(total=loo.get_n_splits(dataFrame))\n",
    "\n",
    "    for ind, pearson in dataFrame.groupby('people'):\n",
    "\n",
    "        X = pearson.drop(['trial', 'group', 'people'], 1)\n",
    "        y = pearson['group']\n",
    "\n",
    "        loo = LeaveOneOut()\n",
    "\n",
    "        for train_index, test_index in loo.split(X):\n",
    "\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "            # Normalize\n",
    "\n",
    "            train_mean = np.average(X_train, axis=0)\n",
    "\n",
    "            X_train_without_mean = np.subtract(X_train, train_mean)\n",
    "            X_test_without_mean = np.subtract(X_test, train_mean)\n",
    "\n",
    "            X_train_without_mean = X_train_without_mean.T\n",
    "            X_test_without_mean = X_test_without_mean.T\n",
    "\n",
    "            clf = GaussianNB()\n",
    "\n",
    "            autoEncoder_ = my_autoenconder(epochs=10,\n",
    "                                           batch_size=32,\n",
    "                                           validation_size=0.2,\n",
    "                                           random_state=42,\n",
    "                                           regularizer=regularizers.l1(10e-5),\n",
    "                                           exposure=exposure,\n",
    "                                           modality=categoria)\n",
    "\n",
    "            autoEncoder_.make_auto_enconder(8)\n",
    "\n",
    "            autoEncoder_.fCohen_Kappahout_mean)\n",
    "\n",
    "            X_train_auto = autoEncoder_.transform(X_train_without_mean.T)\n",
    "\n",
    "            X_test_auto = autoEncoder_.transform(X_test_without_mean.T)\n",
    "\n",
    "\n",
    "            clf = clf.fit(X_train_auto, y_train)\n",
    "\n",
    "            y_pred = clf.predict(X_test_auto)\n",
    "\n",
    "            dataFrame_result.append([ind,y_pred,y_test.values,categoria,exposure])\n",
    "\n",
    "            pbar.update(1)\n",
    "            \n",
    "    return dataFrame_result\n",
    "    #, autoEncoder_.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO... paralelizar..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d43adbf8fa844c65a154023047f8d264",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2400.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'to_csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-285a5348767b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mresu_aud_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification_autoEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maud_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Auditory'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'E1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresu_aud_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/processed/auto_encoder_resu_aud_1.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'to_csv'"
     ]
    }
   ],
   "source": [
    "resu_aud_1 = classification_autoEncoder(aud_1,'Auditory','E1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "resu_aud_1 = pd.DataFrame(\n",
    "    resu_aud_1, columns=['People', 'Predict', 'Real', 'Modality', 'Exposure'])\n",
    "resu_aud_1['Predict'] = resu_aud_1['Predict'].astype(int)\n",
    "resu_aud_1['Real'] = resu_aud_1['Real'].astype(int)\n",
    "resu_aud_1.to_csv(\"../data/processed/auto_encoder_resu_aud_1.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "921075cffd2247fea1dbf2d236573d96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2400.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resu_aud_2 = classification_autoEncoder(aud_2,'Auditory','E2')\n",
    "\n",
    "resu_aud_2 = pd.DataFrame(\n",
    "    resu_aud_2, columns=['People', 'Predict', 'Real', 'Modality', 'Exposure'])\n",
    "resu_aud_2['Predict'] = resu_aud_2['Predict'].astype(int)\n",
    "resu_aud_2['Real'] = resu_aud_2['Real'].astype(int)\n",
    "\n",
    "resu_aud_2.to_csv(\"../data/processed/auto_encoder_resu_aud_2.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2de8b0bbc654ec0b17d210194982346",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2400.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resu_vis_1 = classification_autoEncoder(vis_1,'Visual','E1')\n",
    "\n",
    "resu_vis_1 = pd.DataFrame(\n",
    "    resu_vis_1, columns=['People', 'Predict', 'Real', 'Modality', 'Exposure'])\n",
    "resu_vis_1['Predict'] = resu_vis_1['Predict'].astype(int)\n",
    "resu_vis_1['Real'] = resu_vis_1['Real'].astype(int)\n",
    "\n",
    "resu_vis_1.to_csv(\"../data/processed/auto_encoder_resu_vis_1.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a2374a940c54793ae4331c6f224d8f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2400.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resu_vis_2 = classification_autoEncoder(vis_2,'Visual','E2')\n",
    "\n",
    "resu_vis_2 = pd.DataFrame(\n",
    "    resu_vis_2, columns=['People', 'Predict', 'Real', 'Modality', 'Exposure'])\n",
    "resu_vis_2['Predict'] = resu_vis_2['Predict'].astype(int)\n",
    "resu_vis_2['Real'] = resu_vis_2['Real'].astype(int)\n",
    "\n",
    "resu_vis_2.to_csv(\"../data/processed/auto_encoder_resu_vis_2.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotar = pd.DataFrame(np.concatenate([resu_aud_1,resu_aud_2,resu_vis_1, resu_vis_2]))\n",
    "\n",
    "plotar['Predicted Bin'] = plotar['Predicted Bin'].astype(int)\n",
    "plotar['Real Bin'] = plotar['Real Bin'].astype(int)\n",
    "\n",
    "plotar.columns = ['Id_people','Predicted Bin','Real Bin','Modality','Exposures']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotar = pd.read_csv('../data/processed/auto_encoder_resu_vis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotar_mode = plotar.groupby(['Id_people', 'Modality', 'Exposures', 'Real Bin'])[\n",
    "    'Predicted Bin'].apply(lambda x: sc.stats.mode(x)[0]).reset_index()\n",
    "\n",
    "plotar_mode['Predicted Bin'] = plotar_mode['Predicted Bin'].astype(int)\n",
    "\n",
    "plotar_mode.to_csv('../data/processed/auto_encoder_resu_vis_mode.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classificação nos Dados Visual, exposição 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.23      0.18      0.20       499\n",
      "           2       0.17      0.18      0.18       414\n",
      "           3       0.17      0.15      0.16       429\n",
      "           4       0.14      0.17      0.15       359\n",
      "           5       0.14      0.14      0.14       358\n",
      "           6       0.17      0.21      0.19       341\n",
      "\n",
      "    accuracy                           0.17      2400\n",
      "   macro avg       0.17      0.17      0.17      2400\n",
      "weighted avg       0.18      0.17      0.17      2400\n",
      "\n",
      "Classificação nos Dados Visual, exposição 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.21      0.18      0.19       452\n",
      "           2       0.19      0.20      0.20       425\n",
      "           3       0.20      0.18      0.19       439\n",
      "           4       0.16      0.20      0.18       345\n",
      "           5       0.16      0.14      0.15       387\n",
      "           6       0.17      0.20      0.18       352\n",
      "\n",
      "    accuracy                           0.18      2400\n",
      "   macro avg       0.18      0.18      0.18      2400\n",
      "weighted avg       0.18      0.18      0.18      2400\n",
      "\n",
      "Classificação nos Dados Auditivo, exposição 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.19      0.15      0.17       461\n",
      "           2       0.18      0.18      0.18       417\n",
      "           3       0.18      0.14      0.16       464\n",
      "           4       0.15      0.16      0.15       382\n",
      "           5       0.16      0.14      0.15       417\n",
      "           6       0.11      0.18      0.13       259\n",
      "\n",
      "    accuracy                           0.16      2400\n",
      "   macro avg       0.16      0.16      0.16      2400\n",
      "weighted avg       0.16      0.16      0.16      2400\n",
      "\n",
      "Classificação nos Dados Auditivo, exposição 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.21      0.16      0.18       501\n",
      "           2       0.22      0.20      0.21       483\n",
      "           3       0.17      0.16      0.16       411\n",
      "           4       0.13      0.16      0.14       330\n",
      "           5       0.17      0.17      0.17       364\n",
      "           6       0.14      0.19      0.16       311\n",
      "\n",
      "    accuracy                           0.17      2400\n",
      "   macro avg       0.17      0.17      0.17      2400\n",
      "weighted avg       0.18      0.17      0.17      2400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exposicao1 = plotar[plotar['Exposures']=='E1']\n",
    "\n",
    "exposicao1_aud = exposicao1[exposicao1['Modality']=='Auditory']\n",
    "exposicao1_vis = exposicao1[exposicao1['Modality']=='Visual']\n",
    "\n",
    "exposicao2 = plotar[plotar['Exposures']=='E2']\n",
    "\n",
    "exposicao2_aud = exposicao2[exposicao2['Modality']=='Auditory']\n",
    "exposicao2_vis = exposicao2[exposicao2['Modality']=='Visual']\n",
    "\n",
    "\n",
    "print(\"Classificação nos Dados Visual, exposição 1\")\n",
    "\n",
    "y_test = exposicao1_vis['Predicted Bin'].values\n",
    "y_pred = exposicao1_vis['Real Bin'].values\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Classificação nos Dados Visual, exposição 2\")\n",
    "\n",
    "y_test = exposicao2_vis['Predicted Bin'].values\n",
    "y_pred = exposicao2_vis['Real Bin'].values\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Classificação nos Dados Auditivo, exposição 1\")\n",
    "y_test = exposicao1_aud['Predicted Bin'].values\n",
    "y_pred = exposicao1_aud['Real Bin'].values\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Classificação nos Dados Auditivo, exposição 2\")\n",
    "y_test = exposicao2_aud['Predicted Bin'].values\n",
    "y_pred = exposicao2_aud['Real Bin'].values\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading required package: lattice\n",
      "Loading required package: plyr\n",
      "null device \n",
      "          1 \n"
     ]
    }
   ],
   "source": [
    "! Rscript --vanilla ../src/visualization/Figure5.r auto_encoder_resu_vis_mode.csv auto_encoder_resu_vis_mode.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Figure 2](../reports/figures/auto_encoder_resu_vis_mode.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Passo 2: gerar uma representação comum entre ambas as modalidades\n",
    "* Treinar com a mesma rede para visual e auditivo\n",
    "* Objetivo é verificar se gera uma melhor representação comum entre as modalidades\n",
    "* Comparar o desempenho com a rede treinada em apenas uma modalidade\n",
    "* Treinar redes separadas para visual e auditivo, compartilhando a parte da codificação\n",
    "* Treinamento com exemplos de ambas as modalidades\n",
    "* Pode ser mais interessante, pois enfatiza uma codificação comum, mas permite diferenciações na decodificação\n",
    "\n",
    "### Passo 3: obter representações comuns entre sujeitos\n",
    "* Treinar a mesma rede para todos os participantes \n",
    "* Objetivo é gerar as codificações a partir de grandes quantidades de dados\n",
    "* Abordagem 1: Fazer para a rede uma rede codificação/decodificação comum a todos\n",
    "    * Depois pode ser afinada para cada participante individualmente\n",
    "* Abordagem 2: Usar apenas a parte de codificação em comum\n",
    "    * Enfatiza uma codificação comum, mas permite diferenciações na decodificação\n",
    "* Neste caso o classificador poderia ser comum também?\n",
    "\n",
    "Passo 4: capturar informação temporal (opcional)\n",
    "Repetir os passos anteriores, mas usando 5 valores para cada eletrodo (1 a cada 25 ms)\n",
    "Objetivo é verificar se mais detalhes temporais melhoram a representação do tempo\n",
    "Inicialmente utilizar uma arquitetura fully connected \n",
    "320(E) - 160 - 80 - 40 - 80 - 160 - 320(S)\n",
    "Outra possibilidade é colocar alguma estrutura\n",
    "Transformação é inicialmente realizada sobre a série temporal de cada eletrodo\n",
    "Poderia também juntar sinais de eletrodos vizinhos\n",
    "Isso permitiria diminuir o número de conexões"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "resu_aud_2 = classification(df_aud_2_aver,'Auditory','E2')\n",
    "\n",
    "resu_vis_1 = classification(df_vis_1_aver,'Visual','E1')\n",
    "resu_vis_2 = classification(df_vis_2_aver,'Visual','E2')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
