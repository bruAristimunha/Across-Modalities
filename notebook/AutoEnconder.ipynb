{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abordagem Inicial \n",
    "\n",
    "## Objetivo \n",
    "\n",
    "### Propor método para:\n",
    "* encontrar representações comuns de diferentes modalidades sensoriais\n",
    "* aumentar a quantidade de dados utilizados para redução de dimensionalidade do sinal\n",
    "* melhorar a sensibilidade de análises MVPA posteriores \n",
    "\n",
    "### Inicialmente codificar cada instante de tempo (sem usar janelas no tempo)\n",
    "### Decodificar o momento que estava na mesma e na outra modalidade a partir do estado reduzido\n",
    "* Comparar com decodificação usando: (1) Sinais originais, (2) PCA geral, (3) PCA em cada ponto, (4) Auto-encoder\n",
    "### Ver sobre use da auto-encoders e VAEs\n",
    "### Checar sobre predição da reprodução do intervalo temporal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_FOLDER = '../data/processed/' "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "aud_1 =  pd.read_csv(PATH_FOLDER+'auditory_exposure_1_autoenconder.csv')\n",
    "aud_2 =  pd.read_csv(PATH_FOLDER+'auditory_exposure_2_autoenconder.csv') \n",
    "vis_1 =  pd.read_csv(PATH_FOLDER+'visual_exposure_1_autoenconder.csv') \n",
    "vis_2 =  pd.read_csv(PATH_FOLDER+'visual_exposure_2_autoenconder.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "aud_1 =  pd.read_csv(PATH_FOLDER+'auditory_exposure_1.csv')\n",
    "aud_2 =  pd.read_csv(PATH_FOLDER+'auditory_exposure_2.csv') \n",
    "vis_1 =  pd.read_csv(PATH_FOLDER+'visual_exposure_1.csv') \n",
    "vis_2 =  pd.read_csv(PATH_FOLDER+'visual_exposure_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passo 1: treinar com dados completos capturados do experimento\n",
    "* Entrada e saída como o mesmo sinal (um número para cada eletrodo)\n",
    "* Usar uma rede fully connected e auto-encoder padrão\n",
    "    * 64(E) - 32 - 16 - 8 - 16 - 32 - 64(S)\n",
    "    * Fazer testes verificando o erro de reconstrução\n",
    "* Uma rede por voluntário e por modalidade\n",
    "* Pouca quantidade de dados -> incluir regularização, como dropout, para evitar overfitting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Por voluntário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src/models\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_autoenconder import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brain/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/ipykernel_launcher.py:1: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "from tqdm.autonotebook import tqdm\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import LeaveOneOut\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_autoEncoder(dataFrame, categoria, exposure):\n",
    "    '''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    '''\n",
    "\n",
    "    dataFrame_result = []\n",
    "    history = []\n",
    "    loo = LeaveOneOut()\n",
    "\n",
    "    pbar = tqdm(total=loo.get_n_splits(dataFrame))\n",
    "\n",
    "    for ind, pearson in dataFrame.groupby('people'):\n",
    "\n",
    "        X = pearson.drop(['trial', 'group', 'people'], 1)\n",
    "        y = pearson['group']\n",
    "\n",
    "        loo = LeaveOneOut()\n",
    "\n",
    "        for train_index, test_index in loo.split(X):\n",
    "\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "            # Normalize\n",
    "\n",
    "            train_mean = np.average(X_train, axis=0)\n",
    "\n",
    "            X_train_without_mean = np.subtract(X_train, train_mean)\n",
    "            X_test_without_mean = np.subtract(X_test, train_mean)\n",
    "\n",
    "            X_train_without_mean = X_train_without_mean.T\n",
    "            X_test_without_mean = X_test_without_mean.T\n",
    "\n",
    "            clf = GaussianNB()\n",
    "\n",
    "            autoEncoder_ = my_autoenconder(epochs=10,\n",
    "                                           batch_size=32,\n",
    "                                           validation_size=0.2,\n",
    "                                           random_state=42,\n",
    "                                           regularizer=regularizers.l1(10e-5),\n",
    "                                           exposure=exposure,\n",
    "                                           modality=categoria)\n",
    "\n",
    "            autoEncoder_.make_auto_enconder(8)\n",
    "\n",
    "            autoEncoder_.fit(X_train_without_mean)\n",
    "\n",
    "            X_train_auto = autoEncoder_.transform(X_train_without_mean.T)\n",
    "\n",
    "            X_test_auto = autoEncoder_.transform(X_test_without_mean.T)\n",
    "\n",
    "\n",
    "            clf = clf.fit(X_train_auto, y_train)\n",
    "\n",
    "            y_pred = clf.predict(X_test_auto)\n",
    "\n",
    "            dataFrame_result.append([ind,y_pred,y_test.values,categoria,exposure])\n",
    "\n",
    "            pbar.update(1)\n",
    "            \n",
    "    return dataFrame_result\n",
    "    #, autoEncoder_.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO... paralelizar..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3a20dbc15ef408d87691fda07589983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2400.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resu_aud_1 = classification_autoEncoder(aud_1,'Auditory','E1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotar = pd.DataFrame(resu_aud_1)\n",
    "plotar[0] = plotar[0].astype(int)\n",
    "plotar[1] = plotar[1].astype(int)\n",
    "plotar[2] = plotar[2].astype(int)\n",
    "\n",
    "plotar.columns = ['Id_people','Predicted Bin','Real Bin','Modality','Exposures']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classificação nos Dados Visual, exposição 1\")\n",
    "\n",
    "y_test = plotar['Predicted Bin'].values\n",
    "y_pred = plotar['Real Bin'].values\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Passo 2: gerar uma representação comum entre ambas as modalidades\n",
    "* Treinar com a mesma rede para visual e auditivo\n",
    "* Objetivo é verificar se gera uma melhor representação comum entre as modalidades\n",
    "* Comparar o desempenho com a rede treinada em apenas uma modalidade\n",
    "* Treinar redes separadas para visual e auditivo, compartilhando a parte da codificação\n",
    "* Treinamento com exemplos de ambas as modalidades\n",
    "* Pode ser mais interessante, pois enfatiza uma codificação comum, mas permite diferenciações na decodificação\n",
    "\n",
    "### Passo 3: obter representações comuns entre sujeitos\n",
    "* Treinar a mesma rede para todos os participantes \n",
    "* Objetivo é gerar as codificações a partir de grandes quantidades de dados\n",
    "* Abordagem 1: Fazer para a rede uma rede codificação/decodificação comum a todos\n",
    "    * Depois pode ser afinada para cada participante individualmente\n",
    "* Abordagem 2: Usar apenas a parte de codificação em comum\n",
    "    * Enfatiza uma codificação comum, mas permite diferenciações na decodificação\n",
    "* Neste caso o classificador poderia ser comum também?\n",
    "\n",
    "Passo 4: capturar informação temporal (opcional)\n",
    "Repetir os passos anteriores, mas usando 5 valores para cada eletrodo (1 a cada 25 ms)\n",
    "Objetivo é verificar se mais detalhes temporais melhoram a representação do tempo\n",
    "Inicialmente utilizar uma arquitetura fully connected \n",
    "320(E) - 160 - 80 - 40 - 80 - 160 - 320(S)\n",
    "Outra possibilidade é colocar alguma estrutura\n",
    "Transformação é inicialmente realizada sobre a série temporal de cada eletrodo\n",
    "Poderia também juntar sinais de eletrodos vizinhos\n",
    "Isso permitiria diminuir o número de conexões"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "resu_aud_2 = classification(df_aud_2_aver,'Auditory','E2')\n",
    "\n",
    "resu_vis_1 = classification(df_vis_1_aver,'Visual','E1')\n",
    "resu_vis_2 = classification(df_vis_2_aver,'Visual','E2')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
