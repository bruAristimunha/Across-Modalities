{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abordagem Inicial \n",
    "\n",
    "## Objetivo \n",
    "\n",
    "### Propor método para:\n",
    "* encontrar representações comuns de diferentes modalidades sensoriais\n",
    "* aumentar a quantidade de dados utilizados para redução de dimensionalidade do sinal\n",
    "* melhorar a sensibilidade de análises MVPA posteriores \n",
    "\n",
    "### Inicialmente codificar cada instante de tempo (sem usar janelas no tempo)\n",
    "### Decodificar o momento que estava na mesma e na outra modalidade a partir do estado reduzido\n",
    "* Comparar com decodificação usando: (1) Sinais originais, (2) PCA geral, (3) PCA em cada ponto, (4) Auto-encoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importações necessárias para execução desse notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns; sns.set()\n",
    "import sys\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "sys.path.append(\"../src/data\")\n",
    "from myMNE import makeMNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando dados auditivos e visuais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_AUD = '../data/raw/aud'\n",
    "PATH_VIS = '../data/raw/vis'\n",
    "\n",
    "PATH_INFO = '../data/raw/info_'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções auxiliares para leitura do arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def files_in_path(path):\n",
    "    return [path+\"/\"+f for f in listdir(path) if isfile(join(path, f))]\n",
    "\n",
    "# Getting data from MNE strutuct\n",
    "\n",
    "\n",
    "def data_from_mne(files):\n",
    "    return np.array([file.get_data().T for file in files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of Files contained in the folder with path\n",
    "\n",
    "path_file_aud = files_in_path(PATH_AUD)\n",
    "path_file_vis = files_in_path(PATH_VIS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading files with the MNE library\n",
    "\n",
    "files_aud = list(map(makeMNE, path_file_aud))\n",
    "files_vis = list(map(makeMNE, path_file_vis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting data in numpy format\n",
    "\n",
    "data_aud = data_from_mne(files_aud)\n",
    "data_vis = data_from_mne(files_vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the shape in arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data Aud with shape: {} (individual, raw, channels, trial)\".format(data_aud.shape))\n",
    "print(\"Data Vis with shape: {} (individual, raw, channels, trial)\".format(data_vis.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to exposure separation:\n",
    "# by definition in trial odd are the first exposure, and trial even the second exposure\n",
    "\n",
    "def _exposure_1(data): \n",
    "    # [individual, raw, channels, trial]\n",
    "    return data[::, ::, ::, 0:: 2]\n",
    "\n",
    "def _exposure_2(data): \n",
    "    # [individual, raw, channels, trial]\n",
    "    return data[::, ::, ::, 1:: 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Splitting the exposures for all the individuals\n",
    "\n",
    "aud_expo_1 = _exposure_1(data_aud)\n",
    "\n",
    "aud_expo_2 = _exposure_2(data_aud) \n",
    "\n",
    "vis_expo_1 = _exposure_1(data_vis)\n",
    "\n",
    "vis_expo_2 = _exposure_2(data_vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary function to calculate the average in the bin\n",
    "\n",
    "\n",
    "def _average(frame):\n",
    "    return np.average(frame, axis=0)\n",
    "\n",
    "\n",
    "# Function for splitting and compute the average in the bins\n",
    "def six_bin_first(exposure):\n",
    "    \"\"\"Splitting array in bins for the first exposure,\n",
    "    and compute the average\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    exposure: numpy.array (3-dimensions) [raw, channels, trial]\n",
    "       Array containing data from an exposure.\n",
    "    Returns\n",
    "    -------\n",
    "    average_frames: list of numpy.array\n",
    "        average of 6 arrays with 31 points each\n",
    "    \"\"\"\n",
    "    # Indices\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "\n",
    "    # If the zero is not at the starting point just change the value.\n",
    "    zero = 0\n",
    "\n",
    "    # End in 1500 ms\n",
    "    end = 1500//4 + zero\n",
    "\n",
    "    # 6 bins with 31 points from 250 Hz\n",
    "\n",
    "    size = 744 // 4\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    time_frame = exposure[end-size:end]\n",
    "\n",
    "    frames = np.split(time_frame, 6)\n",
    "\n",
    "    average_frames = np.array(list(map(_average, frames)))\n",
    "\n",
    "    return average_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for splitting and compute the average in the bins, for the second bins\n",
    "def six_bin_second(exposure, indice_exposure):\n",
    "    \"\"\"Splitting array in bins for the first exposure,\n",
    "    and compute the average\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    exposure: numpy.array (3-dimensions) [raw, channels, trial]\n",
    "       Array containing data from an exposure.\n",
    "    Returns\n",
    "    -------\n",
    "    average_frames: list of numpy.array\n",
    "        Average of 6 arrays with 31 points each\n",
    "    \"\"\"\n",
    "    # Indices\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "\n",
    "    # Indice moment of exposure, subtracting 124 milliseconds (31 points)\n",
    "    #import pdb; pdb.set_trace()\n",
    "    begin = indice_exposure - 31\n",
    "\n",
    "    # 6 bins with 31 points from 250 Hz\n",
    "\n",
    "    size = 744 // 4\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    time_frame = exposure[begin:begin+size]\n",
    "\n",
    "    frames = np.split(time_frame, 6)\n",
    "\n",
    "    average_frames = np.array(list(map(_average, frames)))\n",
    "\n",
    "    return average_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "\n",
    "\n",
    "def indice_time_delay(name: str):\n",
    "\n",
    "    info_path = PATH_INFO+name\n",
    "\n",
    "    infos = list(map(sio.loadmat, files_in_path(info_path)))\n",
    "\n",
    "    time_delay = infos[0]['report']['all_trials_delay'][0][0][0]\n",
    "\n",
    "    return ((np.around((time_delay*250), decimals=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indice_vis_expo = indice_time_delay('vis').astype('int')\n",
    "indice_aud_expo = indice_time_delay('aud').astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average in the bins\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aud_expo_1_frames = list(map(six_bin_first, aud_expo_1))\n",
    "vis_expo_1_frames = list(map(six_bin_first, vis_expo_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aud_expo_2_frames = list(map(six_bin_second, aud_expo_2, indice_vis_expo))\n",
    "vis_expo_2_frames = list(map(six_bin_second, vis_expo_2, indice_aud_expo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Com isso, iremos para o próximo passo, que consiste de aplicar o PCA para reduzir as dimensões redudantes presentes nos múltiplos canais.\n",
    "\n",
    "Não realizamos nesse momento a separação do conjunto treino-teste, seguindo o autor original."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![aquisicao](https://raw.githubusercontent.com/bruAristimunha/Across-Modalities/master/reports/figures/mapa_rapha.jpg)\n",
    "#### Figura 01: Diagrama de Reunião de Orientação. O ponto de interesse está na tabela para aplicação do PCA. Segundo os autores, eles empregaram em média 32 componentes +- 1\n",
    "\n",
    "\n",
    "------------------------------------\n",
    "\n",
    "# Studying of the number of components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myPCA(data: np.array, return_data=False, n_components=0.99):\n",
    "\n",
    "    pca_ = PCA(random_state=42, svd_solver='full', n_components=n_components)\n",
    "    \n",
    "    data = data.T\n",
    "\n",
    "    data_ft = pca_.fit_transform(data)\n",
    "\n",
    "    if(return_data):\n",
    "        return data_ft\n",
    "    else:\n",
    "        return pca_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myPCA_method(data): \n",
    "    return myPCA(data, return_data=False)\n",
    "def myPCA_data(data): \n",
    "    return myPCA(data, return_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcas = []\n",
    "\n",
    "for person in aud_expo_1_frames:\n",
    "    method_pca = list(map(myPCA_method,person))\n",
    "    pcas.append(method_pca)\n",
    "    \n",
    "for person in vis_expo_1_frames:\n",
    "    method_pca = list(map(myPCA_method,person))\n",
    "    pcas.append(method_pca)\n",
    "    \n",
    "for person in aud_expo_2_frames:\n",
    "    method_pca = list(map(myPCA_method,person))\n",
    "    pcas.append(method_pca)\n",
    "    \n",
    "for person in vis_expo_2_frames:\n",
    "    method_pca = list(map(myPCA_method,person))\n",
    "    pcas.append(method_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import matplotlib\n",
    "\n",
    "font = {'weight' : 'bold',\n",
    "        'size'   : 18}\n",
    "\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, figsize=(10, 25))\n",
    "method_pca = np.array(pcas).reshape(-1)\n",
    "componentes = [pc.n_components_ for pc in method_pca]\n",
    "\n",
    "for pc in method_pca:\n",
    "\n",
    "    ax[0].plot(np.arange(1, pc.n_components_ + 1),\n",
    "             pc.explained_variance_ratio_, '+', linewidth=2)\n",
    "    ax[0].set_ylabel('Explicação da variação do PCA')\n",
    "\n",
    "ax[1] = sns.boxplot(componentes,orient='vert',ax=ax[1])\n",
    "ax[1].set_title(\"média {media:.5}, desvio padrao {std:.2}, maximo {maxi}, minimo {mini}\".format(\n",
    "                                                                        media = np.mean(componentes),\n",
    "                                                                        std   = np.std(componentes), \n",
    "                                                                        maxi  = np.max(componentes),\n",
    "                                                                        mini  = np.min(componentes)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escolhemos $47$ como o número de componentes, sendo esse o número máximo de componentes necessários para explicar 99% dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myPCA_47_comp(data, n_components = 47): \n",
    "    return myPCA(data, return_data=True, n_components=n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################    \n",
    "\n",
    "X_aud_expo_1_frames = []\n",
    "\n",
    "for person in aud_expo_1_frames:\n",
    "\n",
    "    data_pca = list(map(myPCA_47_comp, person))\n",
    "    X_aud_expo_1_frames.append(data_pca)\n",
    "#####################################################################    \n",
    "\n",
    "X_aud_expo_2_frames = []\n",
    "\n",
    "\n",
    "for person in aud_expo_2_frames:\n",
    "\n",
    "    data_pca = list(map(myPCA_47_comp, person))\n",
    "    X_aud_expo_2_frames.append(data_pca)\n",
    "    \n",
    "#####################################################################\n",
    "\n",
    "X_vis_expo_1_frames = []\n",
    "\n",
    "for person in vis_expo_1_frames:\n",
    "\n",
    "    data_pca = list(map(myPCA_47_comp, person))\n",
    "    X_vis_expo_1_frames.append(data_pca)\n",
    "    \n",
    "#####################################################################    \n",
    "        \n",
    "X_vis_expo_2_frames = []\n",
    "\n",
    "for person in vis_expo_2_frames:\n",
    "\n",
    "    data_pca = list(map(myPCA_47_comp, person))\n",
    "    X_vis_expo_2_frames.append(data_pca)\n",
    "    \n",
    "#####################################################################        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_DataFrame(X :list)-> pd.DataFrame:\n",
    "    \n",
    "    X_transpose = np.array(X).transpose([1, 2, 0, 3])\n",
    "    \n",
    "    X_preDataFrame = np.concatenate(np.concatenate(X_transpose,axis=0),axis=0)\n",
    "    \n",
    "    dataframe = pd.DataFrame(X_preDataFrame)\n",
    "    \n",
    "    dataframe = dataframe.reset_index()\n",
    "    \n",
    "    dataframe['person'] = (dataframe['index'] % 20)+1\n",
    "    \n",
    "    dataframe['trial'] = (dataframe['index'] % 120)+1\n",
    "    \n",
    "    dataframe['class'] = (dataframe['index'] % 6) +1\n",
    "    \n",
    "    dataframe = dataframe.drop('index',1)\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vis_1 = to_DataFrame(X_vis_expo_1_frames)\n",
    "df_vis_2 = to_DataFrame(X_vis_expo_2_frames)\n",
    "\n",
    "df_aud_1 = to_DataFrame(X_aud_expo_1_frames)\n",
    "df_aud_2 = to_DataFrame(X_aud_expo_2_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vis_1.to_csv(\"../data/processed/visual_exposure_1.csv\",index=None)\n",
    "df_vis_2.to_csv(\"../data/processed/visual_exposure_2.csv\",index=None)\n",
    "\n",
    "df_aud_1.to_csv(\"../data/processed/auditory_exposure_1.csv\",index=None)\n",
    "df_aud_2.to_csv(\"../data/processed/auditory_exposure_2.csv\",index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def make_Classification(df):\n",
    "    X = df.drop(['person',  'trial', 'class'],1)\n",
    "    y = df['class']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "    clf = GaussianNB()\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classificação nos Dados Visual, exposição 1\")\n",
    "make_Classification(df_vis_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classificação nos Dados Visual, exposição 2\")\n",
    "make_Classification(df_vis_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classificação nos Dados Auditivo, exposição 1\")\n",
    "make_Classification(df_aud_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classificação nos Dados Auditivo, exposição 2\")\n",
    "make_Classification(df_aud_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EEG recordings and pre-processing\n",
    "\n",
    "EEG was recorded continuously from 64 ActiCap Electrodes (Brain Products) at 1000 Hz by a QuickAmp amplifier (Brain Products). All sites were referenced to FCz and grounded to AFz. The electrodes were positioned according to the International 10–10 system. Additional bipolar electrodes registered the electrooculogram (EOG).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EEG pre-processing was carried out using BrainVision Analyzer (Brain Products). All data were down-sampled to 250 Hz and re-referenced to the average activity across electrodes. For eye movement artefact rejection, an independent component analysis (ICA) was performed on filtered (Butterworth Zero Phase Filter between 0.05.05 Hz and 30 Hz) and segmented (−200 to 2000 ms relative to S1) data. For the ICA, epochs were baselined based on the average activity of the entire trial. Eye related components were identified by comparing individual ICA components with EOG channels and by visual inspection. The average proportion of rejected trials for each participant corresponded to 0.0613. For all further analyses, epochs were baseline corrected based on the period between −200 ms and 0 ms relative to S1 presentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity between different trials and modalities\n",
    "\n",
    "To calculate the similarity across trials we used a bootstrap approach. For each participant and comparison of interest, data from all intervals that lasted at least 1.125 s were divided into two groups of trials and averaged across trials per group (Bueno et al., 2017). Then, for each time point, data from each split (two-row vectors with the averaged amplitude values of all 62 electrodes) were compared using a Pearson correlation. This procedure was repeated 5000 times for each participant and Fisher transformed coefficients were averaged across permutations for each participant and comparison of interest.\n",
    "\n",
    "At the group level, EEG-analyses were implemented non-parametrically (Maris and Oostenveld, 2007, Wolff et al., 2015) with sign-permutation tests. For each time-point, the Fisher transformed coefficients for a random half of the participants were multiplied by. The resulting distribution was used to calculate the p-value of the null-hypothesis that the mean value was equal to 0. Cluster-based permutation tests were then used to correct for multiple comparisons across time using 5000 permutations, with a cluster-forming threshold of p (Maris and Oostenveld, 2007). The sum of the values within a cluster was used as the cluster-level statistic. The significance threshold was set at p; all tests were one-sided.\n",
    "\n",
    "### Decoding the elapsed interval\n",
    "\n",
    "To investigate whether information about the elapsed interval could be decoded from activity across electrodes, we used a Naive Bayes classifier to perform a multiclass classification (Grootswagers et al., 2017). For all classifications, activity from the last 125 ms of the elapsed interval (−125 ms to 0 relative to S2) was averaged for each electrode. Data for each exposure (E1 and E2) were analysed separately. Intervals were divided into six equally sized bins (125 ms each)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
