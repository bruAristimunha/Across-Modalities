{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abordagem Inicial \n",
    "\n",
    "## Objetivo \n",
    "\n",
    "### Propor método para:\n",
    "* encontrar representações comuns de diferentes modalidades sensoriais\n",
    "* aumentar a quantidade de dados utilizados para redução de dimensionalidade do sinal\n",
    "* melhorar a sensibilidade de análises MVPA posteriores \n",
    "\n",
    "### Inicialmente codificar cada instante de tempo (sem usar janelas no tempo)\n",
    "### Decodificar o momento que estava na mesma e na outra modalidade a partir do estado reduzido\n",
    "* Comparar com decodificação usando: (1) Sinais originais, (2) PCA geral, (3) PCA em cada ponto, (4) Auto-encoder\n",
    "### Ver sobre use da auto-encoders e VAEs\n",
    "### Checar sobre predição da reprodução do intervalo temporal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from myMNE import makeMNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "240 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "240 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "240 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "240 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "240 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "240 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "240 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "240 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "240 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "240 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "240 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "240 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "240 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "240 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "240 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "240 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "240 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "240 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "240 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "mypath = 'aud'\n",
    "\n",
    "onlyfiles = [mypath+\"/\"+f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "auds = list(map(makeMNE,onlyfiles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passo 1: treinar com dados completos capturados do experimento\n",
    "* Entrada e saída como o mesmo sinal (um número para cada eletrodo)\n",
    "* Usar uma rede fully connected e auto-encoder padrão\n",
    "    * 64(E) - 32 - 16 - 8 - 16 - 32 - 64(S)\n",
    "    * Fazer testes verificando o erro de reconstrução\n",
    "* Uma rede por voluntário e por modalidade\n",
    "* Pouca quantidade de dados -> incluir regularização, como dropout, para evitar overfitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [aud.get_data().T for aud in auds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "merge_data = np.concatenate(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_data =  merge_data.reshape((10780, 240, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun_loss = losses.mean_absolute_error\n",
    "\n",
    "value_encoding_dim = 8\n",
    "original_trial =  Input(shape=(240,1))\n",
    "enconded = Dense(64, activation='relu')(original_trial)\n",
    "enconded = Dense(32, activation='relu')(enconded)\n",
    "enconded = Dense(16, activation='relu')(enconded)\n",
    "\n",
    "\n",
    "enconded = Dense(value_encoding_dim, activation='relu')(enconded)\n",
    "deconded = Dense(16, activation='relu', use_bias=False)(enconded)\n",
    "deconded = Dense(32, activation='relu', use_bias=False)(deconded)\n",
    "deconded = Dense(64, activation='relu', use_bias=False)(deconded)\n",
    "\n",
    "encoder = Model(original_trial, enconded, name='encoder')\n",
    "autoencoder = Model(original_trial, deconded, name='autoenconder')    \n",
    "\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss=fun_loss,metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "canal_1 = merge_data[:,:,63]\n",
    "X_exemplo = canal_1.reshape(10780, 240,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10780 samples, validate on 10780 samples\n",
      "Epoch 1/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7646 - accuracy: 0.5012 - val_loss: 7.7631 - val_accuracy: 0.5012\n",
      "Epoch 2/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7643 - accuracy: 0.5012 - val_loss: 7.7645 - val_accuracy: 0.5012\n",
      "Epoch 3/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7660 - accuracy: 0.5012 - val_loss: 7.7693 - val_accuracy: 0.5012\n",
      "Epoch 4/5000\n",
      "10780/10780 [==============================] - 0s 43us/sample - loss: 7.7640 - accuracy: 0.5012 - val_loss: 7.7638 - val_accuracy: 0.5012\n",
      "Epoch 5/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7631 - accuracy: 0.5012 - val_loss: 7.7624 - val_accuracy: 0.5012\n",
      "Epoch 6/5000\n",
      "10780/10780 [==============================] - 0s 43us/sample - loss: 7.7631 - accuracy: 0.5012 - val_loss: 7.7621 - val_accuracy: 0.5012\n",
      "Epoch 7/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7633 - accuracy: 0.5012 - val_loss: 7.7640 - val_accuracy: 0.5012\n",
      "Epoch 8/5000\n",
      "10780/10780 [==============================] - 0s 43us/sample - loss: 7.7636 - accuracy: 0.5474 - val_loss: 7.7634 - val_accuracy: 0.5012\n",
      "Epoch 9/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7640 - accuracy: 0.5012 - val_loss: 7.7630 - val_accuracy: 0.5012\n",
      "Epoch 10/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7645 - accuracy: 0.5012 - val_loss: 7.7667 - val_accuracy: 0.5012\n",
      "Epoch 11/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7646 - accuracy: 0.5012 - val_loss: 7.7651 - val_accuracy: 0.5012\n",
      "Epoch 12/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7642 - accuracy: 0.5012 - val_loss: 7.7661 - val_accuracy: 0.5012\n",
      "Epoch 13/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7644 - accuracy: 0.5012 - val_loss: 7.7694 - val_accuracy: 0.5013\n",
      "Epoch 14/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7687 - accuracy: 0.5472 - val_loss: 7.7666 - val_accuracy: 0.5012\n",
      "Epoch 15/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7647 - accuracy: 0.5477 - val_loss: 7.7634 - val_accuracy: 0.5012\n",
      "Epoch 16/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7631 - accuracy: 0.6635 - val_loss: 7.7644 - val_accuracy: 0.5012\n",
      "Epoch 17/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7646 - accuracy: 0.5242 - val_loss: 7.7648 - val_accuracy: 0.5012\n",
      "Epoch 18/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7646 - accuracy: 0.5012 - val_loss: 7.7639 - val_accuracy: 0.5012\n",
      "Epoch 19/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7664 - accuracy: 0.6169 - val_loss: 7.7642 - val_accuracy: 0.5012\n",
      "Epoch 20/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7663 - accuracy: 0.5012 - val_loss: 7.7658 - val_accuracy: 0.5012\n",
      "Epoch 21/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7638 - accuracy: 0.5012 - val_loss: 7.7643 - val_accuracy: 0.5012\n",
      "Epoch 22/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7639 - accuracy: 0.5012 - val_loss: 7.7662 - val_accuracy: 0.5012\n",
      "Epoch 23/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7640 - accuracy: 0.5012 - val_loss: 7.7648 - val_accuracy: 0.5011\n",
      "Epoch 24/5000\n",
      "10780/10780 [==============================] - 0s 31us/sample - loss: 7.7638 - accuracy: 0.5012 - val_loss: 7.7640 - val_accuracy: 0.5012\n",
      "Epoch 25/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7655 - accuracy: 0.5242 - val_loss: 7.7638 - val_accuracy: 0.5012\n",
      "Epoch 26/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7645 - accuracy: 0.6297 - val_loss: 7.7640 - val_accuracy: 1.0000\n",
      "Epoch 27/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7646 - accuracy: 0.6400 - val_loss: 7.7627 - val_accuracy: 0.5012\n",
      "Epoch 28/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7639 - accuracy: 0.5012 - val_loss: 7.7633 - val_accuracy: 0.5012\n",
      "Epoch 29/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7640 - accuracy: 0.5012 - val_loss: 7.7639 - val_accuracy: 0.5012\n",
      "Epoch 30/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7637 - accuracy: 0.5012 - val_loss: 7.7630 - val_accuracy: 0.5012\n",
      "Epoch 31/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7635 - accuracy: 0.5706 - val_loss: 7.7646 - val_accuracy: 0.5012\n",
      "Epoch 32/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7640 - accuracy: 0.5012 - val_loss: 7.7620 - val_accuracy: 0.5012\n",
      "Epoch 33/5000\n",
      "10780/10780 [==============================] - 0s 31us/sample - loss: 7.7636 - accuracy: 0.5012 - val_loss: 7.7637 - val_accuracy: 0.5012\n",
      "Epoch 34/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7654 - accuracy: 0.5012 - val_loss: 7.7684 - val_accuracy: 0.5011\n",
      "Epoch 35/5000\n",
      "10780/10780 [==============================] - 0s 29us/sample - loss: 7.7660 - accuracy: 0.5012 - val_loss: 7.7648 - val_accuracy: 0.5012\n",
      "Epoch 36/5000\n",
      "10780/10780 [==============================] - 0s 31us/sample - loss: 7.7629 - accuracy: 0.5012 - val_loss: 7.7634 - val_accuracy: 0.5012\n",
      "Epoch 37/5000\n",
      "10780/10780 [==============================] - 0s 31us/sample - loss: 7.7632 - accuracy: 0.5473 - val_loss: 7.7622 - val_accuracy: 0.5012\n",
      "Epoch 38/5000\n",
      "10780/10780 [==============================] - 0s 29us/sample - loss: 7.7640 - accuracy: 0.5012 - val_loss: 7.7636 - val_accuracy: 0.5012\n",
      "Epoch 39/5000\n",
      "10780/10780 [==============================] - 0s 30us/sample - loss: 7.7632 - accuracy: 0.5012 - val_loss: 7.7644 - val_accuracy: 0.5012\n",
      "Epoch 40/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7641 - accuracy: 0.5477 - val_loss: 7.7638 - val_accuracy: 0.5012\n",
      "Epoch 41/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7634 - accuracy: 0.6167 - val_loss: 7.7629 - val_accuracy: 0.5012\n",
      "Epoch 42/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7640 - accuracy: 0.5703 - val_loss: 7.7632 - val_accuracy: 0.5012\n",
      "Epoch 43/5000\n",
      "10780/10780 [==============================] - 0s 43us/sample - loss: 7.7663 - accuracy: 0.5012 - val_loss: 7.7666 - val_accuracy: 0.5012\n",
      "Epoch 44/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7660 - accuracy: 0.5012 - val_loss: 7.7637 - val_accuracy: 0.5012\n",
      "Epoch 45/5000\n",
      "10780/10780 [==============================] - 1s 47us/sample - loss: 7.7638 - accuracy: 0.5012 - val_loss: 7.7633 - val_accuracy: 0.5012\n",
      "Epoch 46/5000\n",
      "10780/10780 [==============================] - 1s 51us/sample - loss: 7.7631 - accuracy: 0.5012 - val_loss: 7.7631 - val_accuracy: 0.5012\n",
      "Epoch 47/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7638 - accuracy: 0.5012 - val_loss: 7.7634 - val_accuracy: 0.5012\n",
      "Epoch 48/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7641 - accuracy: 0.5239 - val_loss: 7.7696 - val_accuracy: 0.5011\n",
      "Epoch 49/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7714 - accuracy: 0.5012 - val_loss: 7.7651 - val_accuracy: 0.5012\n",
      "Epoch 50/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7686 - accuracy: 0.5012 - val_loss: 7.7737 - val_accuracy: 0.5011\n",
      "Epoch 51/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7677 - accuracy: 0.5012 - val_loss: 7.7671 - val_accuracy: 0.5012\n",
      "Epoch 52/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7691 - accuracy: 0.5012 - val_loss: 7.7707 - val_accuracy: 0.5013\n",
      "Epoch 53/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7670 - accuracy: 0.6172 - val_loss: 7.7631 - val_accuracy: 0.5012\n",
      "Epoch 54/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10780/10780 [==============================] - 0s 31us/sample - loss: 7.7689 - accuracy: 0.5012 - val_loss: 7.7630 - val_accuracy: 0.5012\n",
      "Epoch 55/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7662 - accuracy: 0.5012 - val_loss: 7.7685 - val_accuracy: 0.5012\n",
      "Epoch 56/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7656 - accuracy: 0.5940 - val_loss: 7.7636 - val_accuracy: 0.5012\n",
      "Epoch 57/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7634 - accuracy: 0.5012 - val_loss: 7.7636 - val_accuracy: 0.5012\n",
      "Epoch 58/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7634 - accuracy: 0.5012 - val_loss: 7.7636 - val_accuracy: 0.5012\n",
      "Epoch 59/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7643 - accuracy: 0.5012 - val_loss: 7.7630 - val_accuracy: 0.5012\n",
      "Epoch 60/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7660 - accuracy: 0.5012 - val_loss: 7.7633 - val_accuracy: 0.5012\n",
      "Epoch 61/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7639 - accuracy: 0.5012 - val_loss: 7.7649 - val_accuracy: 0.5012\n",
      "Epoch 62/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7631 - accuracy: 0.5012 - val_loss: 7.7658 - val_accuracy: 0.5012\n",
      "Epoch 63/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7649 - accuracy: 0.5012 - val_loss: 7.7656 - val_accuracy: 0.5012\n",
      "Epoch 64/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7639 - accuracy: 0.5012 - val_loss: 7.7624 - val_accuracy: 0.5012\n",
      "Epoch 65/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7640 - accuracy: 0.5012 - val_loss: 7.7652 - val_accuracy: 0.5012\n",
      "Epoch 66/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7634 - accuracy: 0.5012 - val_loss: 7.7621 - val_accuracy: 0.5012\n",
      "Epoch 67/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7630 - accuracy: 0.5012 - val_loss: 7.7622 - val_accuracy: 0.5012\n",
      "Epoch 68/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7630 - accuracy: 0.5471 - val_loss: 7.7614 - val_accuracy: 0.5012\n",
      "Epoch 69/5000\n",
      "10780/10780 [==============================] - 0s 32us/sample - loss: 7.7637 - accuracy: 0.5012 - val_loss: 7.7631 - val_accuracy: 0.5012\n",
      "Epoch 70/5000\n",
      "10780/10780 [==============================] - 1s 47us/sample - loss: 7.7631 - accuracy: 0.5012 - val_loss: 7.7648 - val_accuracy: 0.5012\n",
      "Epoch 71/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7638 - accuracy: 0.6167 - val_loss: 7.7652 - val_accuracy: 0.5012\n",
      "Epoch 72/5000\n",
      "10780/10780 [==============================] - 0s 32us/sample - loss: 7.7641 - accuracy: 0.5474 - val_loss: 7.7668 - val_accuracy: 0.5012\n",
      "Epoch 73/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7642 - accuracy: 0.5704 - val_loss: 7.7623 - val_accuracy: 0.5012\n",
      "Epoch 74/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7625 - accuracy: 0.5012 - val_loss: 7.7635 - val_accuracy: 0.5012\n",
      "Epoch 75/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7637 - accuracy: 0.5012 - val_loss: 7.7622 - val_accuracy: 0.5012\n",
      "Epoch 76/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7656 - accuracy: 0.5012 - val_loss: 7.7638 - val_accuracy: 0.5012\n",
      "Epoch 77/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7643 - accuracy: 0.5473 - val_loss: 7.7633 - val_accuracy: 0.5012\n",
      "Epoch 78/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7660 - accuracy: 0.5708 - val_loss: 7.7645 - val_accuracy: 0.5012\n",
      "Epoch 79/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7628 - accuracy: 0.5012 - val_loss: 7.7640 - val_accuracy: 0.5012\n",
      "Epoch 80/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7628 - accuracy: 0.5012 - val_loss: 7.7628 - val_accuracy: 0.5012\n",
      "Epoch 81/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7637 - accuracy: 0.5012 - val_loss: 7.7647 - val_accuracy: 0.5011\n",
      "Epoch 82/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7644 - accuracy: 0.5012 - val_loss: 7.7657 - val_accuracy: 0.5011\n",
      "Epoch 83/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7642 - accuracy: 0.5012 - val_loss: 7.7658 - val_accuracy: 0.5012\n",
      "Epoch 84/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7647 - accuracy: 0.5012 - val_loss: 7.7622 - val_accuracy: 0.5012\n",
      "Epoch 85/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7660 - accuracy: 0.5473 - val_loss: 7.7632 - val_accuracy: 0.5012\n",
      "Epoch 86/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7655 - accuracy: 0.5012 - val_loss: 7.7648 - val_accuracy: 0.5012\n",
      "Epoch 87/5000\n",
      "10780/10780 [==============================] - 0s 44us/sample - loss: 7.7635 - accuracy: 0.5012 - val_loss: 7.7645 - val_accuracy: 0.5012\n",
      "Epoch 88/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7642 - accuracy: 0.5012 - val_loss: 7.7624 - val_accuracy: 0.5012\n",
      "Epoch 89/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7640 - accuracy: 0.5012 - val_loss: 7.7633 - val_accuracy: 0.5012\n",
      "Epoch 90/5000\n",
      "10780/10780 [==============================] - 0s 43us/sample - loss: 7.7637 - accuracy: 0.5012 - val_loss: 7.7644 - val_accuracy: 0.5012\n",
      "Epoch 91/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7645 - accuracy: 0.6297 - val_loss: 7.7650 - val_accuracy: 0.5012\n",
      "Epoch 92/5000\n",
      "10780/10780 [==============================] - 0s 29us/sample - loss: 7.7634 - accuracy: 0.5012 - val_loss: 7.7620 - val_accuracy: 0.5012\n",
      "Epoch 93/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7635 - accuracy: 0.5012 - val_loss: 7.7656 - val_accuracy: 0.5012\n",
      "Epoch 94/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7642 - accuracy: 0.5012 - val_loss: 7.7634 - val_accuracy: 0.5012\n",
      "Epoch 95/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7632 - accuracy: 0.5242 - val_loss: 7.7621 - val_accuracy: 0.5012\n",
      "Epoch 96/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7629 - accuracy: 0.6402 - val_loss: 7.7639 - val_accuracy: 0.5012\n",
      "Epoch 97/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7642 - accuracy: 0.5012 - val_loss: 7.7639 - val_accuracy: 0.5013\n",
      "Epoch 98/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7664 - accuracy: 0.5939 - val_loss: 7.7663 - val_accuracy: 0.5012\n",
      "Epoch 99/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7649 - accuracy: 0.5012 - val_loss: 7.7631 - val_accuracy: 0.5012\n",
      "Epoch 100/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7634 - accuracy: 0.5478 - val_loss: 7.7624 - val_accuracy: 0.5012\n",
      "Epoch 101/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7632 - accuracy: 0.5012 - val_loss: 7.7641 - val_accuracy: 0.5012\n",
      "Epoch 102/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7636 - accuracy: 0.5012 - val_loss: 7.7630 - val_accuracy: 0.5012\n",
      "Epoch 103/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7633 - accuracy: 0.5012 - val_loss: 7.7639 - val_accuracy: 0.5012\n",
      "Epoch 104/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7657 - accuracy: 0.5012 - val_loss: 7.7626 - val_accuracy: 0.5012\n",
      "Epoch 105/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7636 - accuracy: 0.5012 - val_loss: 7.7651 - val_accuracy: 0.5012\n",
      "Epoch 106/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7669 - accuracy: 0.5012 - val_loss: 7.7655 - val_accuracy: 0.5012\n",
      "Epoch 107/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7640 - accuracy: 0.5012 - val_loss: 7.7639 - val_accuracy: 0.5012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7646 - accuracy: 0.5472 - val_loss: 7.7652 - val_accuracy: 0.5012\n",
      "Epoch 109/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7676 - accuracy: 0.5012 - val_loss: 7.7661 - val_accuracy: 0.5012\n",
      "Epoch 110/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7698 - accuracy: 0.5930 - val_loss: 7.7681 - val_accuracy: 0.5012\n",
      "Epoch 111/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7698 - accuracy: 0.5012 - val_loss: 7.7725 - val_accuracy: 0.5011\n",
      "Epoch 112/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7685 - accuracy: 0.5012 - val_loss: 7.7718 - val_accuracy: 0.5011\n",
      "Epoch 113/5000\n",
      "10780/10780 [==============================] - 1s 52us/sample - loss: 7.7678 - accuracy: 0.5012 - val_loss: 7.7663 - val_accuracy: 0.5012\n",
      "Epoch 114/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7656 - accuracy: 0.5012 - val_loss: 7.7652 - val_accuracy: 0.5012\n",
      "Epoch 115/5000\n",
      "10780/10780 [==============================] - 0s 31us/sample - loss: 7.7647 - accuracy: 0.5012 - val_loss: 7.7635 - val_accuracy: 1.0000\n",
      "Epoch 116/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7634 - accuracy: 0.5245 - val_loss: 7.7639 - val_accuracy: 0.5012\n",
      "Epoch 117/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7655 - accuracy: 0.5012 - val_loss: 7.7666 - val_accuracy: 0.5012\n",
      "Epoch 118/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7655 - accuracy: 0.5472 - val_loss: 7.7637 - val_accuracy: 0.5012\n",
      "Epoch 119/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7636 - accuracy: 0.5012 - val_loss: 7.7646 - val_accuracy: 0.5012\n",
      "Epoch 120/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7636 - accuracy: 0.5012 - val_loss: 7.7641 - val_accuracy: 0.5012\n",
      "Epoch 121/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7680 - accuracy: 0.5012 - val_loss: 7.7658 - val_accuracy: 0.5012\n",
      "Epoch 122/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7677 - accuracy: 0.5012 - val_loss: 7.7716 - val_accuracy: 0.5011\n",
      "Epoch 123/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7666 - accuracy: 0.5012 - val_loss: 7.7643 - val_accuracy: 0.5012\n",
      "Epoch 124/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7637 - accuracy: 0.5012 - val_loss: 7.7635 - val_accuracy: 0.5012\n",
      "Epoch 125/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7634 - accuracy: 0.5012 - val_loss: 7.7630 - val_accuracy: 0.5012\n",
      "Epoch 126/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7628 - accuracy: 0.5012 - val_loss: 7.7627 - val_accuracy: 0.5012\n",
      "Epoch 127/5000\n",
      "10780/10780 [==============================] - 0s 46us/sample - loss: 7.7647 - accuracy: 0.5012 - val_loss: 7.7685 - val_accuracy: 0.5011\n",
      "Epoch 128/5000\n",
      "10780/10780 [==============================] - 1s 52us/sample - loss: 7.7651 - accuracy: 0.5012 - val_loss: 7.7692 - val_accuracy: 0.5012\n",
      "Epoch 129/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7680 - accuracy: 0.5012 - val_loss: 7.7671 - val_accuracy: 0.5012\n",
      "Epoch 130/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7643 - accuracy: 0.5943 - val_loss: 7.7628 - val_accuracy: 0.5012\n",
      "Epoch 131/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7629 - accuracy: 0.5704 - val_loss: 7.7618 - val_accuracy: 0.5012\n",
      "Epoch 132/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7626 - accuracy: 0.5012 - val_loss: 7.7623 - val_accuracy: 0.5012\n",
      "Epoch 133/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7631 - accuracy: 0.6066 - val_loss: 7.7624 - val_accuracy: 1.0000\n",
      "Epoch 134/5000\n",
      "10780/10780 [==============================] - 0s 31us/sample - loss: 7.7639 - accuracy: 0.5941 - val_loss: 7.7639 - val_accuracy: 0.5012\n",
      "Epoch 135/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7647 - accuracy: 0.5012 - val_loss: 7.7687 - val_accuracy: 0.5012\n",
      "Epoch 136/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7649 - accuracy: 0.5708 - val_loss: 7.7612 - val_accuracy: 0.5012\n",
      "Epoch 137/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7633 - accuracy: 0.5245 - val_loss: 7.7626 - val_accuracy: 0.5012\n",
      "Epoch 138/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7639 - accuracy: 0.5012 - val_loss: 7.7623 - val_accuracy: 0.5012\n",
      "Epoch 139/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7626 - accuracy: 0.5248 - val_loss: 7.7621 - val_accuracy: 0.5012\n",
      "Epoch 140/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7631 - accuracy: 0.6169 - val_loss: 7.7637 - val_accuracy: 0.5012\n",
      "Epoch 141/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7634 - accuracy: 0.5012 - val_loss: 7.7645 - val_accuracy: 0.5012\n",
      "Epoch 142/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7632 - accuracy: 0.5479 - val_loss: 7.7724 - val_accuracy: 0.5013\n",
      "Epoch 143/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7676 - accuracy: 0.5012 - val_loss: 7.7669 - val_accuracy: 0.5012\n",
      "Epoch 144/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7657 - accuracy: 0.5012 - val_loss: 7.7631 - val_accuracy: 0.5012\n",
      "Epoch 145/5000\n",
      "10780/10780 [==============================] - 0s 31us/sample - loss: 7.7631 - accuracy: 0.5702 - val_loss: 7.7661 - val_accuracy: 0.5013\n",
      "Epoch 146/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7636 - accuracy: 0.5012 - val_loss: 7.7653 - val_accuracy: 0.5011\n",
      "Epoch 147/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7641 - accuracy: 0.5836 - val_loss: 7.7628 - val_accuracy: 1.0000\n",
      "Epoch 148/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7633 - accuracy: 0.6404 - val_loss: 7.7622 - val_accuracy: 0.5012\n",
      "Epoch 149/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7639 - accuracy: 0.5938 - val_loss: 7.7631 - val_accuracy: 0.5012\n",
      "Epoch 150/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7631 - accuracy: 0.5246 - val_loss: 7.7628 - val_accuracy: 0.5012\n",
      "Epoch 151/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7643 - accuracy: 0.5012 - val_loss: 7.7648 - val_accuracy: 0.5012\n",
      "Epoch 152/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7630 - accuracy: 0.5604 - val_loss: 7.7620 - val_accuracy: 0.5012\n",
      "Epoch 153/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7633 - accuracy: 0.5012 - val_loss: 7.7631 - val_accuracy: 0.5012\n",
      "Epoch 154/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7628 - accuracy: 0.5012 - val_loss: 7.7625 - val_accuracy: 0.5012\n",
      "Epoch 155/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7629 - accuracy: 0.5012 - val_loss: 7.7618 - val_accuracy: 0.5012\n",
      "Epoch 156/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7651 - accuracy: 0.5012 - val_loss: 7.7671 - val_accuracy: 0.5012\n",
      "Epoch 157/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7648 - accuracy: 0.5012 - val_loss: 7.7633 - val_accuracy: 0.5012\n",
      "Epoch 158/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7672 - accuracy: 0.5012 - val_loss: 7.7673 - val_accuracy: 0.5012\n",
      "Epoch 159/5000\n",
      "10780/10780 [==============================] - 0s 29us/sample - loss: 7.7669 - accuracy: 0.5012 - val_loss: 7.7661 - val_accuracy: 0.5012\n",
      "Epoch 160/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7633 - accuracy: 0.6397 - val_loss: 7.7613 - val_accuracy: 0.5012\n",
      "Epoch 161/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7638 - accuracy: 0.5936 - val_loss: 7.7650 - val_accuracy: 0.5013\n",
      "Epoch 162/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7632 - accuracy: 0.5012 - val_loss: 7.7621 - val_accuracy: 0.5011\n",
      "Epoch 163/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7640 - accuracy: 0.5012 - val_loss: 7.7638 - val_accuracy: 0.5012\n",
      "Epoch 164/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7632 - accuracy: 0.5012 - val_loss: 7.7629 - val_accuracy: 0.5012\n",
      "Epoch 165/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7631 - accuracy: 0.5012 - val_loss: 7.7625 - val_accuracy: 0.5012\n",
      "Epoch 166/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7699 - accuracy: 0.5012 - val_loss: 7.7655 - val_accuracy: 0.5012\n",
      "Epoch 167/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7634 - accuracy: 0.5012 - val_loss: 7.7618 - val_accuracy: 0.5012\n",
      "Epoch 168/5000\n",
      "10780/10780 [==============================] - 0s 43us/sample - loss: 7.7642 - accuracy: 0.5701 - val_loss: 7.7632 - val_accuracy: 0.5012\n",
      "Epoch 169/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7635 - accuracy: 0.5012 - val_loss: 7.7634 - val_accuracy: 0.5012\n",
      "Epoch 170/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7653 - accuracy: 0.5012 - val_loss: 7.7642 - val_accuracy: 0.5012\n",
      "Epoch 171/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7662 - accuracy: 0.5012 - val_loss: 7.7653 - val_accuracy: 0.5011\n",
      "Epoch 172/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7646 - accuracy: 0.5012 - val_loss: 7.7638 - val_accuracy: 0.5012\n",
      "Epoch 173/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7642 - accuracy: 0.5012 - val_loss: 7.7631 - val_accuracy: 0.5011\n",
      "Epoch 174/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7631 - accuracy: 0.5012 - val_loss: 7.7642 - val_accuracy: 0.5012\n",
      "Epoch 175/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7637 - accuracy: 0.5012 - val_loss: 7.7615 - val_accuracy: 0.5012\n",
      "Epoch 176/5000\n",
      "10780/10780 [==============================] - 0s 43us/sample - loss: 7.7649 - accuracy: 0.5012 - val_loss: 7.7640 - val_accuracy: 0.5012\n",
      "Epoch 177/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7642 - accuracy: 0.5244 - val_loss: 7.7632 - val_accuracy: 0.5012\n",
      "Epoch 178/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7661 - accuracy: 0.6168 - val_loss: 7.7679 - val_accuracy: 0.5012\n",
      "Epoch 179/5000\n",
      "10780/10780 [==============================] - 0s 43us/sample - loss: 7.7675 - accuracy: 0.5012 - val_loss: 7.7668 - val_accuracy: 0.5013\n",
      "Epoch 180/5000\n",
      "10780/10780 [==============================] - 0s 43us/sample - loss: 7.7639 - accuracy: 0.5012 - val_loss: 7.7650 - val_accuracy: 0.5012\n",
      "Epoch 181/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7681 - accuracy: 0.5012 - val_loss: 7.7668 - val_accuracy: 0.5013\n",
      "Epoch 182/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7695 - accuracy: 0.5012 - val_loss: 7.7643 - val_accuracy: 0.5012\n",
      "Epoch 183/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7648 - accuracy: 0.5012 - val_loss: 7.7637 - val_accuracy: 0.5012\n",
      "Epoch 184/5000\n",
      "10780/10780 [==============================] - 0s 43us/sample - loss: 7.7632 - accuracy: 0.5243 - val_loss: 7.7625 - val_accuracy: 0.5012\n",
      "Epoch 185/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7623 - accuracy: 0.5012 - val_loss: 7.7619 - val_accuracy: 0.5012\n",
      "Epoch 186/5000\n",
      "10780/10780 [==============================] - 0s 43us/sample - loss: 7.7625 - accuracy: 0.5012 - val_loss: 7.7641 - val_accuracy: 0.5013\n",
      "Epoch 187/5000\n",
      "10780/10780 [==============================] - 0s 44us/sample - loss: 7.7654 - accuracy: 0.5012 - val_loss: 7.7645 - val_accuracy: 0.5011\n",
      "Epoch 188/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7634 - accuracy: 0.5012 - val_loss: 7.7621 - val_accuracy: 0.5012\n",
      "Epoch 189/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7629 - accuracy: 0.5012 - val_loss: 7.7632 - val_accuracy: 0.5012\n",
      "Epoch 190/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7641 - accuracy: 0.5012 - val_loss: 7.7654 - val_accuracy: 0.5012\n",
      "Epoch 191/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7644 - accuracy: 0.5012 - val_loss: 7.7635 - val_accuracy: 0.5012\n",
      "Epoch 192/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7631 - accuracy: 0.5012 - val_loss: 7.7643 - val_accuracy: 0.5012\n",
      "Epoch 193/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7630 - accuracy: 0.5012 - val_loss: 7.7619 - val_accuracy: 0.5012\n",
      "Epoch 194/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7629 - accuracy: 0.5012 - val_loss: 7.7640 - val_accuracy: 0.5012\n",
      "Epoch 195/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7626 - accuracy: 0.5012 - val_loss: 7.7622 - val_accuracy: 0.5012\n",
      "Epoch 196/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7625 - accuracy: 0.5012 - val_loss: 7.7667 - val_accuracy: 0.5012\n",
      "Epoch 197/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7662 - accuracy: 0.5939 - val_loss: 7.7663 - val_accuracy: 0.5012\n",
      "Epoch 198/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7648 - accuracy: 0.5012 - val_loss: 7.7640 - val_accuracy: 0.5012\n",
      "Epoch 199/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7631 - accuracy: 0.5012 - val_loss: 7.7623 - val_accuracy: 0.5012\n",
      "Epoch 200/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7635 - accuracy: 0.5012 - val_loss: 7.7653 - val_accuracy: 0.5012\n",
      "Epoch 201/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7635 - accuracy: 0.5012 - val_loss: 7.7615 - val_accuracy: 0.5012\n",
      "Epoch 202/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7632 - accuracy: 0.5012 - val_loss: 7.7627 - val_accuracy: 0.5012\n",
      "Epoch 203/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7639 - accuracy: 0.5012 - val_loss: 7.7669 - val_accuracy: 0.5012\n",
      "Epoch 204/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7649 - accuracy: 0.5012 - val_loss: 7.7650 - val_accuracy: 0.5013\n",
      "Epoch 205/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7635 - accuracy: 0.5375 - val_loss: 7.7656 - val_accuracy: 0.5012\n",
      "Epoch 206/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7647 - accuracy: 0.5012 - val_loss: 7.7641 - val_accuracy: 0.5012\n",
      "Epoch 207/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7644 - accuracy: 0.5012 - val_loss: 7.7628 - val_accuracy: 0.5012\n",
      "Epoch 208/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7638 - accuracy: 0.5012 - val_loss: 7.7632 - val_accuracy: 0.5012\n",
      "Epoch 209/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7631 - accuracy: 0.5012 - val_loss: 7.7635 - val_accuracy: 0.5012\n",
      "Epoch 210/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7632 - accuracy: 0.5012 - val_loss: 7.7621 - val_accuracy: 0.5012\n",
      "Epoch 211/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7628 - accuracy: 0.5012 - val_loss: 7.7645 - val_accuracy: 0.5012\n",
      "Epoch 212/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7640 - accuracy: 0.5012 - val_loss: 7.7623 - val_accuracy: 0.5012\n",
      "Epoch 213/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7628 - accuracy: 0.5012 - val_loss: 7.7670 - val_accuracy: 0.5011\n",
      "Epoch 214/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7634 - accuracy: 0.5012 - val_loss: 7.7623 - val_accuracy: 0.5012\n",
      "Epoch 215/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7680 - accuracy: 0.5012 - val_loss: 7.7653 - val_accuracy: 0.5012\n",
      "Epoch 216/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7647 - accuracy: 0.5012 - val_loss: 7.7639 - val_accuracy: 0.5012\n",
      "Epoch 217/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7634 - accuracy: 0.5012 - val_loss: 7.7637 - val_accuracy: 0.5012\n",
      "Epoch 218/5000\n",
      "10780/10780 [==============================] - 0s 46us/sample - loss: 7.7627 - accuracy: 0.5012 - val_loss: 7.7636 - val_accuracy: 0.5012\n",
      "Epoch 219/5000\n",
      "10780/10780 [==============================] - 1s 47us/sample - loss: 7.7641 - accuracy: 0.5139 - val_loss: 7.7678 - val_accuracy: 1.0000\n",
      "Epoch 220/5000\n",
      "10780/10780 [==============================] - 1s 47us/sample - loss: 7.7659 - accuracy: 0.5242 - val_loss: 7.7652 - val_accuracy: 0.5012\n",
      "Epoch 221/5000\n",
      "10780/10780 [==============================] - 1s 47us/sample - loss: 7.7643 - accuracy: 0.5469 - val_loss: 7.7640 - val_accuracy: 0.5012\n",
      "Epoch 222/5000\n",
      "10780/10780 [==============================] - 0s 46us/sample - loss: 7.7640 - accuracy: 0.5012 - val_loss: 7.7641 - val_accuracy: 0.5012\n",
      "Epoch 223/5000\n",
      "10780/10780 [==============================] - 1s 47us/sample - loss: 7.7630 - accuracy: 0.5012 - val_loss: 7.7630 - val_accuracy: 0.5012\n",
      "Epoch 224/5000\n",
      "10780/10780 [==============================] - 1s 47us/sample - loss: 7.7629 - accuracy: 0.5706 - val_loss: 7.7696 - val_accuracy: 0.5011\n",
      "Epoch 225/5000\n",
      "10780/10780 [==============================] - 1s 47us/sample - loss: 7.7659 - accuracy: 0.5012 - val_loss: 7.7673 - val_accuracy: 0.5012\n",
      "Epoch 226/5000\n",
      "10780/10780 [==============================] - 0s 45us/sample - loss: 7.7689 - accuracy: 0.5012 - val_loss: 7.7682 - val_accuracy: 0.5012\n",
      "Epoch 227/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7675 - accuracy: 0.5245 - val_loss: 7.7682 - val_accuracy: 0.5013\n",
      "Epoch 228/5000\n",
      "10780/10780 [==============================] - 0s 28us/sample - loss: 7.7654 - accuracy: 0.5012 - val_loss: 7.7636 - val_accuracy: 0.5012\n",
      "Epoch 229/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7640 - accuracy: 0.6166 - val_loss: 7.7646 - val_accuracy: 0.5012\n",
      "Epoch 230/5000\n",
      "10780/10780 [==============================] - 0s 32us/sample - loss: 7.7634 - accuracy: 0.5012 - val_loss: 7.7634 - val_accuracy: 0.5012\n",
      "Epoch 231/5000\n",
      "10780/10780 [==============================] - 0s 28us/sample - loss: 7.7644 - accuracy: 0.5012 - val_loss: 7.7689 - val_accuracy: 0.5013\n",
      "Epoch 232/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7651 - accuracy: 0.5012 - val_loss: 7.7624 - val_accuracy: 0.5012\n",
      "Epoch 233/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7636 - accuracy: 0.5012 - val_loss: 7.7620 - val_accuracy: 0.5012\n",
      "Epoch 234/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7644 - accuracy: 0.5474 - val_loss: 7.7675 - val_accuracy: 0.5013\n",
      "Epoch 235/5000\n",
      "10780/10780 [==============================] - 0s 32us/sample - loss: 7.7687 - accuracy: 0.5012 - val_loss: 7.7654 - val_accuracy: 0.5012\n",
      "Epoch 236/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7658 - accuracy: 0.5012 - val_loss: 7.7639 - val_accuracy: 0.5012\n",
      "Epoch 237/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7631 - accuracy: 0.5244 - val_loss: 7.7639 - val_accuracy: 0.5012\n",
      "Epoch 238/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7638 - accuracy: 0.5012 - val_loss: 7.7678 - val_accuracy: 0.5013\n",
      "Epoch 239/5000\n",
      "10780/10780 [==============================] - 0s 43us/sample - loss: 7.7644 - accuracy: 0.5012 - val_loss: 7.7629 - val_accuracy: 0.5012\n",
      "Epoch 240/5000\n",
      "10780/10780 [==============================] - 1s 46us/sample - loss: 7.7630 - accuracy: 0.5832 - val_loss: 7.7648 - val_accuracy: 1.0000\n",
      "Epoch 241/5000\n",
      "10780/10780 [==============================] - 1s 47us/sample - loss: 7.7645 - accuracy: 0.5472 - val_loss: 7.7652 - val_accuracy: 0.5012\n",
      "Epoch 242/5000\n",
      "10780/10780 [==============================] - 1s 47us/sample - loss: 7.7628 - accuracy: 0.5012 - val_loss: 7.7633 - val_accuracy: 0.5012\n",
      "Epoch 243/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7635 - accuracy: 0.5012 - val_loss: 7.7622 - val_accuracy: 0.5012\n",
      "Epoch 244/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7635 - accuracy: 0.5012 - val_loss: 7.7632 - val_accuracy: 0.5012\n",
      "Epoch 245/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7628 - accuracy: 0.5245 - val_loss: 7.7623 - val_accuracy: 0.5012\n",
      "Epoch 246/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7639 - accuracy: 0.5143 - val_loss: 7.7653 - val_accuracy: 1.0000\n",
      "Epoch 247/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7647 - accuracy: 0.5476 - val_loss: 7.7631 - val_accuracy: 0.5013\n",
      "Epoch 248/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7626 - accuracy: 0.5012 - val_loss: 7.7621 - val_accuracy: 0.5012\n",
      "Epoch 249/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7633 - accuracy: 0.5012 - val_loss: 7.7624 - val_accuracy: 0.5012\n",
      "Epoch 250/5000\n",
      "10780/10780 [==============================] - 0s 44us/sample - loss: 7.7636 - accuracy: 0.5012 - val_loss: 7.7630 - val_accuracy: 0.5012\n",
      "Epoch 251/5000\n",
      "10780/10780 [==============================] - 0s 44us/sample - loss: 7.7632 - accuracy: 0.5012 - val_loss: 7.7636 - val_accuracy: 0.5012\n",
      "Epoch 252/5000\n",
      "10780/10780 [==============================] - 0s 44us/sample - loss: 7.7644 - accuracy: 0.5012 - val_loss: 7.7713 - val_accuracy: 0.5012\n",
      "Epoch 253/5000\n",
      "10780/10780 [==============================] - 0s 44us/sample - loss: 7.7670 - accuracy: 0.5373 - val_loss: 7.7638 - val_accuracy: 1.0000\n",
      "Epoch 254/5000\n",
      "10780/10780 [==============================] - 0s 44us/sample - loss: 7.7668 - accuracy: 0.5245 - val_loss: 7.7648 - val_accuracy: 0.5012\n",
      "Epoch 255/5000\n",
      "10780/10780 [==============================] - 0s 44us/sample - loss: 7.7654 - accuracy: 0.5012 - val_loss: 7.7669 - val_accuracy: 0.5012\n",
      "Epoch 256/5000\n",
      "10780/10780 [==============================] - 0s 44us/sample - loss: 7.7654 - accuracy: 0.5012 - val_loss: 7.7630 - val_accuracy: 0.5013\n",
      "Epoch 257/5000\n",
      "10780/10780 [==============================] - 0s 44us/sample - loss: 7.7627 - accuracy: 0.5012 - val_loss: 7.7629 - val_accuracy: 0.5012\n",
      "Epoch 258/5000\n",
      "10780/10780 [==============================] - 0s 44us/sample - loss: 7.7677 - accuracy: 0.5012 - val_loss: 7.7643 - val_accuracy: 0.5013\n",
      "Epoch 259/5000\n",
      "10780/10780 [==============================] - 0s 44us/sample - loss: 7.7730 - accuracy: 0.5012 - val_loss: 7.7682 - val_accuracy: 0.5012\n",
      "Epoch 260/5000\n",
      "10780/10780 [==============================] - 0s 44us/sample - loss: 7.7666 - accuracy: 0.5939 - val_loss: 7.7662 - val_accuracy: 0.5013\n",
      "Epoch 261/5000\n",
      "10780/10780 [==============================] - 0s 44us/sample - loss: 7.7634 - accuracy: 0.5012 - val_loss: 7.7622 - val_accuracy: 0.5012\n",
      "Epoch 262/5000\n",
      "10780/10780 [==============================] - 0s 44us/sample - loss: 7.7632 - accuracy: 0.5012 - val_loss: 7.7632 - val_accuracy: 0.5012\n",
      "Epoch 263/5000\n",
      "10780/10780 [==============================] - 0s 44us/sample - loss: 7.7627 - accuracy: 0.5012 - val_loss: 7.7620 - val_accuracy: 0.5011\n",
      "Epoch 264/5000\n",
      "10780/10780 [==============================] - 0s 44us/sample - loss: 7.7625 - accuracy: 0.5245 - val_loss: 7.7642 - val_accuracy: 0.5012\n",
      "Epoch 265/5000\n",
      "10780/10780 [==============================] - 0s 44us/sample - loss: 7.7634 - accuracy: 0.5012 - val_loss: 7.7618 - val_accuracy: 0.5012\n",
      "Epoch 266/5000\n",
      "10780/10780 [==============================] - 0s 44us/sample - loss: 7.7677 - accuracy: 0.5012 - val_loss: 7.7629 - val_accuracy: 0.5012\n",
      "Epoch 267/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10780/10780 [==============================] - 0s 44us/sample - loss: 7.7641 - accuracy: 0.5241 - val_loss: 7.7633 - val_accuracy: 0.5012\n",
      "Epoch 268/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7633 - accuracy: 0.6397 - val_loss: 7.7620 - val_accuracy: 0.5012\n",
      "Epoch 269/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7634 - accuracy: 0.5475 - val_loss: 7.7687 - val_accuracy: 0.5012\n",
      "Epoch 270/5000\n",
      "10780/10780 [==============================] - 0s 31us/sample - loss: 7.7680 - accuracy: 0.5242 - val_loss: 7.7652 - val_accuracy: 0.5012\n",
      "Epoch 271/5000\n",
      "10780/10780 [==============================] - 1s 47us/sample - loss: 7.7654 - accuracy: 0.5012 - val_loss: 7.7635 - val_accuracy: 0.5012\n",
      "Epoch 272/5000\n",
      "10780/10780 [==============================] - 1s 47us/sample - loss: 7.7641 - accuracy: 0.5012 - val_loss: 7.7665 - val_accuracy: 0.5012\n",
      "Epoch 273/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7637 - accuracy: 0.5012 - val_loss: 7.7612 - val_accuracy: 0.5012\n",
      "Epoch 274/5000\n",
      "10780/10780 [==============================] - 0s 43us/sample - loss: 7.7625 - accuracy: 0.5012 - val_loss: 7.7631 - val_accuracy: 0.5012\n",
      "Epoch 275/5000\n",
      "10780/10780 [==============================] - 0s 44us/sample - loss: 7.7629 - accuracy: 0.5012 - val_loss: 7.7633 - val_accuracy: 0.5012\n",
      "Epoch 276/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7634 - accuracy: 0.5012 - val_loss: 7.7621 - val_accuracy: 0.5012\n",
      "Epoch 277/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7631 - accuracy: 0.5012 - val_loss: 7.7640 - val_accuracy: 0.5012\n",
      "Epoch 278/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7625 - accuracy: 0.5012 - val_loss: 7.7620 - val_accuracy: 0.5012\n",
      "Epoch 279/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7641 - accuracy: 0.5012 - val_loss: 7.7638 - val_accuracy: 0.5013\n",
      "Epoch 280/5000\n",
      "10780/10780 [==============================] - 0s 43us/sample - loss: 7.7625 - accuracy: 0.5943 - val_loss: 7.7617 - val_accuracy: 0.5012\n",
      "Epoch 281/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7657 - accuracy: 0.5012 - val_loss: 7.7631 - val_accuracy: 0.5012\n",
      "Epoch 282/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7628 - accuracy: 0.5012 - val_loss: 7.7617 - val_accuracy: 0.5012\n",
      "Epoch 283/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7623 - accuracy: 0.5475 - val_loss: 7.7624 - val_accuracy: 0.5012\n",
      "Epoch 284/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7628 - accuracy: 0.5704 - val_loss: 7.7633 - val_accuracy: 0.5012\n",
      "Epoch 285/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7630 - accuracy: 0.5012 - val_loss: 7.7633 - val_accuracy: 0.5012\n",
      "Epoch 286/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7625 - accuracy: 0.5707 - val_loss: 7.7626 - val_accuracy: 0.5012\n",
      "Epoch 287/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7640 - accuracy: 0.5012 - val_loss: 7.7637 - val_accuracy: 0.5012\n",
      "Epoch 288/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7634 - accuracy: 0.5012 - val_loss: 7.7664 - val_accuracy: 0.5012\n",
      "Epoch 289/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7649 - accuracy: 0.5371 - val_loss: 7.7688 - val_accuracy: 0.5012\n",
      "Epoch 290/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7666 - accuracy: 0.5012 - val_loss: 7.7647 - val_accuracy: 0.5012\n",
      "Epoch 291/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7644 - accuracy: 0.5012 - val_loss: 7.7635 - val_accuracy: 0.5012\n",
      "Epoch 292/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7629 - accuracy: 0.5012 - val_loss: 7.7620 - val_accuracy: 0.5012\n",
      "Epoch 293/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7645 - accuracy: 0.5012 - val_loss: 7.7648 - val_accuracy: 0.5012\n",
      "Epoch 294/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7654 - accuracy: 0.5708 - val_loss: 7.7652 - val_accuracy: 0.5013\n",
      "Epoch 295/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7666 - accuracy: 0.5012 - val_loss: 7.7637 - val_accuracy: 0.5012\n",
      "Epoch 296/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7634 - accuracy: 0.5012 - val_loss: 7.7628 - val_accuracy: 0.5012\n",
      "Epoch 297/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7626 - accuracy: 0.5703 - val_loss: 7.7636 - val_accuracy: 0.5012\n",
      "Epoch 298/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7643 - accuracy: 0.5012 - val_loss: 7.7642 - val_accuracy: 0.5012\n",
      "Epoch 299/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7639 - accuracy: 0.5012 - val_loss: 7.7628 - val_accuracy: 0.5012\n",
      "Epoch 300/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7637 - accuracy: 0.5705 - val_loss: 7.7674 - val_accuracy: 0.5012\n",
      "Epoch 301/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7713 - accuracy: 0.5012 - val_loss: 7.7683 - val_accuracy: 0.5012\n",
      "Epoch 302/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7670 - accuracy: 0.5239 - val_loss: 7.7687 - val_accuracy: 0.5011\n",
      "Epoch 303/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7653 - accuracy: 0.5012 - val_loss: 7.7684 - val_accuracy: 0.5012\n",
      "Epoch 304/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7658 - accuracy: 0.5012 - val_loss: 7.7642 - val_accuracy: 0.5012\n",
      "Epoch 305/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7625 - accuracy: 0.5012 - val_loss: 7.7629 - val_accuracy: 0.5012\n",
      "Epoch 306/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7645 - accuracy: 0.5012 - val_loss: 7.7636 - val_accuracy: 0.5012\n",
      "Epoch 307/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7635 - accuracy: 0.5012 - val_loss: 7.7674 - val_accuracy: 0.5012\n",
      "Epoch 308/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7640 - accuracy: 0.5243 - val_loss: 7.7637 - val_accuracy: 0.5012\n",
      "Epoch 309/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7659 - accuracy: 0.5012 - val_loss: 7.7647 - val_accuracy: 0.5012\n",
      "Epoch 310/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7635 - accuracy: 0.5012 - val_loss: 7.7623 - val_accuracy: 0.5012\n",
      "Epoch 311/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7642 - accuracy: 0.5012 - val_loss: 7.7653 - val_accuracy: 0.5012\n",
      "Epoch 312/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7668 - accuracy: 0.5012 - val_loss: 7.7644 - val_accuracy: 0.5012\n",
      "Epoch 313/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7668 - accuracy: 0.5373 - val_loss: 7.7652 - val_accuracy: 1.0000\n",
      "Epoch 314/5000\n",
      "10780/10780 [==============================] - 0s 31us/sample - loss: 7.7649 - accuracy: 0.5479 - val_loss: 7.7626 - val_accuracy: 0.5012\n",
      "Epoch 315/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7631 - accuracy: 0.5012 - val_loss: 7.7632 - val_accuracy: 0.5012\n",
      "Epoch 316/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7630 - accuracy: 0.5012 - val_loss: 7.7641 - val_accuracy: 0.5012\n",
      "Epoch 317/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7632 - accuracy: 0.5012 - val_loss: 7.7616 - val_accuracy: 0.5012\n",
      "Epoch 318/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7634 - accuracy: 0.6165 - val_loss: 7.7675 - val_accuracy: 0.5012\n",
      "Epoch 319/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7669 - accuracy: 0.5012 - val_loss: 7.7654 - val_accuracy: 0.5012\n",
      "Epoch 320/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7654 - accuracy: 0.5012 - val_loss: 7.7637 - val_accuracy: 0.5012\n",
      "Epoch 321/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7645 - accuracy: 0.5012 - val_loss: 7.7629 - val_accuracy: 0.5012\n",
      "Epoch 322/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7626 - accuracy: 0.5012 - val_loss: 7.7626 - val_accuracy: 0.5012\n",
      "Epoch 323/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7629 - accuracy: 0.5012 - val_loss: 7.7619 - val_accuracy: 0.5012\n",
      "Epoch 324/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7626 - accuracy: 0.5012 - val_loss: 7.7639 - val_accuracy: 0.5011\n",
      "Epoch 325/5000\n",
      "10780/10780 [==============================] - 0s 43us/sample - loss: 7.7630 - accuracy: 0.5012 - val_loss: 7.7636 - val_accuracy: 0.5012\n",
      "Epoch 326/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7631 - accuracy: 0.5246 - val_loss: 7.7626 - val_accuracy: 0.5012\n",
      "Epoch 327/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7634 - accuracy: 0.5012 - val_loss: 7.7666 - val_accuracy: 0.5012\n",
      "Epoch 328/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7635 - accuracy: 0.5012 - val_loss: 7.7641 - val_accuracy: 0.5012\n",
      "Epoch 329/5000\n",
      "10780/10780 [==============================] - 0s 31us/sample - loss: 7.7632 - accuracy: 0.5012 - val_loss: 7.7654 - val_accuracy: 0.5012\n",
      "Epoch 330/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7629 - accuracy: 0.5012 - val_loss: 7.7643 - val_accuracy: 0.5011\n",
      "Epoch 331/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7627 - accuracy: 0.5012 - val_loss: 7.7645 - val_accuracy: 0.5012\n",
      "Epoch 332/5000\n",
      "10780/10780 [==============================] - 0s 32us/sample - loss: 7.7638 - accuracy: 0.5012 - val_loss: 7.7620 - val_accuracy: 0.5011\n",
      "Epoch 333/5000\n",
      "10780/10780 [==============================] - 0s 32us/sample - loss: 7.7673 - accuracy: 0.5012 - val_loss: 7.7659 - val_accuracy: 0.5011\n",
      "Epoch 334/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7646 - accuracy: 0.5012 - val_loss: 7.7654 - val_accuracy: 0.5011\n",
      "Epoch 335/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7647 - accuracy: 0.5012 - val_loss: 7.7637 - val_accuracy: 0.5012\n",
      "Epoch 336/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7635 - accuracy: 0.5012 - val_loss: 7.7622 - val_accuracy: 0.5012\n",
      "Epoch 337/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7635 - accuracy: 0.5145 - val_loss: 7.7664 - val_accuracy: 1.0000\n",
      "Epoch 338/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7652 - accuracy: 0.5939 - val_loss: 7.7639 - val_accuracy: 0.5012\n",
      "Epoch 339/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7645 - accuracy: 0.5012 - val_loss: 7.7628 - val_accuracy: 0.5011\n",
      "Epoch 340/5000\n",
      "10780/10780 [==============================] - 0s 29us/sample - loss: 7.7628 - accuracy: 0.5012 - val_loss: 7.7627 - val_accuracy: 0.5012\n",
      "Epoch 341/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7636 - accuracy: 0.5012 - val_loss: 7.7639 - val_accuracy: 0.5012\n",
      "Epoch 342/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7629 - accuracy: 0.5012 - val_loss: 7.7624 - val_accuracy: 0.5012\n",
      "Epoch 343/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7655 - accuracy: 0.5012 - val_loss: 7.7620 - val_accuracy: 0.5012\n",
      "Epoch 344/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7638 - accuracy: 0.5012 - val_loss: 7.7637 - val_accuracy: 0.5012\n",
      "Epoch 345/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7638 - accuracy: 0.5012 - val_loss: 7.7658 - val_accuracy: 0.5012\n",
      "Epoch 346/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7639 - accuracy: 0.5012 - val_loss: 7.7683 - val_accuracy: 0.5012\n",
      "Epoch 347/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7680 - accuracy: 0.5012 - val_loss: 7.7632 - val_accuracy: 0.5012\n",
      "Epoch 348/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7636 - accuracy: 0.5012 - val_loss: 7.7619 - val_accuracy: 0.5011\n",
      "Epoch 349/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7624 - accuracy: 0.5012 - val_loss: 7.7629 - val_accuracy: 0.5012\n",
      "Epoch 350/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7627 - accuracy: 0.5012 - val_loss: 7.7622 - val_accuracy: 0.5012\n",
      "Epoch 351/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7648 - accuracy: 0.5012 - val_loss: 7.7715 - val_accuracy: 0.5011\n",
      "Epoch 352/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7658 - accuracy: 0.5012 - val_loss: 7.7616 - val_accuracy: 0.5012\n",
      "Epoch 353/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7637 - accuracy: 0.5012 - val_loss: 7.7665 - val_accuracy: 0.5012\n",
      "Epoch 354/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7652 - accuracy: 0.5012 - val_loss: 7.7630 - val_accuracy: 0.5012\n",
      "Epoch 355/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7633 - accuracy: 0.5012 - val_loss: 7.7632 - val_accuracy: 0.5012\n",
      "Epoch 356/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7648 - accuracy: 0.6297 - val_loss: 7.7643 - val_accuracy: 0.5012\n",
      "Epoch 357/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7630 - accuracy: 0.5477 - val_loss: 7.7632 - val_accuracy: 0.5012\n",
      "Epoch 358/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7634 - accuracy: 0.5012 - val_loss: 7.7636 - val_accuracy: 0.5012\n",
      "Epoch 359/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7635 - accuracy: 0.5012 - val_loss: 7.7627 - val_accuracy: 0.5012\n",
      "Epoch 360/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7628 - accuracy: 0.5141 - val_loss: 7.7621 - val_accuracy: 1.0000\n",
      "Epoch 361/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7629 - accuracy: 0.5246 - val_loss: 7.7614 - val_accuracy: 0.5012\n",
      "Epoch 362/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7642 - accuracy: 0.5012 - val_loss: 7.7724 - val_accuracy: 0.5012\n",
      "Epoch 363/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7702 - accuracy: 0.5012 - val_loss: 7.7756 - val_accuracy: 0.5011\n",
      "Epoch 364/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7708 - accuracy: 0.5012 - val_loss: 7.7646 - val_accuracy: 0.5012\n",
      "Epoch 365/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7637 - accuracy: 0.5012 - val_loss: 7.7623 - val_accuracy: 0.5012\n",
      "Epoch 366/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7630 - accuracy: 0.5012 - val_loss: 7.7615 - val_accuracy: 0.5012\n",
      "Epoch 367/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7640 - accuracy: 0.5244 - val_loss: 7.7641 - val_accuracy: 0.5012\n",
      "Epoch 368/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7630 - accuracy: 0.5245 - val_loss: 7.7619 - val_accuracy: 0.5012\n",
      "Epoch 369/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7658 - accuracy: 0.5012 - val_loss: 7.7707 - val_accuracy: 0.5012\n",
      "Epoch 370/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7652 - accuracy: 0.5012 - val_loss: 7.7659 - val_accuracy: 0.5012\n",
      "Epoch 371/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7652 - accuracy: 0.5012 - val_loss: 7.7628 - val_accuracy: 0.5012\n",
      "Epoch 372/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7630 - accuracy: 0.5239 - val_loss: 7.7638 - val_accuracy: 0.5011\n",
      "Epoch 373/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7632 - accuracy: 0.5012 - val_loss: 7.7635 - val_accuracy: 0.5012\n",
      "Epoch 374/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7628 - accuracy: 0.5012 - val_loss: 7.7615 - val_accuracy: 0.5012\n",
      "Epoch 375/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7630 - accuracy: 0.5012 - val_loss: 7.7627 - val_accuracy: 0.5012\n",
      "Epoch 376/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7635 - accuracy: 0.5012 - val_loss: 7.7642 - val_accuracy: 0.5011\n",
      "Epoch 377/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7640 - accuracy: 0.5012 - val_loss: 7.7684 - val_accuracy: 0.5011\n",
      "Epoch 378/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7685 - accuracy: 0.5012 - val_loss: 7.7628 - val_accuracy: 0.5011\n",
      "Epoch 379/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7640 - accuracy: 0.5012 - val_loss: 7.7631 - val_accuracy: 0.5011\n",
      "Epoch 380/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7623 - accuracy: 0.5012 - val_loss: 7.7631 - val_accuracy: 0.5012\n",
      "Epoch 381/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7640 - accuracy: 0.5012 - val_loss: 7.7650 - val_accuracy: 0.5012\n",
      "Epoch 382/5000\n",
      "10780/10780 [==============================] - 1s 50us/sample - loss: 7.7633 - accuracy: 0.5143 - val_loss: 7.7655 - val_accuracy: 0.5012\n",
      "Epoch 383/5000\n",
      "10780/10780 [==============================] - 1s 51us/sample - loss: 7.7653 - accuracy: 0.5939 - val_loss: 7.7626 - val_accuracy: 0.5012\n",
      "Epoch 384/5000\n",
      "10780/10780 [==============================] - 1s 50us/sample - loss: 7.7643 - accuracy: 0.5702 - val_loss: 7.7684 - val_accuracy: 0.5012\n",
      "Epoch 385/5000\n",
      "10780/10780 [==============================] - 0s 43us/sample - loss: 7.7638 - accuracy: 0.5012 - val_loss: 7.7624 - val_accuracy: 0.5012\n",
      "Epoch 386/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7627 - accuracy: 0.5012 - val_loss: 7.7627 - val_accuracy: 0.5012\n",
      "Epoch 387/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7626 - accuracy: 0.5012 - val_loss: 7.7646 - val_accuracy: 0.5011\n",
      "Epoch 388/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7669 - accuracy: 0.5012 - val_loss: 7.7652 - val_accuracy: 0.5012\n",
      "Epoch 389/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7643 - accuracy: 0.5012 - val_loss: 7.7628 - val_accuracy: 0.5011\n",
      "Epoch 390/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7625 - accuracy: 0.5012 - val_loss: 7.7642 - val_accuracy: 0.5011\n",
      "Epoch 391/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7633 - accuracy: 0.6069 - val_loss: 7.7657 - val_accuracy: 0.5012\n",
      "Epoch 392/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7667 - accuracy: 0.5012 - val_loss: 7.7667 - val_accuracy: 0.5012\n",
      "Epoch 393/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7634 - accuracy: 0.5242 - val_loss: 7.7618 - val_accuracy: 1.0000\n",
      "Epoch 394/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7629 - accuracy: 0.5243 - val_loss: 7.7628 - val_accuracy: 0.5012\n",
      "Epoch 395/5000\n",
      "10780/10780 [==============================] - 0s 32us/sample - loss: 7.7650 - accuracy: 0.5481 - val_loss: 7.7619 - val_accuracy: 0.5012\n",
      "Epoch 396/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7645 - accuracy: 0.5012 - val_loss: 7.7667 - val_accuracy: 0.5012\n",
      "Epoch 397/5000\n",
      "10780/10780 [==============================] - 1s 47us/sample - loss: 7.7653 - accuracy: 0.5012 - val_loss: 7.7619 - val_accuracy: 0.5012\n",
      "Epoch 398/5000\n",
      "10780/10780 [==============================] - 1s 47us/sample - loss: 7.7628 - accuracy: 0.5012 - val_loss: 7.7624 - val_accuracy: 0.5012\n",
      "Epoch 399/5000\n",
      "10780/10780 [==============================] - 1s 47us/sample - loss: 7.7641 - accuracy: 0.5944 - val_loss: 7.7637 - val_accuracy: 0.5012\n",
      "Epoch 400/5000\n",
      "10780/10780 [==============================] - 1s 47us/sample - loss: 7.7629 - accuracy: 0.5012 - val_loss: 7.7635 - val_accuracy: 1.0000\n",
      "Epoch 401/5000\n",
      "10780/10780 [==============================] - 1s 47us/sample - loss: 7.7633 - accuracy: 0.5477 - val_loss: 7.7626 - val_accuracy: 0.5012\n",
      "Epoch 402/5000\n",
      "10780/10780 [==============================] - 1s 47us/sample - loss: 7.7631 - accuracy: 0.5012 - val_loss: 7.7612 - val_accuracy: 0.5012\n",
      "Epoch 403/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7628 - accuracy: 0.5012 - val_loss: 7.7643 - val_accuracy: 0.5012\n",
      "Epoch 404/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7657 - accuracy: 0.5012 - val_loss: 7.7649 - val_accuracy: 0.5012\n",
      "Epoch 405/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7654 - accuracy: 0.5012 - val_loss: 7.7643 - val_accuracy: 0.5012\n",
      "Epoch 406/5000\n",
      "10780/10780 [==============================] - 0s 44us/sample - loss: 7.7643 - accuracy: 0.5012 - val_loss: 7.7629 - val_accuracy: 0.5012\n",
      "Epoch 407/5000\n",
      "10780/10780 [==============================] - 0s 44us/sample - loss: 7.7654 - accuracy: 0.6406 - val_loss: 7.7658 - val_accuracy: 0.5012\n",
      "Epoch 408/5000\n",
      "10780/10780 [==============================] - 0s 44us/sample - loss: 7.7643 - accuracy: 0.5012 - val_loss: 7.7644 - val_accuracy: 0.5012\n",
      "Epoch 409/5000\n",
      "10780/10780 [==============================] - 0s 45us/sample - loss: 7.7645 - accuracy: 0.5012 - val_loss: 7.7626 - val_accuracy: 0.5012\n",
      "Epoch 410/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7626 - accuracy: 0.5012 - val_loss: 7.7633 - val_accuracy: 0.5012\n",
      "Epoch 411/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7632 - accuracy: 0.5012 - val_loss: 7.7630 - val_accuracy: 0.5012\n",
      "Epoch 412/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7627 - accuracy: 0.5012 - val_loss: 7.7613 - val_accuracy: 0.5012\n",
      "Epoch 413/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7634 - accuracy: 0.5012 - val_loss: 7.7624 - val_accuracy: 0.5012\n",
      "Epoch 414/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7624 - accuracy: 0.5012 - val_loss: 7.7629 - val_accuracy: 0.5012\n",
      "Epoch 415/5000\n",
      "10780/10780 [==============================] - 0s 45us/sample - loss: 7.7637 - accuracy: 0.5242 - val_loss: 7.7628 - val_accuracy: 0.5012\n",
      "Epoch 416/5000\n",
      "10780/10780 [==============================] - 1s 49us/sample - loss: 7.7628 - accuracy: 0.5012 - val_loss: 7.7624 - val_accuracy: 0.5012\n",
      "Epoch 417/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7632 - accuracy: 0.5604 - val_loss: 7.7666 - val_accuracy: 0.5012\n",
      "Epoch 418/5000\n",
      "10780/10780 [==============================] - 0s 44us/sample - loss: 7.7635 - accuracy: 0.5012 - val_loss: 7.7638 - val_accuracy: 0.5012\n",
      "Epoch 419/5000\n",
      "10780/10780 [==============================] - 0s 45us/sample - loss: 7.7632 - accuracy: 0.5012 - val_loss: 7.7628 - val_accuracy: 0.5012\n",
      "Epoch 420/5000\n",
      "10780/10780 [==============================] - 0s 45us/sample - loss: 7.7622 - accuracy: 0.5012 - val_loss: 7.7644 - val_accuracy: 0.5012\n",
      "Epoch 421/5000\n",
      "10780/10780 [==============================] - 0s 46us/sample - loss: 7.7666 - accuracy: 0.5012 - val_loss: 7.7638 - val_accuracy: 0.5012\n",
      "Epoch 422/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7630 - accuracy: 0.5473 - val_loss: 7.7678 - val_accuracy: 0.5012\n",
      "Epoch 423/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7648 - accuracy: 0.5243 - val_loss: 7.7633 - val_accuracy: 0.5012\n",
      "Epoch 424/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7630 - accuracy: 0.5012 - val_loss: 7.7624 - val_accuracy: 0.5012\n",
      "Epoch 425/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7627 - accuracy: 0.5012 - val_loss: 7.7618 - val_accuracy: 0.5012\n",
      "Epoch 426/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7624 - accuracy: 0.5012 - val_loss: 7.7613 - val_accuracy: 0.5012\n",
      "Epoch 427/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7624 - accuracy: 0.5012 - val_loss: 7.7623 - val_accuracy: 0.5012\n",
      "Epoch 428/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7623 - accuracy: 0.5012 - val_loss: 7.7614 - val_accuracy: 0.5012\n",
      "Epoch 429/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7648 - accuracy: 0.5012 - val_loss: 7.7630 - val_accuracy: 0.5012\n",
      "Epoch 430/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7635 - accuracy: 0.5012 - val_loss: 7.7633 - val_accuracy: 0.5012\n",
      "Epoch 431/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7630 - accuracy: 0.5012 - val_loss: 7.7639 - val_accuracy: 0.5012\n",
      "Epoch 432/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7656 - accuracy: 0.5012 - val_loss: 7.7642 - val_accuracy: 0.5012\n",
      "Epoch 433/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7626 - accuracy: 0.5012 - val_loss: 7.7640 - val_accuracy: 0.5012\n",
      "Epoch 434/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7632 - accuracy: 0.5012 - val_loss: 7.7635 - val_accuracy: 0.5012\n",
      "Epoch 435/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7630 - accuracy: 0.5012 - val_loss: 7.7627 - val_accuracy: 0.5012\n",
      "Epoch 436/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7629 - accuracy: 0.5374 - val_loss: 7.7630 - val_accuracy: 1.0000\n",
      "Epoch 437/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7627 - accuracy: 0.5243 - val_loss: 7.7618 - val_accuracy: 0.5012\n",
      "Epoch 438/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7625 - accuracy: 0.5248 - val_loss: 7.7616 - val_accuracy: 0.5012\n",
      "Epoch 439/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7631 - accuracy: 0.5012 - val_loss: 7.7655 - val_accuracy: 0.5012\n",
      "Epoch 440/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7661 - accuracy: 0.5476 - val_loss: 7.7643 - val_accuracy: 0.5012\n",
      "Epoch 441/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7658 - accuracy: 0.5012 - val_loss: 7.7655 - val_accuracy: 0.5012\n",
      "Epoch 442/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7634 - accuracy: 0.5705 - val_loss: 7.7614 - val_accuracy: 0.5012\n",
      "Epoch 443/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7629 - accuracy: 0.5947 - val_loss: 7.7633 - val_accuracy: 0.5012\n",
      "Epoch 444/5000\n",
      "10780/10780 [==============================] - 0s 32us/sample - loss: 7.7630 - accuracy: 0.5012 - val_loss: 7.7616 - val_accuracy: 0.5012\n",
      "Epoch 445/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7621 - accuracy: 0.5012 - val_loss: 7.7622 - val_accuracy: 0.5012\n",
      "Epoch 446/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7624 - accuracy: 0.5707 - val_loss: 7.7622 - val_accuracy: 0.5012\n",
      "Epoch 447/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7627 - accuracy: 0.5012 - val_loss: 7.7634 - val_accuracy: 0.5012\n",
      "Epoch 448/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7630 - accuracy: 0.5012 - val_loss: 7.7653 - val_accuracy: 0.5011\n",
      "Epoch 449/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7656 - accuracy: 0.5943 - val_loss: 7.7618 - val_accuracy: 0.5012\n",
      "Epoch 450/5000\n",
      "10780/10780 [==============================] - 0s 43us/sample - loss: 7.7630 - accuracy: 0.5012 - val_loss: 7.7658 - val_accuracy: 0.5013\n",
      "Epoch 451/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7654 - accuracy: 0.5012 - val_loss: 7.7628 - val_accuracy: 0.5012\n",
      "Epoch 452/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7647 - accuracy: 0.5012 - val_loss: 7.7626 - val_accuracy: 0.5012\n",
      "Epoch 453/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7635 - accuracy: 0.5012 - val_loss: 7.7623 - val_accuracy: 0.5012\n",
      "Epoch 454/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7631 - accuracy: 0.5012 - val_loss: 7.7639 - val_accuracy: 0.5012\n",
      "Epoch 455/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7643 - accuracy: 0.5012 - val_loss: 7.7622 - val_accuracy: 0.5011\n",
      "Epoch 456/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7635 - accuracy: 0.5012 - val_loss: 7.7616 - val_accuracy: 0.5012\n",
      "Epoch 457/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7627 - accuracy: 0.5012 - val_loss: 7.7639 - val_accuracy: 0.5012\n",
      "Epoch 458/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7632 - accuracy: 0.5941 - val_loss: 7.7627 - val_accuracy: 0.5012\n",
      "Epoch 459/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7628 - accuracy: 0.5012 - val_loss: 7.7615 - val_accuracy: 0.5012\n",
      "Epoch 460/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7670 - accuracy: 0.5012 - val_loss: 7.7710 - val_accuracy: 0.5013\n",
      "Epoch 461/5000\n",
      "10780/10780 [==============================] - 1s 49us/sample - loss: 7.7661 - accuracy: 0.5012 - val_loss: 7.7632 - val_accuracy: 0.5011\n",
      "Epoch 462/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7634 - accuracy: 0.5708 - val_loss: 7.7626 - val_accuracy: 0.5012\n",
      "Epoch 463/5000\n",
      "10780/10780 [==============================] - 1s 48us/sample - loss: 7.7635 - accuracy: 0.5246 - val_loss: 7.7624 - val_accuracy: 0.5011\n",
      "Epoch 464/5000\n",
      "10780/10780 [==============================] - 1s 52us/sample - loss: 7.7628 - accuracy: 0.5012 - val_loss: 7.7641 - val_accuracy: 0.5012\n",
      "Epoch 465/5000\n",
      "10780/10780 [==============================] - 1s 53us/sample - loss: 7.7630 - accuracy: 0.5012 - val_loss: 7.7615 - val_accuracy: 0.5012\n",
      "Epoch 466/5000\n",
      "10780/10780 [==============================] - 1s 50us/sample - loss: 7.7636 - accuracy: 0.5012 - val_loss: 7.7627 - val_accuracy: 0.5012\n",
      "Epoch 467/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7630 - accuracy: 0.5245 - val_loss: 7.7634 - val_accuracy: 0.5012\n",
      "Epoch 468/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7635 - accuracy: 0.5939 - val_loss: 7.7628 - val_accuracy: 0.5012\n",
      "Epoch 469/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7633 - accuracy: 0.5012 - val_loss: 7.7634 - val_accuracy: 0.5012\n",
      "Epoch 470/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7638 - accuracy: 0.4809 - val_loss: 7.7625 - val_accuracy: 0.5016\n",
      "Epoch 471/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7640 - accuracy: 0.4778 - val_loss: 7.7673 - val_accuracy: 0.5007\n",
      "Epoch 472/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7631 - accuracy: 0.5011 - val_loss: 7.7620 - val_accuracy: 0.5011\n",
      "Epoch 473/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7652 - accuracy: 0.5011 - val_loss: 7.7639 - val_accuracy: 0.5011\n",
      "Epoch 474/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7635 - accuracy: 0.5011 - val_loss: 7.7625 - val_accuracy: 0.5011\n",
      "Epoch 475/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7636 - accuracy: 0.5011 - val_loss: 7.7641 - val_accuracy: 0.5012\n",
      "Epoch 476/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7631 - accuracy: 0.5705 - val_loss: 7.7627 - val_accuracy: 0.5011\n",
      "Epoch 477/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7627 - accuracy: 0.5475 - val_loss: 7.7616 - val_accuracy: 0.5011\n",
      "Epoch 478/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7655 - accuracy: 0.5012 - val_loss: 7.7654 - val_accuracy: 0.5011\n",
      "Epoch 479/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10780/10780 [==============================] - 0s 44us/sample - loss: 7.7643 - accuracy: 0.6062 - val_loss: 7.7698 - val_accuracy: 0.5012\n",
      "Epoch 480/5000\n",
      "10780/10780 [==============================] - 0s 44us/sample - loss: 7.7669 - accuracy: 0.5012 - val_loss: 7.7629 - val_accuracy: 0.5011\n",
      "Epoch 481/5000\n",
      "10780/10780 [==============================] - 0s 44us/sample - loss: 7.7665 - accuracy: 0.5012 - val_loss: 7.7723 - val_accuracy: 0.5011\n",
      "Epoch 482/5000\n",
      "10780/10780 [==============================] - 0s 44us/sample - loss: 7.7655 - accuracy: 0.5012 - val_loss: 7.7628 - val_accuracy: 0.5012\n",
      "Epoch 483/5000\n",
      "10780/10780 [==============================] - 0s 44us/sample - loss: 7.7625 - accuracy: 0.5012 - val_loss: 7.7621 - val_accuracy: 0.5012\n",
      "Epoch 484/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7632 - accuracy: 0.5012 - val_loss: 7.7666 - val_accuracy: 0.5012\n",
      "Epoch 485/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7652 - accuracy: 0.5012 - val_loss: 7.7693 - val_accuracy: 0.5012\n",
      "Epoch 486/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7653 - accuracy: 0.5012 - val_loss: 7.7632 - val_accuracy: 0.5012\n",
      "Epoch 487/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7626 - accuracy: 0.5243 - val_loss: 7.7628 - val_accuracy: 0.5012\n",
      "Epoch 488/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7623 - accuracy: 0.5012 - val_loss: 7.7620 - val_accuracy: 0.5012\n",
      "Epoch 489/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7644 - accuracy: 0.5012 - val_loss: 7.7713 - val_accuracy: 0.5012\n",
      "Epoch 490/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7644 - accuracy: 0.5012 - val_loss: 7.7614 - val_accuracy: 0.5012\n",
      "Epoch 491/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7629 - accuracy: 0.5012 - val_loss: 7.7618 - val_accuracy: 0.5012\n",
      "Epoch 492/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7624 - accuracy: 0.5012 - val_loss: 7.7629 - val_accuracy: 0.5012\n",
      "Epoch 493/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7632 - accuracy: 0.5012 - val_loss: 7.7642 - val_accuracy: 0.5012\n",
      "Epoch 494/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7635 - accuracy: 0.5012 - val_loss: 7.7608 - val_accuracy: 0.5012\n",
      "Epoch 495/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7624 - accuracy: 0.5012 - val_loss: 7.7628 - val_accuracy: 0.5012\n",
      "Epoch 496/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7622 - accuracy: 0.5012 - val_loss: 7.7625 - val_accuracy: 0.5012\n",
      "Epoch 497/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7637 - accuracy: 0.5012 - val_loss: 7.7638 - val_accuracy: 0.5012\n",
      "Epoch 498/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7646 - accuracy: 0.5012 - val_loss: 7.7632 - val_accuracy: 0.5011\n",
      "Epoch 499/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7636 - accuracy: 0.6160 - val_loss: 7.7671 - val_accuracy: 0.5012\n",
      "Epoch 500/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7633 - accuracy: 0.5012 - val_loss: 7.7621 - val_accuracy: 0.5012\n",
      "Epoch 501/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7629 - accuracy: 0.5012 - val_loss: 7.7656 - val_accuracy: 0.5012\n",
      "Epoch 502/5000\n",
      "10780/10780 [==============================] - 0s 44us/sample - loss: 7.7646 - accuracy: 0.5012 - val_loss: 7.7617 - val_accuracy: 0.5012\n",
      "Epoch 503/5000\n",
      "10780/10780 [==============================] - 0s 44us/sample - loss: 7.7626 - accuracy: 0.5012 - val_loss: 7.7653 - val_accuracy: 0.5012\n",
      "Epoch 504/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7659 - accuracy: 0.5704 - val_loss: 7.7642 - val_accuracy: 0.5012\n",
      "Epoch 505/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7663 - accuracy: 0.5012 - val_loss: 7.7666 - val_accuracy: 0.5012\n",
      "Epoch 506/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7663 - accuracy: 0.5012 - val_loss: 7.7650 - val_accuracy: 0.5012\n",
      "Epoch 507/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7668 - accuracy: 0.5012 - val_loss: 7.7690 - val_accuracy: 0.5012\n",
      "Epoch 508/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7645 - accuracy: 0.5478 - val_loss: 7.7638 - val_accuracy: 0.5012\n",
      "Epoch 509/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7633 - accuracy: 0.5012 - val_loss: 7.7648 - val_accuracy: 0.5012\n",
      "Epoch 510/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7640 - accuracy: 0.5246 - val_loss: 7.7691 - val_accuracy: 0.5012\n",
      "Epoch 511/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7659 - accuracy: 0.5012 - val_loss: 7.7665 - val_accuracy: 0.5012\n",
      "Epoch 512/5000\n",
      "10780/10780 [==============================] - 0s 29us/sample - loss: 7.7634 - accuracy: 0.5012 - val_loss: 7.7629 - val_accuracy: 0.5011\n",
      "Epoch 513/5000\n",
      "10780/10780 [==============================] - 0s 45us/sample - loss: 7.7636 - accuracy: 0.5012 - val_loss: 7.7632 - val_accuracy: 0.5012\n",
      "Epoch 514/5000\n",
      "10780/10780 [==============================] - 1s 50us/sample - loss: 7.7655 - accuracy: 0.5012 - val_loss: 7.7623 - val_accuracy: 0.5012\n",
      "Epoch 515/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7655 - accuracy: 0.5012 - val_loss: 7.7685 - val_accuracy: 0.5012\n",
      "Epoch 516/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7649 - accuracy: 0.5012 - val_loss: 7.7647 - val_accuracy: 0.5012\n",
      "Epoch 517/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7655 - accuracy: 0.5012 - val_loss: 7.7637 - val_accuracy: 0.5012\n",
      "Epoch 518/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7632 - accuracy: 0.5012 - val_loss: 7.7619 - val_accuracy: 0.5012\n",
      "Epoch 519/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7631 - accuracy: 0.5012 - val_loss: 7.7627 - val_accuracy: 0.5012\n",
      "Epoch 520/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7633 - accuracy: 0.5012 - val_loss: 7.7640 - val_accuracy: 0.5012\n",
      "Epoch 521/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7630 - accuracy: 0.5012 - val_loss: 7.7625 - val_accuracy: 0.5012\n",
      "Epoch 522/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7629 - accuracy: 0.5012 - val_loss: 7.7677 - val_accuracy: 0.5011\n",
      "Epoch 523/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7676 - accuracy: 0.5012 - val_loss: 7.7703 - val_accuracy: 0.5012\n",
      "Epoch 524/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7671 - accuracy: 0.5937 - val_loss: 7.7640 - val_accuracy: 0.5012\n",
      "Epoch 525/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7632 - accuracy: 0.5243 - val_loss: 7.7613 - val_accuracy: 0.5012\n",
      "Epoch 526/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7647 - accuracy: 0.5012 - val_loss: 7.7700 - val_accuracy: 0.5012\n",
      "Epoch 527/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7653 - accuracy: 0.5012 - val_loss: 7.7643 - val_accuracy: 0.5012\n",
      "Epoch 528/5000\n",
      "10780/10780 [==============================] - 0s 31us/sample - loss: 7.7634 - accuracy: 0.5012 - val_loss: 7.7616 - val_accuracy: 0.5012\n",
      "Epoch 529/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7631 - accuracy: 0.5012 - val_loss: 7.7633 - val_accuracy: 0.5012\n",
      "Epoch 530/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7622 - accuracy: 0.5012 - val_loss: 7.7639 - val_accuracy: 0.5011\n",
      "Epoch 531/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7649 - accuracy: 0.5012 - val_loss: 7.7689 - val_accuracy: 0.5012\n",
      "Epoch 532/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7654 - accuracy: 0.5012 - val_loss: 7.7621 - val_accuracy: 0.5012\n",
      "Epoch 533/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7623 - accuracy: 0.5012 - val_loss: 7.7635 - val_accuracy: 0.5012\n",
      "Epoch 534/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7622 - accuracy: 0.5012 - val_loss: 7.7615 - val_accuracy: 1.0000\n",
      "Epoch 535/5000\n",
      "10780/10780 [==============================] - 0s 30us/sample - loss: 7.7636 - accuracy: 0.5474 - val_loss: 7.7660 - val_accuracy: 0.5012\n",
      "Epoch 536/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7680 - accuracy: 0.5012 - val_loss: 7.7629 - val_accuracy: 0.5012\n",
      "Epoch 537/5000\n",
      "10780/10780 [==============================] - 0s 32us/sample - loss: 7.7668 - accuracy: 0.5012 - val_loss: 7.7631 - val_accuracy: 0.5011\n",
      "Epoch 538/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7626 - accuracy: 0.5247 - val_loss: 7.7619 - val_accuracy: 0.5012\n",
      "Epoch 539/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7620 - accuracy: 0.5012 - val_loss: 7.7625 - val_accuracy: 0.5012\n",
      "Epoch 540/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7628 - accuracy: 0.5012 - val_loss: 7.7633 - val_accuracy: 0.5011\n",
      "Epoch 541/5000\n",
      "10780/10780 [==============================] - 0s 45us/sample - loss: 7.7631 - accuracy: 0.5932 - val_loss: 7.7628 - val_accuracy: 1.0000\n",
      "Epoch 542/5000\n",
      "10780/10780 [==============================] - 1s 50us/sample - loss: 7.7629 - accuracy: 0.5242 - val_loss: 7.7607 - val_accuracy: 0.5012\n",
      "Epoch 543/5000\n",
      "10780/10780 [==============================] - 1s 50us/sample - loss: 7.7635 - accuracy: 0.5245 - val_loss: 7.7619 - val_accuracy: 0.5012\n",
      "Epoch 544/5000\n",
      "10780/10780 [==============================] - 1s 50us/sample - loss: 7.7624 - accuracy: 0.5012 - val_loss: 7.7633 - val_accuracy: 0.5012\n",
      "Epoch 545/5000\n",
      "10780/10780 [==============================] - 1s 51us/sample - loss: 7.7634 - accuracy: 0.5012 - val_loss: 7.7628 - val_accuracy: 0.5012\n",
      "Epoch 546/5000\n",
      "10780/10780 [==============================] - 1s 52us/sample - loss: 7.7629 - accuracy: 0.5012 - val_loss: 7.7630 - val_accuracy: 0.5012\n",
      "Epoch 547/5000\n",
      "10780/10780 [==============================] - 1s 52us/sample - loss: 7.7627 - accuracy: 0.5012 - val_loss: 7.7638 - val_accuracy: 0.5012\n",
      "Epoch 548/5000\n",
      "10780/10780 [==============================] - 1s 51us/sample - loss: 7.7635 - accuracy: 0.5012 - val_loss: 7.7683 - val_accuracy: 0.5012\n",
      "Epoch 549/5000\n",
      "10780/10780 [==============================] - 1s 51us/sample - loss: 7.7642 - accuracy: 0.5944 - val_loss: 7.7632 - val_accuracy: 0.5012\n",
      "Epoch 550/5000\n",
      "10780/10780 [==============================] - 1s 51us/sample - loss: 7.7628 - accuracy: 0.5012 - val_loss: 7.7621 - val_accuracy: 0.5012\n",
      "Epoch 551/5000\n",
      "10780/10780 [==============================] - 1s 52us/sample - loss: 7.7646 - accuracy: 0.5012 - val_loss: 7.7661 - val_accuracy: 0.5012\n",
      "Epoch 552/5000\n",
      "10780/10780 [==============================] - 1s 52us/sample - loss: 7.7653 - accuracy: 0.5938 - val_loss: 7.7627 - val_accuracy: 0.5012\n",
      "Epoch 553/5000\n",
      "10780/10780 [==============================] - 1s 52us/sample - loss: 7.7620 - accuracy: 0.5012 - val_loss: 7.7610 - val_accuracy: 0.5012\n",
      "Epoch 554/5000\n",
      "10780/10780 [==============================] - 1s 48us/sample - loss: 7.7625 - accuracy: 0.5012 - val_loss: 7.7633 - val_accuracy: 0.5012\n",
      "Epoch 555/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7634 - accuracy: 0.5012 - val_loss: 7.7636 - val_accuracy: 0.5012\n",
      "Epoch 556/5000\n",
      "10780/10780 [==============================] - 1s 56us/sample - loss: 7.7632 - accuracy: 0.5372 - val_loss: 7.7633 - val_accuracy: 1.0000\n",
      "Epoch 557/5000\n",
      "10780/10780 [==============================] - 1s 47us/sample - loss: 7.7628 - accuracy: 0.5242 - val_loss: 7.7634 - val_accuracy: 0.5012\n",
      "Epoch 558/5000\n",
      "10780/10780 [==============================] - 1s 58us/sample - loss: 7.7628 - accuracy: 0.5012 - val_loss: 7.7620 - val_accuracy: 0.5012\n",
      "Epoch 559/5000\n",
      "10780/10780 [==============================] - 0s 45us/sample - loss: 7.7653 - accuracy: 0.5012 - val_loss: 7.7628 - val_accuracy: 0.5012\n",
      "Epoch 560/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7633 - accuracy: 0.5012 - val_loss: 7.7652 - val_accuracy: 0.5012\n",
      "Epoch 561/5000\n",
      "10780/10780 [==============================] - 0s 44us/sample - loss: 7.7637 - accuracy: 0.5478 - val_loss: 7.7636 - val_accuracy: 0.5012\n",
      "Epoch 562/5000\n",
      "10780/10780 [==============================] - 0s 44us/sample - loss: 7.7637 - accuracy: 0.5012 - val_loss: 7.7640 - val_accuracy: 0.5012\n",
      "Epoch 563/5000\n",
      "10780/10780 [==============================] - 0s 44us/sample - loss: 7.7641 - accuracy: 0.5012 - val_loss: 7.7634 - val_accuracy: 0.5012\n",
      "Epoch 564/5000\n",
      "10780/10780 [==============================] - 0s 45us/sample - loss: 7.7635 - accuracy: 0.5012 - val_loss: 7.7633 - val_accuracy: 0.5012\n",
      "Epoch 565/5000\n",
      "10780/10780 [==============================] - 0s 44us/sample - loss: 7.7630 - accuracy: 0.5012 - val_loss: 7.7618 - val_accuracy: 0.5012\n",
      "Epoch 566/5000\n",
      "10780/10780 [==============================] - 0s 44us/sample - loss: 7.7627 - accuracy: 0.5012 - val_loss: 7.7685 - val_accuracy: 0.5012\n",
      "Epoch 567/5000\n",
      "10780/10780 [==============================] - 1s 51us/sample - loss: 7.7648 - accuracy: 0.5012 - val_loss: 7.7622 - val_accuracy: 0.5012\n",
      "Epoch 568/5000\n",
      "10780/10780 [==============================] - 1s 53us/sample - loss: 7.7631 - accuracy: 0.5012 - val_loss: 7.7619 - val_accuracy: 0.5012\n",
      "Epoch 569/5000\n",
      "10780/10780 [==============================] - 1s 54us/sample - loss: 7.7638 - accuracy: 0.5012 - val_loss: 7.7662 - val_accuracy: 0.5012\n",
      "Epoch 570/5000\n",
      "10780/10780 [==============================] - 1s 55us/sample - loss: 7.7654 - accuracy: 0.5012 - val_loss: 7.7650 - val_accuracy: 0.5011\n",
      "Epoch 571/5000\n",
      "10780/10780 [==============================] - 1s 54us/sample - loss: 7.7649 - accuracy: 0.5012 - val_loss: 7.7649 - val_accuracy: 0.5012\n",
      "Epoch 572/5000\n",
      "10780/10780 [==============================] - 1s 54us/sample - loss: 7.7669 - accuracy: 0.5012 - val_loss: 7.7694 - val_accuracy: 0.5012\n",
      "Epoch 573/5000\n",
      "10780/10780 [==============================] - 1s 55us/sample - loss: 7.7652 - accuracy: 0.5012 - val_loss: 7.7670 - val_accuracy: 0.5012\n",
      "Epoch 574/5000\n",
      "10780/10780 [==============================] - 1s 54us/sample - loss: 7.7656 - accuracy: 0.5012 - val_loss: 7.7627 - val_accuracy: 0.5012\n",
      "Epoch 575/5000\n",
      "10780/10780 [==============================] - 1s 54us/sample - loss: 7.7672 - accuracy: 0.5710 - val_loss: 7.7708 - val_accuracy: 0.5012\n",
      "Epoch 576/5000\n",
      "10780/10780 [==============================] - 1s 48us/sample - loss: 7.7657 - accuracy: 0.5012 - val_loss: 7.7635 - val_accuracy: 0.5012\n",
      "Epoch 577/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7631 - accuracy: 0.5247 - val_loss: 7.7633 - val_accuracy: 0.5012\n",
      "Epoch 578/5000\n",
      "10780/10780 [==============================] - 0s 45us/sample - loss: 7.7624 - accuracy: 0.5472 - val_loss: 7.7620 - val_accuracy: 0.5012\n",
      "Epoch 579/5000\n",
      "10780/10780 [==============================] - 0s 44us/sample - loss: 7.7628 - accuracy: 0.5012 - val_loss: 7.7635 - val_accuracy: 0.5012\n",
      "Epoch 580/5000\n",
      "10780/10780 [==============================] - 0s 44us/sample - loss: 7.7640 - accuracy: 0.5476 - val_loss: 7.7626 - val_accuracy: 0.5013\n",
      "Epoch 581/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7632 - accuracy: 0.6173 - val_loss: 7.7617 - val_accuracy: 0.5012\n",
      "Epoch 582/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7630 - accuracy: 0.5012 - val_loss: 7.7612 - val_accuracy: 0.5012\n",
      "Epoch 583/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7622 - accuracy: 0.5012 - val_loss: 7.7632 - val_accuracy: 0.5012\n",
      "Epoch 584/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7624 - accuracy: 0.5012 - val_loss: 7.7634 - val_accuracy: 0.5012\n",
      "Epoch 585/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7635 - accuracy: 0.5012 - val_loss: 7.7623 - val_accuracy: 0.5012\n",
      "Epoch 586/5000\n",
      "10780/10780 [==============================] - 1s 51us/sample - loss: 7.7634 - accuracy: 0.5012 - val_loss: 7.7638 - val_accuracy: 0.5012\n",
      "Epoch 587/5000\n",
      "10780/10780 [==============================] - 1s 53us/sample - loss: 7.7627 - accuracy: 0.5245 - val_loss: 7.7613 - val_accuracy: 0.5012\n",
      "Epoch 588/5000\n",
      "10780/10780 [==============================] - 1s 53us/sample - loss: 7.7628 - accuracy: 0.5711 - val_loss: 7.7612 - val_accuracy: 0.5012\n",
      "Epoch 589/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7627 - accuracy: 0.5012 - val_loss: 7.7626 - val_accuracy: 0.5012\n",
      "Epoch 590/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7623 - accuracy: 0.5012 - val_loss: 7.7619 - val_accuracy: 0.5012\n",
      "Epoch 591/5000\n",
      "10780/10780 [==============================] - 0s 43us/sample - loss: 7.7628 - accuracy: 0.5012 - val_loss: 7.7622 - val_accuracy: 0.5012\n",
      "Epoch 592/5000\n",
      "10780/10780 [==============================] - 0s 43us/sample - loss: 7.7633 - accuracy: 0.5012 - val_loss: 7.7620 - val_accuracy: 0.5012\n",
      "Epoch 593/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7626 - accuracy: 0.5012 - val_loss: 7.7619 - val_accuracy: 0.5012\n",
      "Epoch 594/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7635 - accuracy: 0.5012 - val_loss: 7.7709 - val_accuracy: 0.5012\n",
      "Epoch 595/5000\n",
      "10780/10780 [==============================] - 1s 48us/sample - loss: 7.7679 - accuracy: 0.5475 - val_loss: 7.7662 - val_accuracy: 0.5012\n",
      "Epoch 596/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7624 - accuracy: 0.5477 - val_loss: 7.7625 - val_accuracy: 0.5012\n",
      "Epoch 597/5000\n",
      "10780/10780 [==============================] - 0s 46us/sample - loss: 7.7651 - accuracy: 0.5012 - val_loss: 7.7683 - val_accuracy: 0.5012\n",
      "Epoch 598/5000\n",
      "10780/10780 [==============================] - 0s 45us/sample - loss: 7.7676 - accuracy: 0.5012 - val_loss: 7.7641 - val_accuracy: 0.5012\n",
      "Epoch 599/5000\n",
      "10780/10780 [==============================] - 0s 45us/sample - loss: 7.7631 - accuracy: 0.5932 - val_loss: 7.7612 - val_accuracy: 1.0000\n",
      "Epoch 600/5000\n",
      "10780/10780 [==============================] - 0s 45us/sample - loss: 7.7635 - accuracy: 0.5940 - val_loss: 7.7650 - val_accuracy: 0.5012\n",
      "Epoch 601/5000\n",
      "10780/10780 [==============================] - 0s 45us/sample - loss: 7.7663 - accuracy: 0.5012 - val_loss: 7.7654 - val_accuracy: 0.5011\n",
      "Epoch 602/5000\n",
      "10780/10780 [==============================] - 0s 45us/sample - loss: 7.7635 - accuracy: 0.5012 - val_loss: 7.7644 - val_accuracy: 0.5012\n",
      "Epoch 603/5000\n",
      "10780/10780 [==============================] - 0s 44us/sample - loss: 7.7628 - accuracy: 0.5012 - val_loss: 7.7631 - val_accuracy: 0.5012\n",
      "Epoch 604/5000\n",
      "10780/10780 [==============================] - 0s 44us/sample - loss: 7.7625 - accuracy: 0.5012 - val_loss: 7.7624 - val_accuracy: 0.5012\n",
      "Epoch 605/5000\n",
      "10780/10780 [==============================] - 0s 45us/sample - loss: 7.7645 - accuracy: 0.5012 - val_loss: 7.7649 - val_accuracy: 0.5012\n",
      "Epoch 606/5000\n",
      "10780/10780 [==============================] - 0s 45us/sample - loss: 7.7655 - accuracy: 0.5012 - val_loss: 7.7674 - val_accuracy: 0.5012\n",
      "Epoch 607/5000\n",
      "10780/10780 [==============================] - 0s 45us/sample - loss: 7.7657 - accuracy: 0.5012 - val_loss: 7.7628 - val_accuracy: 0.5012\n",
      "Epoch 608/5000\n",
      "10780/10780 [==============================] - 0s 45us/sample - loss: 7.7646 - accuracy: 0.5012 - val_loss: 7.7651 - val_accuracy: 0.5012\n",
      "Epoch 609/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7645 - accuracy: 0.5012 - val_loss: 7.7602 - val_accuracy: 0.5012\n",
      "Epoch 610/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7625 - accuracy: 0.5012 - val_loss: 7.7609 - val_accuracy: 0.5012\n",
      "Epoch 611/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7620 - accuracy: 0.5012 - val_loss: 7.7615 - val_accuracy: 0.5012\n",
      "Epoch 612/5000\n",
      "10780/10780 [==============================] - 1s 50us/sample - loss: 7.7640 - accuracy: 0.5012 - val_loss: 7.7645 - val_accuracy: 0.5011\n",
      "Epoch 613/5000\n",
      "10780/10780 [==============================] - 0s 44us/sample - loss: 7.7665 - accuracy: 0.5012 - val_loss: 7.7670 - val_accuracy: 0.5012\n",
      "Epoch 614/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7640 - accuracy: 0.5012 - val_loss: 7.7623 - val_accuracy: 0.5013\n",
      "Epoch 615/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7619 - accuracy: 0.5012 - val_loss: 7.7626 - val_accuracy: 0.5012\n",
      "Epoch 616/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7626 - accuracy: 0.5012 - val_loss: 7.7636 - val_accuracy: 0.5012\n",
      "Epoch 617/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7630 - accuracy: 0.5012 - val_loss: 7.7659 - val_accuracy: 0.5012\n",
      "Epoch 618/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7638 - accuracy: 0.5245 - val_loss: 7.7618 - val_accuracy: 0.5013\n",
      "Epoch 619/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7619 - accuracy: 0.5012 - val_loss: 7.7618 - val_accuracy: 0.5012\n",
      "Epoch 620/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7628 - accuracy: 0.5246 - val_loss: 7.7635 - val_accuracy: 0.5012\n",
      "Epoch 621/5000\n",
      "10780/10780 [==============================] - 1s 47us/sample - loss: 7.7636 - accuracy: 0.5012 - val_loss: 7.7642 - val_accuracy: 0.5012\n",
      "Epoch 622/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7629 - accuracy: 0.5942 - val_loss: 7.7639 - val_accuracy: 0.5012\n",
      "Epoch 623/5000\n",
      "10780/10780 [==============================] - 0s 32us/sample - loss: 7.7653 - accuracy: 0.5012 - val_loss: 7.7628 - val_accuracy: 0.5012\n",
      "Epoch 624/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7630 - accuracy: 0.5012 - val_loss: 7.7621 - val_accuracy: 0.5012\n",
      "Epoch 625/5000\n",
      "10780/10780 [==============================] - 0s 46us/sample - loss: 7.7628 - accuracy: 0.5012 - val_loss: 7.7619 - val_accuracy: 0.5012\n",
      "Epoch 626/5000\n",
      "10780/10780 [==============================] - 0s 31us/sample - loss: 7.7632 - accuracy: 0.5012 - val_loss: 7.7624 - val_accuracy: 1.0000\n",
      "Epoch 627/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7626 - accuracy: 0.5941 - val_loss: 7.7617 - val_accuracy: 0.5012\n",
      "Epoch 628/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7624 - accuracy: 0.5244 - val_loss: 7.7638 - val_accuracy: 0.5012\n",
      "Epoch 629/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7622 - accuracy: 0.5012 - val_loss: 7.7650 - val_accuracy: 0.5012\n",
      "Epoch 630/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7644 - accuracy: 0.5012 - val_loss: 7.7634 - val_accuracy: 0.5011\n",
      "Epoch 631/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7627 - accuracy: 0.5373 - val_loss: 7.7624 - val_accuracy: 1.0000\n",
      "Epoch 632/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7655 - accuracy: 0.5939 - val_loss: 7.7681 - val_accuracy: 0.5012\n",
      "Epoch 633/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7685 - accuracy: 0.5012 - val_loss: 7.7667 - val_accuracy: 0.5012\n",
      "Epoch 634/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7647 - accuracy: 0.5012 - val_loss: 7.7632 - val_accuracy: 0.5012\n",
      "Epoch 635/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7636 - accuracy: 0.6763 - val_loss: 7.7622 - val_accuracy: 0.5012\n",
      "Epoch 636/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7623 - accuracy: 0.5012 - val_loss: 7.7632 - val_accuracy: 0.5012\n",
      "Epoch 637/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7656 - accuracy: 0.5142 - val_loss: 7.7699 - val_accuracy: 1.0000\n",
      "Epoch 638/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7666 - accuracy: 0.5246 - val_loss: 7.7636 - val_accuracy: 0.5011\n",
      "Epoch 639/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7645 - accuracy: 0.5243 - val_loss: 7.7623 - val_accuracy: 0.5012\n",
      "Epoch 640/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7638 - accuracy: 0.5012 - val_loss: 7.7649 - val_accuracy: 0.5012\n",
      "Epoch 641/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7657 - accuracy: 0.5012 - val_loss: 7.7651 - val_accuracy: 0.5012\n",
      "Epoch 642/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7647 - accuracy: 0.5243 - val_loss: 7.7656 - val_accuracy: 0.5011\n",
      "Epoch 643/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7643 - accuracy: 0.5011 - val_loss: 7.7620 - val_accuracy: 0.5012\n",
      "Epoch 644/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7637 - accuracy: 0.5012 - val_loss: 7.7628 - val_accuracy: 0.5011\n",
      "Epoch 645/5000\n",
      "10780/10780 [==============================] - 1s 48us/sample - loss: 7.7625 - accuracy: 0.5012 - val_loss: 7.7610 - val_accuracy: 0.5012\n",
      "Epoch 646/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7623 - accuracy: 0.5012 - val_loss: 7.7628 - val_accuracy: 0.5012\n",
      "Epoch 647/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7631 - accuracy: 0.5012 - val_loss: 7.7615 - val_accuracy: 0.5012\n",
      "Epoch 648/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7629 - accuracy: 0.5012 - val_loss: 7.7613 - val_accuracy: 0.5012\n",
      "Epoch 649/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7625 - accuracy: 0.5012 - val_loss: 7.7627 - val_accuracy: 0.5011\n",
      "Epoch 650/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7628 - accuracy: 0.5941 - val_loss: 7.7652 - val_accuracy: 0.5012\n",
      "Epoch 651/5000\n",
      "10780/10780 [==============================] - 0s 32us/sample - loss: 7.7664 - accuracy: 0.5245 - val_loss: 7.7637 - val_accuracy: 0.5012\n",
      "Epoch 652/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7651 - accuracy: 0.5012 - val_loss: 7.7634 - val_accuracy: 0.5012\n",
      "Epoch 653/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7630 - accuracy: 0.5012 - val_loss: 7.7630 - val_accuracy: 0.5011\n",
      "Epoch 654/5000\n",
      "10780/10780 [==============================] - 0s 31us/sample - loss: 7.7638 - accuracy: 0.5012 - val_loss: 7.7634 - val_accuracy: 0.5012\n",
      "Epoch 655/5000\n",
      "10780/10780 [==============================] - 0s 32us/sample - loss: 7.7638 - accuracy: 0.5012 - val_loss: 7.7627 - val_accuracy: 0.5012\n",
      "Epoch 656/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7627 - accuracy: 0.5012 - val_loss: 7.7620 - val_accuracy: 0.5012\n",
      "Epoch 657/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7630 - accuracy: 0.5012 - val_loss: 7.7653 - val_accuracy: 0.5009\n",
      "Epoch 658/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7640 - accuracy: 0.5012 - val_loss: 7.7685 - val_accuracy: 0.5012\n",
      "Epoch 659/5000\n",
      "10780/10780 [==============================] - 0s 46us/sample - loss: 7.7683 - accuracy: 0.5012 - val_loss: 7.7664 - val_accuracy: 0.5012\n",
      "Epoch 660/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7648 - accuracy: 0.5242 - val_loss: 7.7633 - val_accuracy: 0.5012\n",
      "Epoch 661/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7637 - accuracy: 0.5012 - val_loss: 7.7684 - val_accuracy: 0.5012\n",
      "Epoch 662/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7642 - accuracy: 0.5012 - val_loss: 7.7612 - val_accuracy: 0.5012\n",
      "Epoch 663/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7628 - accuracy: 0.5012 - val_loss: 7.7626 - val_accuracy: 0.5012\n",
      "Epoch 664/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7640 - accuracy: 0.5702 - val_loss: 7.7625 - val_accuracy: 0.5011\n",
      "Epoch 665/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7623 - accuracy: 0.5012 - val_loss: 7.7618 - val_accuracy: 0.5012\n",
      "Epoch 666/5000\n",
      "10780/10780 [==============================] - 0s 32us/sample - loss: 7.7660 - accuracy: 0.5012 - val_loss: 7.7665 - val_accuracy: 0.5011\n",
      "Epoch 667/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7667 - accuracy: 0.5703 - val_loss: 7.7635 - val_accuracy: 0.5012\n",
      "Epoch 668/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7632 - accuracy: 0.5012 - val_loss: 7.7654 - val_accuracy: 0.5012\n",
      "Epoch 669/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7632 - accuracy: 0.5476 - val_loss: 7.7639 - val_accuracy: 0.5012\n",
      "Epoch 670/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7636 - accuracy: 0.5012 - val_loss: 7.7626 - val_accuracy: 0.5012\n",
      "Epoch 671/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7627 - accuracy: 0.5012 - val_loss: 7.7612 - val_accuracy: 0.5012\n",
      "Epoch 672/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7625 - accuracy: 0.5012 - val_loss: 7.7635 - val_accuracy: 0.5012\n",
      "Epoch 673/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7637 - accuracy: 0.5012 - val_loss: 7.7640 - val_accuracy: 0.5011\n",
      "Epoch 674/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7672 - accuracy: 0.5012 - val_loss: 7.7653 - val_accuracy: 0.5011\n",
      "Epoch 675/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7657 - accuracy: 0.5012 - val_loss: 7.7670 - val_accuracy: 0.5012\n",
      "Epoch 676/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7637 - accuracy: 0.5012 - val_loss: 7.7616 - val_accuracy: 0.5011\n",
      "Epoch 677/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7625 - accuracy: 0.5243 - val_loss: 7.7624 - val_accuracy: 0.5012\n",
      "Epoch 678/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7635 - accuracy: 0.5245 - val_loss: 7.7652 - val_accuracy: 1.0000\n",
      "Epoch 679/5000\n",
      "10780/10780 [==============================] - 0s 32us/sample - loss: 7.7630 - accuracy: 0.5704 - val_loss: 7.7610 - val_accuracy: 0.5012\n",
      "Epoch 680/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7629 - accuracy: 0.5012 - val_loss: 7.7638 - val_accuracy: 0.5012\n",
      "Epoch 681/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7672 - accuracy: 0.5012 - val_loss: 7.7625 - val_accuracy: 0.5012\n",
      "Epoch 682/5000\n",
      "10780/10780 [==============================] - 0s 32us/sample - loss: 7.7686 - accuracy: 0.5012 - val_loss: 7.7659 - val_accuracy: 0.5012\n",
      "Epoch 683/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7672 - accuracy: 0.5242 - val_loss: 7.7653 - val_accuracy: 0.5011\n",
      "Epoch 684/5000\n",
      "10780/10780 [==============================] - 0s 30us/sample - loss: 7.7636 - accuracy: 0.5934 - val_loss: 7.7612 - val_accuracy: 0.5012\n",
      "Epoch 685/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7625 - accuracy: 0.5012 - val_loss: 7.7671 - val_accuracy: 0.5012\n",
      "Epoch 686/5000\n",
      "10780/10780 [==============================] - 0s 44us/sample - loss: 7.7674 - accuracy: 0.5012 - val_loss: 7.7654 - val_accuracy: 0.5012\n",
      "Epoch 687/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7647 - accuracy: 0.5012 - val_loss: 7.7626 - val_accuracy: 0.5011\n",
      "Epoch 688/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7623 - accuracy: 0.5242 - val_loss: 7.7619 - val_accuracy: 0.5012\n",
      "Epoch 689/5000\n",
      "10780/10780 [==============================] - 0s 32us/sample - loss: 7.7620 - accuracy: 0.5012 - val_loss: 7.7629 - val_accuracy: 1.0000\n",
      "Epoch 690/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7618 - accuracy: 0.5473 - val_loss: 7.7623 - val_accuracy: 0.5012\n",
      "Epoch 691/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10780/10780 [==============================] - 0s 43us/sample - loss: 7.7620 - accuracy: 0.5012 - val_loss: 7.7627 - val_accuracy: 0.5012\n",
      "Epoch 692/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7623 - accuracy: 0.5012 - val_loss: 7.7649 - val_accuracy: 0.5012\n",
      "Epoch 693/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7628 - accuracy: 0.5012 - val_loss: 7.7624 - val_accuracy: 0.5012\n",
      "Epoch 694/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7631 - accuracy: 0.6168 - val_loss: 7.7617 - val_accuracy: 0.5012\n",
      "Epoch 695/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7617 - accuracy: 0.6397 - val_loss: 7.7611 - val_accuracy: 0.5012\n",
      "Epoch 696/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7621 - accuracy: 0.5474 - val_loss: 7.7626 - val_accuracy: 0.5012\n",
      "Epoch 697/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7633 - accuracy: 0.5012 - val_loss: 7.7633 - val_accuracy: 0.5012\n",
      "Epoch 698/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7626 - accuracy: 0.5244 - val_loss: 7.7618 - val_accuracy: 0.5012\n",
      "Epoch 699/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7623 - accuracy: 0.5012 - val_loss: 7.7609 - val_accuracy: 0.5012\n",
      "Epoch 700/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7640 - accuracy: 0.5012 - val_loss: 7.7645 - val_accuracy: 0.5012\n",
      "Epoch 701/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7625 - accuracy: 0.5012 - val_loss: 7.7622 - val_accuracy: 0.5012\n",
      "Epoch 702/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7632 - accuracy: 0.5012 - val_loss: 7.7714 - val_accuracy: 0.5011\n",
      "Epoch 703/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7680 - accuracy: 0.5708 - val_loss: 7.7678 - val_accuracy: 0.5012\n",
      "Epoch 704/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7670 - accuracy: 0.5012 - val_loss: 7.7647 - val_accuracy: 0.5012\n",
      "Epoch 705/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7647 - accuracy: 0.5011 - val_loss: 7.7639 - val_accuracy: 0.5012\n",
      "Epoch 706/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7627 - accuracy: 0.5012 - val_loss: 7.7626 - val_accuracy: 0.5011\n",
      "Epoch 707/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7630 - accuracy: 0.5012 - val_loss: 7.7656 - val_accuracy: 0.5012\n",
      "Epoch 708/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7622 - accuracy: 0.5012 - val_loss: 7.7612 - val_accuracy: 0.5012\n",
      "Epoch 709/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7628 - accuracy: 0.5012 - val_loss: 7.7628 - val_accuracy: 0.5012\n",
      "Epoch 710/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7631 - accuracy: 0.5012 - val_loss: 7.7615 - val_accuracy: 0.5012\n",
      "Epoch 711/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7626 - accuracy: 0.5012 - val_loss: 7.7614 - val_accuracy: 1.0000\n",
      "Epoch 712/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7629 - accuracy: 0.5473 - val_loss: 7.7627 - val_accuracy: 1.0000\n",
      "Epoch 713/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7637 - accuracy: 0.5242 - val_loss: 7.7659 - val_accuracy: 0.5012\n",
      "Epoch 714/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7649 - accuracy: 0.5012 - val_loss: 7.7629 - val_accuracy: 0.5012\n",
      "Epoch 715/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7626 - accuracy: 0.5012 - val_loss: 7.7610 - val_accuracy: 0.5012\n",
      "Epoch 716/5000\n",
      "10780/10780 [==============================] - 1s 49us/sample - loss: 7.7622 - accuracy: 0.5012 - val_loss: 7.7612 - val_accuracy: 0.5012\n",
      "Epoch 717/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7623 - accuracy: 0.5469 - val_loss: 7.7643 - val_accuracy: 0.5012\n",
      "Epoch 718/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7638 - accuracy: 0.5012 - val_loss: 7.7646 - val_accuracy: 0.5012\n",
      "Epoch 719/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7625 - accuracy: 0.5012 - val_loss: 7.7617 - val_accuracy: 0.5012\n",
      "Epoch 720/5000\n",
      "10780/10780 [==============================] - 0s 43us/sample - loss: 7.7639 - accuracy: 0.5012 - val_loss: 7.7616 - val_accuracy: 0.5011\n",
      "Epoch 721/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7628 - accuracy: 0.5012 - val_loss: 7.7632 - val_accuracy: 0.5011\n",
      "Epoch 722/5000\n",
      "10780/10780 [==============================] - 0s 43us/sample - loss: 7.7632 - accuracy: 0.5012 - val_loss: 7.7628 - val_accuracy: 0.5012\n",
      "Epoch 723/5000\n",
      "10780/10780 [==============================] - 0s 45us/sample - loss: 7.7621 - accuracy: 0.5928 - val_loss: 7.7637 - val_accuracy: 0.5012\n",
      "Epoch 724/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7626 - accuracy: 0.5012 - val_loss: 7.7628 - val_accuracy: 0.5011\n",
      "Epoch 725/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7643 - accuracy: 0.5141 - val_loss: 7.7667 - val_accuracy: 0.5012\n",
      "Epoch 726/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7643 - accuracy: 0.5475 - val_loss: 7.7637 - val_accuracy: 0.5012\n",
      "Epoch 727/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7622 - accuracy: 0.5707 - val_loss: 7.7616 - val_accuracy: 0.5012\n",
      "Epoch 728/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7625 - accuracy: 0.5012 - val_loss: 7.7619 - val_accuracy: 0.5012\n",
      "Epoch 729/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7623 - accuracy: 0.5012 - val_loss: 7.7618 - val_accuracy: 0.5012\n",
      "Epoch 730/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7639 - accuracy: 0.5012 - val_loss: 7.7656 - val_accuracy: 0.5012\n",
      "Epoch 731/5000\n",
      "10780/10780 [==============================] - 1s 56us/sample - loss: 7.7637 - accuracy: 0.5012 - val_loss: 7.7647 - val_accuracy: 0.5012\n",
      "Epoch 732/5000\n",
      "10780/10780 [==============================] - 0s 43us/sample - loss: 7.7626 - accuracy: 0.5472 - val_loss: 7.7632 - val_accuracy: 0.5012\n",
      "Epoch 733/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7624 - accuracy: 0.5012 - val_loss: 7.7618 - val_accuracy: 0.5012\n",
      "Epoch 734/5000\n",
      "10780/10780 [==============================] - 0s 32us/sample - loss: 7.7624 - accuracy: 0.5012 - val_loss: 7.7620 - val_accuracy: 0.5011\n",
      "Epoch 735/5000\n",
      "10780/10780 [==============================] - 0s 32us/sample - loss: 7.7621 - accuracy: 0.5246 - val_loss: 7.7614 - val_accuracy: 0.5011\n",
      "Epoch 736/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7635 - accuracy: 0.5935 - val_loss: 7.7628 - val_accuracy: 1.0000\n",
      "Epoch 737/5000\n",
      "10780/10780 [==============================] - 1s 47us/sample - loss: 7.7624 - accuracy: 0.5473 - val_loss: 7.7632 - val_accuracy: 0.5012\n",
      "Epoch 738/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7638 - accuracy: 0.5012 - val_loss: 7.7709 - val_accuracy: 0.5012\n",
      "Epoch 739/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7641 - accuracy: 0.5011 - val_loss: 7.7628 - val_accuracy: 0.5010\n",
      "Epoch 740/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7658 - accuracy: 0.5242 - val_loss: 7.7648 - val_accuracy: 0.5012\n",
      "Epoch 741/5000\n",
      "10780/10780 [==============================] - 1s 47us/sample - loss: 7.7650 - accuracy: 0.5373 - val_loss: 7.7617 - val_accuracy: 1.0000\n",
      "Epoch 742/5000\n",
      "10780/10780 [==============================] - 1s 55us/sample - loss: 7.7621 - accuracy: 0.6165 - val_loss: 7.7638 - val_accuracy: 0.5012\n",
      "Epoch 743/5000\n",
      "10780/10780 [==============================] - 1s 55us/sample - loss: 7.7633 - accuracy: 0.5012 - val_loss: 7.7610 - val_accuracy: 0.5012\n",
      "Epoch 744/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10780/10780 [==============================] - 1s 56us/sample - loss: 7.7650 - accuracy: 0.5012 - val_loss: 7.7627 - val_accuracy: 0.5012\n",
      "Epoch 745/5000\n",
      "10780/10780 [==============================] - 1s 57us/sample - loss: 7.7623 - accuracy: 0.5012 - val_loss: 7.7634 - val_accuracy: 0.5012\n",
      "Epoch 746/5000\n",
      "10780/10780 [==============================] - 1s 53us/sample - loss: 7.7630 - accuracy: 0.5012 - val_loss: 7.7625 - val_accuracy: 0.5012\n",
      "Epoch 747/5000\n",
      "10780/10780 [==============================] - 1s 46us/sample - loss: 7.7617 - accuracy: 0.5012 - val_loss: 7.7617 - val_accuracy: 0.5012\n",
      "Epoch 748/5000\n",
      "10780/10780 [==============================] - 0s 46us/sample - loss: 7.7672 - accuracy: 0.5012 - val_loss: 7.7663 - val_accuracy: 0.5012\n",
      "Epoch 749/5000\n",
      "10780/10780 [==============================] - 0s 46us/sample - loss: 7.7675 - accuracy: 0.5012 - val_loss: 7.7662 - val_accuracy: 1.0000\n",
      "Epoch 750/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7627 - accuracy: 0.5476 - val_loss: 7.7599 - val_accuracy: 0.5012\n",
      "Epoch 751/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7646 - accuracy: 0.5011 - val_loss: 7.7656 - val_accuracy: 0.5012\n",
      "Epoch 752/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7641 - accuracy: 0.5247 - val_loss: 7.7619 - val_accuracy: 0.5012\n",
      "Epoch 753/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7635 - accuracy: 0.5011 - val_loss: 7.7618 - val_accuracy: 0.5012\n",
      "Epoch 754/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7617 - accuracy: 0.5012 - val_loss: 7.7627 - val_accuracy: 0.5012\n",
      "Epoch 755/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7634 - accuracy: 0.5012 - val_loss: 7.7625 - val_accuracy: 0.5011\n",
      "Epoch 756/5000\n",
      "10780/10780 [==============================] - 0s 31us/sample - loss: 7.7635 - accuracy: 0.5937 - val_loss: 7.7688 - val_accuracy: 0.5012\n",
      "Epoch 757/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7642 - accuracy: 0.5244 - val_loss: 7.7640 - val_accuracy: 0.5012\n",
      "Epoch 758/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7647 - accuracy: 0.5012 - val_loss: 7.7613 - val_accuracy: 0.5012\n",
      "Epoch 759/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7662 - accuracy: 0.5012 - val_loss: 7.7643 - val_accuracy: 0.5012\n",
      "Epoch 760/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7671 - accuracy: 0.5012 - val_loss: 7.7626 - val_accuracy: 0.5013\n",
      "Epoch 761/5000\n",
      "10780/10780 [==============================] - 0s 46us/sample - loss: 7.7643 - accuracy: 0.5012 - val_loss: 7.7658 - val_accuracy: 0.5012\n",
      "Epoch 762/5000\n",
      "10780/10780 [==============================] - 0s 32us/sample - loss: 7.7630 - accuracy: 0.5012 - val_loss: 7.7611 - val_accuracy: 0.5012\n",
      "Epoch 763/5000\n",
      "10780/10780 [==============================] - 0s 44us/sample - loss: 7.7629 - accuracy: 0.5474 - val_loss: 7.7624 - val_accuracy: 0.5012\n",
      "Epoch 764/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7625 - accuracy: 0.5012 - val_loss: 7.7632 - val_accuracy: 0.5012\n",
      "Epoch 765/5000\n",
      "10780/10780 [==============================] - 0s 29us/sample - loss: 7.7627 - accuracy: 0.5012 - val_loss: 7.7623 - val_accuracy: 0.5011\n",
      "Epoch 766/5000\n",
      "10780/10780 [==============================] - 0s 30us/sample - loss: 7.7631 - accuracy: 0.5012 - val_loss: 7.7630 - val_accuracy: 0.5012\n",
      "Epoch 767/5000\n",
      "10780/10780 [==============================] - 0s 30us/sample - loss: 7.7635 - accuracy: 0.5012 - val_loss: 7.7632 - val_accuracy: 0.5012\n",
      "Epoch 768/5000\n",
      "10780/10780 [==============================] - 0s 29us/sample - loss: 7.7622 - accuracy: 0.5012 - val_loss: 7.7643 - val_accuracy: 0.5012\n",
      "Epoch 769/5000\n",
      "10780/10780 [==============================] - 0s 30us/sample - loss: 7.7645 - accuracy: 0.5012 - val_loss: 7.7650 - val_accuracy: 0.5011\n",
      "Epoch 770/5000\n",
      "10780/10780 [==============================] - 0s 28us/sample - loss: 7.7627 - accuracy: 0.5012 - val_loss: 7.7630 - val_accuracy: 0.5012\n",
      "Epoch 771/5000\n",
      "10780/10780 [==============================] - 0s 29us/sample - loss: 7.7641 - accuracy: 0.5012 - val_loss: 7.7619 - val_accuracy: 0.5012\n",
      "Epoch 772/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7688 - accuracy: 0.5012 - val_loss: 7.7618 - val_accuracy: 0.5012\n",
      "Epoch 773/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7678 - accuracy: 0.5012 - val_loss: 7.7697 - val_accuracy: 0.5012\n",
      "Epoch 774/5000\n",
      "10780/10780 [==============================] - 0s 32us/sample - loss: 7.7645 - accuracy: 0.5012 - val_loss: 7.7645 - val_accuracy: 0.5012\n",
      "Epoch 775/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7642 - accuracy: 0.5012 - val_loss: 7.7622 - val_accuracy: 0.5012\n",
      "Epoch 776/5000\n",
      "10780/10780 [==============================] - 0s 43us/sample - loss: 7.7622 - accuracy: 0.5012 - val_loss: 7.7617 - val_accuracy: 0.5012\n",
      "Epoch 777/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7627 - accuracy: 0.5475 - val_loss: 7.7669 - val_accuracy: 0.5013\n",
      "Epoch 778/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7638 - accuracy: 0.5012 - val_loss: 7.7605 - val_accuracy: 0.5012\n",
      "Epoch 779/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7622 - accuracy: 0.5012 - val_loss: 7.7615 - val_accuracy: 0.5012\n",
      "Epoch 780/5000\n",
      "10780/10780 [==============================] - 0s 32us/sample - loss: 7.7631 - accuracy: 0.5373 - val_loss: 7.7616 - val_accuracy: 1.0000\n",
      "Epoch 781/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7620 - accuracy: 0.5679 - val_loss: 7.7623 - val_accuracy: 1.0000\n",
      "Epoch 782/5000\n",
      "10780/10780 [==============================] - 0s 31us/sample - loss: 7.7648 - accuracy: 0.5709 - val_loss: 7.7669 - val_accuracy: 0.5012\n",
      "Epoch 783/5000\n",
      "10780/10780 [==============================] - 1s 56us/sample - loss: 7.7656 - accuracy: 0.5477 - val_loss: 7.7647 - val_accuracy: 0.5011\n",
      "Epoch 784/5000\n",
      "10780/10780 [==============================] - 1s 56us/sample - loss: 7.7629 - accuracy: 0.5141 - val_loss: 7.7646 - val_accuracy: 1.0000\n",
      "Epoch 785/5000\n",
      "10780/10780 [==============================] - 1s 55us/sample - loss: 7.7630 - accuracy: 0.5700 - val_loss: 7.7616 - val_accuracy: 0.5012\n",
      "Epoch 786/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7625 - accuracy: 0.5012 - val_loss: 7.7633 - val_accuracy: 0.5012\n",
      "Epoch 787/5000\n",
      "10780/10780 [==============================] - 0s 44us/sample - loss: 7.7621 - accuracy: 0.5012 - val_loss: 7.7619 - val_accuracy: 0.5011\n",
      "Epoch 788/5000\n",
      "10780/10780 [==============================] - 0s 45us/sample - loss: 7.7619 - accuracy: 0.5012 - val_loss: 7.7620 - val_accuracy: 0.5012\n",
      "Epoch 789/5000\n",
      "10780/10780 [==============================] - 0s 32us/sample - loss: 7.7622 - accuracy: 0.5474 - val_loss: 7.7614 - val_accuracy: 0.5012\n",
      "Epoch 790/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7617 - accuracy: 0.5012 - val_loss: 7.7647 - val_accuracy: 1.0000\n",
      "Epoch 791/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7628 - accuracy: 0.5939 - val_loss: 7.7623 - val_accuracy: 0.5012\n",
      "Epoch 792/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7624 - accuracy: 0.5243 - val_loss: 7.7610 - val_accuracy: 0.5012\n",
      "Epoch 793/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7629 - accuracy: 0.5012 - val_loss: 7.7624 - val_accuracy: 0.5012\n",
      "Epoch 794/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7641 - accuracy: 0.5012 - val_loss: 7.7624 - val_accuracy: 0.5012\n",
      "Epoch 795/5000\n",
      "10780/10780 [==============================] - 1s 47us/sample - loss: 7.7623 - accuracy: 0.5012 - val_loss: 7.7611 - val_accuracy: 0.5011\n",
      "Epoch 796/5000\n",
      "10780/10780 [==============================] - 1s 51us/sample - loss: 7.7619 - accuracy: 0.5012 - val_loss: 7.7622 - val_accuracy: 0.5012\n",
      "Epoch 797/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10780/10780 [==============================] - 1s 51us/sample - loss: 7.7634 - accuracy: 0.5012 - val_loss: 7.7638 - val_accuracy: 0.5012\n",
      "Epoch 798/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7637 - accuracy: 0.5012 - val_loss: 7.7626 - val_accuracy: 0.5012\n",
      "Epoch 799/5000\n",
      "10780/10780 [==============================] - 0s 32us/sample - loss: 7.7629 - accuracy: 0.5012 - val_loss: 7.7620 - val_accuracy: 0.5012\n",
      "Epoch 800/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7665 - accuracy: 0.5239 - val_loss: 7.7637 - val_accuracy: 0.5012\n",
      "Epoch 801/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7635 - accuracy: 0.5704 - val_loss: 7.7636 - val_accuracy: 0.5012\n",
      "Epoch 802/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7642 - accuracy: 0.5012 - val_loss: 7.7669 - val_accuracy: 0.5013\n",
      "Epoch 803/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7648 - accuracy: 0.5479 - val_loss: 7.7631 - val_accuracy: 0.5012\n",
      "Epoch 804/5000\n",
      "10780/10780 [==============================] - 0s 32us/sample - loss: 7.7627 - accuracy: 0.5012 - val_loss: 7.7627 - val_accuracy: 0.5012\n",
      "Epoch 805/5000\n",
      "10780/10780 [==============================] - 1s 54us/sample - loss: 7.7647 - accuracy: 0.5012 - val_loss: 7.7638 - val_accuracy: 0.5012\n",
      "Epoch 806/5000\n",
      "10780/10780 [==============================] - 0s 32us/sample - loss: 7.7626 - accuracy: 0.5012 - val_loss: 7.7620 - val_accuracy: 0.5012\n",
      "Epoch 807/5000\n",
      "10780/10780 [==============================] - 0s 30us/sample - loss: 7.7644 - accuracy: 0.5012 - val_loss: 7.7655 - val_accuracy: 0.5012\n",
      "Epoch 808/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7636 - accuracy: 0.5012 - val_loss: 7.7626 - val_accuracy: 0.5012\n",
      "Epoch 809/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7623 - accuracy: 0.5243 - val_loss: 7.7641 - val_accuracy: 0.5012\n",
      "Epoch 810/5000\n",
      "10780/10780 [==============================] - 0s 44us/sample - loss: 7.7628 - accuracy: 0.5012 - val_loss: 7.7653 - val_accuracy: 0.5012\n",
      "Epoch 811/5000\n",
      "10780/10780 [==============================] - 1s 48us/sample - loss: 7.7640 - accuracy: 0.5012 - val_loss: 7.7665 - val_accuracy: 0.5012\n",
      "Epoch 812/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7636 - accuracy: 0.5012 - val_loss: 7.7624 - val_accuracy: 0.5012\n",
      "Epoch 813/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7626 - accuracy: 0.5012 - val_loss: 7.7609 - val_accuracy: 0.5012\n",
      "Epoch 814/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7636 - accuracy: 0.5012 - val_loss: 7.7618 - val_accuracy: 0.5012\n",
      "Epoch 815/5000\n",
      "10780/10780 [==============================] - 0s 44us/sample - loss: 7.7623 - accuracy: 0.5012 - val_loss: 7.7624 - val_accuracy: 0.5012\n",
      "Epoch 816/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7622 - accuracy: 0.5012 - val_loss: 7.7629 - val_accuracy: 0.5011\n",
      "Epoch 817/5000\n",
      "10780/10780 [==============================] - 0s 32us/sample - loss: 7.7646 - accuracy: 0.5012 - val_loss: 7.7721 - val_accuracy: 0.5012\n",
      "Epoch 818/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7673 - accuracy: 0.5012 - val_loss: 7.7686 - val_accuracy: 0.5011\n",
      "Epoch 819/5000\n",
      "10780/10780 [==============================] - 0s 30us/sample - loss: 7.7673 - accuracy: 0.5012 - val_loss: 7.7729 - val_accuracy: 0.5012\n",
      "Epoch 820/5000\n",
      "10780/10780 [==============================] - 0s 32us/sample - loss: 7.7672 - accuracy: 0.5012 - val_loss: 7.7664 - val_accuracy: 0.5012\n",
      "Epoch 821/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7638 - accuracy: 0.5012 - val_loss: 7.7639 - val_accuracy: 0.5012\n",
      "Epoch 822/5000\n",
      "10780/10780 [==============================] - 0s 30us/sample - loss: 7.7627 - accuracy: 0.5012 - val_loss: 7.7619 - val_accuracy: 0.5012\n",
      "Epoch 823/5000\n",
      "10780/10780 [==============================] - 0s 29us/sample - loss: 7.7633 - accuracy: 0.5707 - val_loss: 7.7634 - val_accuracy: 0.5012\n",
      "Epoch 824/5000\n",
      "10780/10780 [==============================] - 0s 29us/sample - loss: 7.7632 - accuracy: 0.5012 - val_loss: 7.7628 - val_accuracy: 0.5012\n",
      "Epoch 825/5000\n",
      "10780/10780 [==============================] - 0s 29us/sample - loss: 7.7632 - accuracy: 0.5242 - val_loss: 7.7645 - val_accuracy: 0.5012\n",
      "Epoch 826/5000\n",
      "10780/10780 [==============================] - 0s 30us/sample - loss: 7.7667 - accuracy: 0.5012 - val_loss: 7.7633 - val_accuracy: 0.5013\n",
      "Epoch 827/5000\n",
      "10780/10780 [==============================] - 0s 30us/sample - loss: 7.7651 - accuracy: 0.5012 - val_loss: 7.7647 - val_accuracy: 0.5012\n",
      "Epoch 828/5000\n",
      "10780/10780 [==============================] - 0s 32us/sample - loss: 7.7629 - accuracy: 0.5012 - val_loss: 7.7623 - val_accuracy: 0.5012\n",
      "Epoch 829/5000\n",
      "10780/10780 [==============================] - 0s 29us/sample - loss: 7.7622 - accuracy: 0.5012 - val_loss: 7.7657 - val_accuracy: 0.5012\n",
      "Epoch 830/5000\n",
      "10780/10780 [==============================] - 0s 30us/sample - loss: 7.7629 - accuracy: 0.5012 - val_loss: 7.7653 - val_accuracy: 0.5012\n",
      "Epoch 831/5000\n",
      "10780/10780 [==============================] - 0s 31us/sample - loss: 7.7663 - accuracy: 0.5012 - val_loss: 7.7629 - val_accuracy: 0.5012\n",
      "Epoch 832/5000\n",
      "10780/10780 [==============================] - 0s 31us/sample - loss: 7.7637 - accuracy: 0.5012 - val_loss: 7.7616 - val_accuracy: 0.5012\n",
      "Epoch 833/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7625 - accuracy: 0.5012 - val_loss: 7.7621 - val_accuracy: 0.5012\n",
      "Epoch 834/5000\n",
      "10780/10780 [==============================] - 0s 31us/sample - loss: 7.7622 - accuracy: 0.5012 - val_loss: 7.7619 - val_accuracy: 0.5012\n",
      "Epoch 835/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7629 - accuracy: 0.5012 - val_loss: 7.7675 - val_accuracy: 0.5012\n",
      "Epoch 836/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7644 - accuracy: 0.5012 - val_loss: 7.7636 - val_accuracy: 0.5012\n",
      "Epoch 837/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7627 - accuracy: 0.5012 - val_loss: 7.7632 - val_accuracy: 0.5012\n",
      "Epoch 838/5000\n",
      "10780/10780 [==============================] - 0s 31us/sample - loss: 7.7626 - accuracy: 0.5012 - val_loss: 7.7622 - val_accuracy: 0.5012\n",
      "Epoch 839/5000\n",
      "10780/10780 [==============================] - 0s 31us/sample - loss: 7.7622 - accuracy: 0.5012 - val_loss: 7.7645 - val_accuracy: 0.5012\n",
      "Epoch 840/5000\n",
      "10780/10780 [==============================] - 1s 54us/sample - loss: 7.7635 - accuracy: 0.5242 - val_loss: 7.7626 - val_accuracy: 0.5012\n",
      "Epoch 841/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7626 - accuracy: 0.6175 - val_loss: 7.7681 - val_accuracy: 0.5012\n",
      "Epoch 842/5000\n",
      "10780/10780 [==============================] - 0s 30us/sample - loss: 7.7671 - accuracy: 0.5012 - val_loss: 7.7691 - val_accuracy: 0.5011\n",
      "Epoch 843/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7653 - accuracy: 0.5370 - val_loss: 7.7652 - val_accuracy: 1.0000\n",
      "Epoch 844/5000\n",
      "10780/10780 [==============================] - 0s 31us/sample - loss: 7.7666 - accuracy: 0.5243 - val_loss: 7.7647 - val_accuracy: 0.5012\n",
      "Epoch 845/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7660 - accuracy: 0.5701 - val_loss: 7.7620 - val_accuracy: 0.5012\n",
      "Epoch 846/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7654 - accuracy: 0.5012 - val_loss: 7.7636 - val_accuracy: 0.5011\n",
      "Epoch 847/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7637 - accuracy: 0.5012 - val_loss: 7.7610 - val_accuracy: 0.5012\n",
      "Epoch 848/5000\n",
      "10780/10780 [==============================] - 0s 29us/sample - loss: 7.7623 - accuracy: 0.5368 - val_loss: 7.7617 - val_accuracy: 0.5012\n",
      "Epoch 849/5000\n",
      "10780/10780 [==============================] - 0s 30us/sample - loss: 7.7621 - accuracy: 0.5241 - val_loss: 7.7615 - val_accuracy: 0.5012\n",
      "Epoch 850/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10780/10780 [==============================] - 0s 29us/sample - loss: 7.7642 - accuracy: 0.5012 - val_loss: 7.7654 - val_accuracy: 0.5012\n",
      "Epoch 851/5000\n",
      "10780/10780 [==============================] - 0s 30us/sample - loss: 7.7646 - accuracy: 0.5012 - val_loss: 7.7610 - val_accuracy: 0.5012\n",
      "Epoch 852/5000\n",
      "10780/10780 [==============================] - 0s 29us/sample - loss: 7.7631 - accuracy: 0.5012 - val_loss: 7.7615 - val_accuracy: 0.5011\n",
      "Epoch 853/5000\n",
      "10780/10780 [==============================] - 0s 29us/sample - loss: 7.7633 - accuracy: 0.5012 - val_loss: 7.7615 - val_accuracy: 0.5011\n",
      "Epoch 854/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7625 - accuracy: 0.5012 - val_loss: 7.7633 - val_accuracy: 0.5012\n",
      "Epoch 855/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7632 - accuracy: 0.5009 - val_loss: 7.7618 - val_accuracy: 0.5012\n",
      "Epoch 856/5000\n",
      "10780/10780 [==============================] - 0s 46us/sample - loss: 7.7661 - accuracy: 0.5012 - val_loss: 7.7693 - val_accuracy: 0.5012\n",
      "Epoch 857/5000\n",
      "10780/10780 [==============================] - 0s 44us/sample - loss: 7.7632 - accuracy: 0.5012 - val_loss: 7.7636 - val_accuracy: 0.5013\n",
      "Epoch 858/5000\n",
      "10780/10780 [==============================] - 0s 45us/sample - loss: 7.7639 - accuracy: 0.5012 - val_loss: 7.7634 - val_accuracy: 0.5013\n",
      "Epoch 859/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7627 - accuracy: 0.5012 - val_loss: 7.7631 - val_accuracy: 0.5012\n",
      "Epoch 860/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7624 - accuracy: 0.5708 - val_loss: 7.7641 - val_accuracy: 0.5012\n",
      "Epoch 861/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7634 - accuracy: 0.5244 - val_loss: 7.7639 - val_accuracy: 0.5013\n",
      "Epoch 862/5000\n",
      "10780/10780 [==============================] - 0s 28us/sample - loss: 7.7630 - accuracy: 0.5012 - val_loss: 7.7603 - val_accuracy: 0.5013\n",
      "Epoch 863/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7627 - accuracy: 0.5012 - val_loss: 7.7647 - val_accuracy: 0.5012\n",
      "Epoch 864/5000\n",
      "10780/10780 [==============================] - 1s 48us/sample - loss: 7.7631 - accuracy: 0.5012 - val_loss: 7.7640 - val_accuracy: 0.5012\n",
      "Epoch 865/5000\n",
      "10780/10780 [==============================] - 1s 48us/sample - loss: 7.7634 - accuracy: 0.5012 - val_loss: 7.7611 - val_accuracy: 0.5012\n",
      "Epoch 866/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7628 - accuracy: 0.5012 - val_loss: 7.7638 - val_accuracy: 0.5012\n",
      "Epoch 867/5000\n",
      "10780/10780 [==============================] - 0s 43us/sample - loss: 7.7650 - accuracy: 0.6178 - val_loss: 7.7617 - val_accuracy: 0.5012\n",
      "Epoch 868/5000\n",
      "10780/10780 [==============================] - 0s 43us/sample - loss: 7.7621 - accuracy: 0.5012 - val_loss: 7.7637 - val_accuracy: 0.5012\n",
      "Epoch 869/5000\n",
      "10780/10780 [==============================] - 0s 43us/sample - loss: 7.7625 - accuracy: 0.5012 - val_loss: 7.7614 - val_accuracy: 0.5012\n",
      "Epoch 870/5000\n",
      "10780/10780 [==============================] - 0s 43us/sample - loss: 7.7656 - accuracy: 0.5473 - val_loss: 7.7740 - val_accuracy: 0.5013\n",
      "Epoch 871/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7651 - accuracy: 0.5245 - val_loss: 7.7613 - val_accuracy: 0.5013\n",
      "Epoch 872/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7621 - accuracy: 0.5012 - val_loss: 7.7613 - val_accuracy: 0.5012\n",
      "Epoch 873/5000\n",
      "10780/10780 [==============================] - 1s 48us/sample - loss: 7.7617 - accuracy: 0.5242 - val_loss: 7.7623 - val_accuracy: 0.5012\n",
      "Epoch 874/5000\n",
      "10780/10780 [==============================] - 0s 46us/sample - loss: 7.7646 - accuracy: 0.5243 - val_loss: 7.7636 - val_accuracy: 0.5012\n",
      "Epoch 875/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7643 - accuracy: 0.5012 - val_loss: 7.7643 - val_accuracy: 0.5012\n",
      "Epoch 876/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7621 - accuracy: 0.5012 - val_loss: 7.7611 - val_accuracy: 0.5012\n",
      "Epoch 877/5000\n",
      "10780/10780 [==============================] - 0s 44us/sample - loss: 7.7617 - accuracy: 0.5476 - val_loss: 7.7627 - val_accuracy: 0.5012\n",
      "Epoch 878/5000\n",
      "10780/10780 [==============================] - 1s 51us/sample - loss: 7.7671 - accuracy: 0.5012 - val_loss: 7.7681 - val_accuracy: 0.5012\n",
      "Epoch 879/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7684 - accuracy: 0.5012 - val_loss: 7.7647 - val_accuracy: 0.5012\n",
      "Epoch 880/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7644 - accuracy: 0.5012 - val_loss: 7.7651 - val_accuracy: 0.5012\n",
      "Epoch 881/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7670 - accuracy: 0.5012 - val_loss: 7.7661 - val_accuracy: 0.5013\n",
      "Epoch 882/5000\n",
      "10780/10780 [==============================] - 0s 31us/sample - loss: 7.7642 - accuracy: 0.5012 - val_loss: 7.7630 - val_accuracy: 0.5012\n",
      "Epoch 883/5000\n",
      "10780/10780 [==============================] - 0s 31us/sample - loss: 7.7671 - accuracy: 0.5012 - val_loss: 7.7643 - val_accuracy: 0.5011\n",
      "Epoch 884/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7653 - accuracy: 0.5012 - val_loss: 7.7623 - val_accuracy: 0.5012\n",
      "Epoch 885/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7653 - accuracy: 0.5242 - val_loss: 7.7652 - val_accuracy: 0.5011\n",
      "Epoch 886/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7657 - accuracy: 0.5012 - val_loss: 7.7646 - val_accuracy: 0.5012\n",
      "Epoch 887/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7632 - accuracy: 0.5934 - val_loss: 7.7609 - val_accuracy: 0.5012\n",
      "Epoch 888/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7622 - accuracy: 0.6397 - val_loss: 7.7638 - val_accuracy: 0.5012\n",
      "Epoch 889/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7628 - accuracy: 0.5012 - val_loss: 7.7644 - val_accuracy: 0.5012\n",
      "Epoch 890/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7624 - accuracy: 0.5012 - val_loss: 7.7629 - val_accuracy: 0.5012\n",
      "Epoch 891/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7641 - accuracy: 0.5242 - val_loss: 7.7620 - val_accuracy: 0.5012\n",
      "Epoch 892/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7622 - accuracy: 0.5012 - val_loss: 7.7624 - val_accuracy: 0.5012\n",
      "Epoch 893/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7629 - accuracy: 0.5012 - val_loss: 7.7674 - val_accuracy: 0.5012\n",
      "Epoch 894/5000\n",
      "10780/10780 [==============================] - 0s 31us/sample - loss: 7.7640 - accuracy: 0.5244 - val_loss: 7.7634 - val_accuracy: 0.5012\n",
      "Epoch 895/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7617 - accuracy: 0.5012 - val_loss: 7.7625 - val_accuracy: 0.5012\n",
      "Epoch 896/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7621 - accuracy: 0.5714 - val_loss: 7.7615 - val_accuracy: 0.5012\n",
      "Epoch 897/5000\n",
      "10780/10780 [==============================] - 1s 47us/sample - loss: 7.7622 - accuracy: 0.5012 - val_loss: 7.7615 - val_accuracy: 0.5012\n",
      "Epoch 898/5000\n",
      "10780/10780 [==============================] - 1s 48us/sample - loss: 7.7624 - accuracy: 0.5012 - val_loss: 7.7623 - val_accuracy: 0.5012\n",
      "Epoch 899/5000\n",
      "10780/10780 [==============================] - 1s 48us/sample - loss: 7.7643 - accuracy: 0.5374 - val_loss: 7.7652 - val_accuracy: 0.5013\n",
      "Epoch 900/5000\n",
      "10780/10780 [==============================] - 1s 47us/sample - loss: 7.7635 - accuracy: 0.5474 - val_loss: 7.7616 - val_accuracy: 0.5012\n",
      "Epoch 901/5000\n",
      "10780/10780 [==============================] - 1s 47us/sample - loss: 7.7618 - accuracy: 0.6167 - val_loss: 7.7635 - val_accuracy: 0.5012\n",
      "Epoch 902/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7626 - accuracy: 0.5243 - val_loss: 7.7627 - val_accuracy: 0.5012\n",
      "Epoch 903/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7626 - accuracy: 0.5012 - val_loss: 7.7620 - val_accuracy: 0.5012\n",
      "Epoch 904/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7638 - accuracy: 0.5012 - val_loss: 7.7624 - val_accuracy: 0.5012\n",
      "Epoch 905/5000\n",
      "10780/10780 [==============================] - 0s 32us/sample - loss: 7.7627 - accuracy: 0.5242 - val_loss: 7.7663 - val_accuracy: 0.5013\n",
      "Epoch 906/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7653 - accuracy: 0.5477 - val_loss: 7.7663 - val_accuracy: 0.5012\n",
      "Epoch 907/5000\n",
      "10780/10780 [==============================] - 0s 31us/sample - loss: 7.7655 - accuracy: 0.5142 - val_loss: 7.7652 - val_accuracy: 1.0000\n",
      "Epoch 908/5000\n",
      "10780/10780 [==============================] - 0s 31us/sample - loss: 7.7635 - accuracy: 0.5702 - val_loss: 7.7613 - val_accuracy: 0.5012\n",
      "Epoch 909/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7630 - accuracy: 0.5012 - val_loss: 7.7647 - val_accuracy: 0.5012\n",
      "Epoch 910/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7639 - accuracy: 0.4780 - val_loss: 7.7698 - val_accuracy: 0.5013\n",
      "Epoch 911/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7665 - accuracy: 0.5012 - val_loss: 7.7614 - val_accuracy: 0.5012\n",
      "Epoch 912/5000\n",
      "10780/10780 [==============================] - 0s 43us/sample - loss: 7.7631 - accuracy: 0.5012 - val_loss: 7.7624 - val_accuracy: 0.5012\n",
      "Epoch 913/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7624 - accuracy: 0.5244 - val_loss: 7.7626 - val_accuracy: 0.5012\n",
      "Epoch 914/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7621 - accuracy: 0.5012 - val_loss: 7.7623 - val_accuracy: 0.5012\n",
      "Epoch 915/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7628 - accuracy: 0.5715 - val_loss: 7.7641 - val_accuracy: 0.5012\n",
      "Epoch 916/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7628 - accuracy: 0.6398 - val_loss: 7.7614 - val_accuracy: 0.5012\n",
      "Epoch 917/5000\n",
      "10780/10780 [==============================] - 0s 30us/sample - loss: 7.7648 - accuracy: 0.5706 - val_loss: 7.7639 - val_accuracy: 0.5012\n",
      "Epoch 918/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7628 - accuracy: 0.5012 - val_loss: 7.7625 - val_accuracy: 0.5012\n",
      "Epoch 919/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7638 - accuracy: 0.5012 - val_loss: 7.7664 - val_accuracy: 1.0000\n",
      "Epoch 920/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7637 - accuracy: 0.5473 - val_loss: 7.7630 - val_accuracy: 0.5012\n",
      "Epoch 921/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7626 - accuracy: 0.5012 - val_loss: 7.7620 - val_accuracy: 0.5012\n",
      "Epoch 922/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7625 - accuracy: 0.5709 - val_loss: 7.7664 - val_accuracy: 0.5012\n",
      "Epoch 923/5000\n",
      "10780/10780 [==============================] - 0s 31us/sample - loss: 7.7628 - accuracy: 0.5602 - val_loss: 7.7657 - val_accuracy: 1.0000\n",
      "Epoch 924/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7642 - accuracy: 0.5242 - val_loss: 7.7618 - val_accuracy: 0.5012\n",
      "Epoch 925/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7621 - accuracy: 0.5706 - val_loss: 7.7616 - val_accuracy: 0.5012\n",
      "Epoch 926/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7621 - accuracy: 0.5012 - val_loss: 7.7625 - val_accuracy: 0.5012\n",
      "Epoch 927/5000\n",
      "10780/10780 [==============================] - 0s 32us/sample - loss: 7.7647 - accuracy: 0.5012 - val_loss: 7.7635 - val_accuracy: 0.5012\n",
      "Epoch 928/5000\n",
      "10780/10780 [==============================] - 0s 32us/sample - loss: 7.7628 - accuracy: 0.5012 - val_loss: 7.7622 - val_accuracy: 0.5012\n",
      "Epoch 929/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7623 - accuracy: 0.5012 - val_loss: 7.7615 - val_accuracy: 0.5012\n",
      "Epoch 930/5000\n",
      "10780/10780 [==============================] - 1s 47us/sample - loss: 7.7619 - accuracy: 0.5012 - val_loss: 7.7650 - val_accuracy: 0.5012\n",
      "Epoch 931/5000\n",
      "10780/10780 [==============================] - 1s 47us/sample - loss: 7.7622 - accuracy: 0.5709 - val_loss: 7.7611 - val_accuracy: 0.5012\n",
      "Epoch 932/5000\n",
      "10780/10780 [==============================] - 1s 47us/sample - loss: 7.7619 - accuracy: 0.5012 - val_loss: 7.7616 - val_accuracy: 0.5012\n",
      "Epoch 933/5000\n",
      "10780/10780 [==============================] - 0s 43us/sample - loss: 7.7647 - accuracy: 0.5012 - val_loss: 7.7658 - val_accuracy: 0.5013\n",
      "Epoch 934/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7653 - accuracy: 0.5012 - val_loss: 7.7659 - val_accuracy: 0.5011\n",
      "Epoch 935/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7635 - accuracy: 0.5012 - val_loss: 7.7656 - val_accuracy: 0.5011\n",
      "Epoch 936/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7644 - accuracy: 0.5012 - val_loss: 7.7639 - val_accuracy: 0.5011\n",
      "Epoch 937/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7632 - accuracy: 0.5012 - val_loss: 7.7620 - val_accuracy: 0.5011\n",
      "Epoch 938/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7638 - accuracy: 0.5479 - val_loss: 7.7648 - val_accuracy: 0.5012\n",
      "Epoch 939/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7626 - accuracy: 0.5243 - val_loss: 7.7624 - val_accuracy: 0.5012\n",
      "Epoch 940/5000\n",
      "10780/10780 [==============================] - 0s 32us/sample - loss: 7.7619 - accuracy: 0.5012 - val_loss: 7.7610 - val_accuracy: 0.5012\n",
      "Epoch 941/5000\n",
      "10780/10780 [==============================] - 1s 49us/sample - loss: 7.7645 - accuracy: 0.5012 - val_loss: 7.7613 - val_accuracy: 0.5012\n",
      "Epoch 942/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7661 - accuracy: 0.5012 - val_loss: 7.7673 - val_accuracy: 0.5012\n",
      "Epoch 943/5000\n",
      "10780/10780 [==============================] - 0s 32us/sample - loss: 7.7655 - accuracy: 0.5012 - val_loss: 7.7635 - val_accuracy: 0.5012\n",
      "Epoch 944/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7632 - accuracy: 0.5012 - val_loss: 7.7629 - val_accuracy: 0.5012\n",
      "Epoch 945/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7631 - accuracy: 0.5012 - val_loss: 7.7623 - val_accuracy: 0.5011\n",
      "Epoch 946/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7638 - accuracy: 0.5012 - val_loss: 7.7648 - val_accuracy: 0.5012\n",
      "Epoch 947/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7626 - accuracy: 0.5012 - val_loss: 7.7623 - val_accuracy: 0.5012\n",
      "Epoch 948/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7642 - accuracy: 0.5012 - val_loss: 7.7624 - val_accuracy: 0.5012\n",
      "Epoch 949/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7625 - accuracy: 0.5244 - val_loss: 7.7618 - val_accuracy: 0.5012\n",
      "Epoch 950/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7619 - accuracy: 0.5703 - val_loss: 7.7618 - val_accuracy: 0.5012\n",
      "Epoch 951/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7637 - accuracy: 0.5012 - val_loss: 7.7622 - val_accuracy: 0.5012\n",
      "Epoch 952/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7640 - accuracy: 0.5012 - val_loss: 7.7647 - val_accuracy: 0.5012\n",
      "Epoch 953/5000\n",
      "10780/10780 [==============================] - 1s 47us/sample - loss: 7.7624 - accuracy: 0.5012 - val_loss: 7.7613 - val_accuracy: 0.5012\n",
      "Epoch 954/5000\n",
      "10780/10780 [==============================] - 1s 58us/sample - loss: 7.7617 - accuracy: 0.5012 - val_loss: 7.7612 - val_accuracy: 0.5012\n",
      "Epoch 955/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7627 - accuracy: 0.5241 - val_loss: 7.7623 - val_accuracy: 0.5012\n",
      "Epoch 956/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7621 - accuracy: 0.5012 - val_loss: 7.7659 - val_accuracy: 0.5011\n",
      "Epoch 957/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7626 - accuracy: 0.5012 - val_loss: 7.7643 - val_accuracy: 0.5012\n",
      "Epoch 958/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7625 - accuracy: 0.5012 - val_loss: 7.7622 - val_accuracy: 0.5012\n",
      "Epoch 959/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7622 - accuracy: 0.5935 - val_loss: 7.7621 - val_accuracy: 0.5012\n",
      "Epoch 960/5000\n",
      "10780/10780 [==============================] - 0s 32us/sample - loss: 7.7625 - accuracy: 0.5012 - val_loss: 7.7618 - val_accuracy: 0.5011\n",
      "Epoch 961/5000\n",
      "10780/10780 [==============================] - 0s 31us/sample - loss: 7.7672 - accuracy: 0.5366 - val_loss: 7.7700 - val_accuracy: 0.5011\n",
      "Epoch 962/5000\n",
      "10780/10780 [==============================] - 0s 29us/sample - loss: 7.7662 - accuracy: 0.5012 - val_loss: 7.7656 - val_accuracy: 0.5012\n",
      "Epoch 963/5000\n",
      "10780/10780 [==============================] - 0s 27us/sample - loss: 7.7639 - accuracy: 0.5012 - val_loss: 7.7644 - val_accuracy: 0.5012\n",
      "Epoch 964/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7625 - accuracy: 0.5474 - val_loss: 7.7615 - val_accuracy: 0.5012\n",
      "Epoch 965/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7627 - accuracy: 0.5012 - val_loss: 7.7635 - val_accuracy: 0.5012\n",
      "Epoch 966/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7668 - accuracy: 0.5012 - val_loss: 7.7622 - val_accuracy: 0.5012\n",
      "Epoch 967/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7658 - accuracy: 0.5012 - val_loss: 7.7639 - val_accuracy: 0.5012\n",
      "Epoch 968/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7659 - accuracy: 0.5012 - val_loss: 7.7667 - val_accuracy: 0.5012\n",
      "Epoch 969/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7641 - accuracy: 0.5372 - val_loss: 7.7668 - val_accuracy: 0.5012\n",
      "Epoch 970/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7636 - accuracy: 0.5012 - val_loss: 7.7624 - val_accuracy: 0.5011\n",
      "Epoch 971/5000\n",
      "10780/10780 [==============================] - 0s 32us/sample - loss: 7.7620 - accuracy: 0.5012 - val_loss: 7.7625 - val_accuracy: 0.5011\n",
      "Epoch 972/5000\n",
      "10780/10780 [==============================] - 0s 30us/sample - loss: 7.7618 - accuracy: 0.5012 - val_loss: 7.7621 - val_accuracy: 0.5012\n",
      "Epoch 973/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7618 - accuracy: 0.5012 - val_loss: 7.7614 - val_accuracy: 0.5012\n",
      "Epoch 974/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7623 - accuracy: 0.5012 - val_loss: 7.7627 - val_accuracy: 0.5012\n",
      "Epoch 975/5000\n",
      "10780/10780 [==============================] - 0s 32us/sample - loss: 7.7641 - accuracy: 0.5012 - val_loss: 7.7650 - val_accuracy: 0.5012\n",
      "Epoch 976/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7633 - accuracy: 0.5012 - val_loss: 7.7614 - val_accuracy: 0.5012\n",
      "Epoch 977/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7622 - accuracy: 0.5012 - val_loss: 7.7618 - val_accuracy: 0.5012\n",
      "Epoch 978/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7618 - accuracy: 0.5012 - val_loss: 7.7621 - val_accuracy: 0.5012\n",
      "Epoch 979/5000\n",
      "10780/10780 [==============================] - 0s 29us/sample - loss: 7.7625 - accuracy: 0.5012 - val_loss: 7.7623 - val_accuracy: 0.5012\n",
      "Epoch 980/5000\n",
      "10780/10780 [==============================] - 0s 31us/sample - loss: 7.7629 - accuracy: 0.5012 - val_loss: 7.7640 - val_accuracy: 0.5011\n",
      "Epoch 981/5000\n",
      "10780/10780 [==============================] - 0s 32us/sample - loss: 7.7628 - accuracy: 0.5012 - val_loss: 7.7624 - val_accuracy: 0.5012\n",
      "Epoch 982/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7622 - accuracy: 0.5012 - val_loss: 7.7658 - val_accuracy: 0.5012\n",
      "Epoch 983/5000\n",
      "10780/10780 [==============================] - 0s 28us/sample - loss: 7.7624 - accuracy: 0.5012 - val_loss: 7.7616 - val_accuracy: 0.5012\n",
      "Epoch 984/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7623 - accuracy: 0.5012 - val_loss: 7.7624 - val_accuracy: 0.5012\n",
      "Epoch 985/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7621 - accuracy: 0.5939 - val_loss: 7.7630 - val_accuracy: 0.5012\n",
      "Epoch 986/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7633 - accuracy: 0.5012 - val_loss: 7.7616 - val_accuracy: 0.5012\n",
      "Epoch 987/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7655 - accuracy: 0.5012 - val_loss: 7.7658 - val_accuracy: 0.5012\n",
      "Epoch 988/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7644 - accuracy: 0.5012 - val_loss: 7.7623 - val_accuracy: 0.5012\n",
      "Epoch 989/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7620 - accuracy: 0.5012 - val_loss: 7.7611 - val_accuracy: 0.5012\n",
      "Epoch 990/5000\n",
      "10780/10780 [==============================] - 0s 44us/sample - loss: 7.7622 - accuracy: 0.5012 - val_loss: 7.7635 - val_accuracy: 0.5012\n",
      "Epoch 991/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7627 - accuracy: 0.5012 - val_loss: 7.7624 - val_accuracy: 0.5012\n",
      "Epoch 992/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7621 - accuracy: 0.5606 - val_loss: 7.7621 - val_accuracy: 1.0000\n",
      "Epoch 993/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7621 - accuracy: 0.5244 - val_loss: 7.7622 - val_accuracy: 0.5012\n",
      "Epoch 994/5000\n",
      "10780/10780 [==============================] - 0s 31us/sample - loss: 7.7626 - accuracy: 0.5011 - val_loss: 7.7625 - val_accuracy: 0.5012\n",
      "Epoch 995/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7626 - accuracy: 0.5012 - val_loss: 7.7631 - val_accuracy: 0.5011\n",
      "Epoch 996/5000\n",
      "10780/10780 [==============================] - 0s 32us/sample - loss: 7.7626 - accuracy: 0.5010 - val_loss: 7.7624 - val_accuracy: 0.5011\n",
      "Epoch 997/5000\n",
      "10780/10780 [==============================] - 0s 32us/sample - loss: 7.7629 - accuracy: 0.5012 - val_loss: 7.7646 - val_accuracy: 0.5011\n",
      "Epoch 998/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7634 - accuracy: 0.5012 - val_loss: 7.7620 - val_accuracy: 0.5012\n",
      "Epoch 999/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7633 - accuracy: 0.5012 - val_loss: 7.7630 - val_accuracy: 0.5012\n",
      "Epoch 1000/5000\n",
      "10780/10780 [==============================] - 0s 30us/sample - loss: 7.7654 - accuracy: 0.5012 - val_loss: 7.7644 - val_accuracy: 0.5012\n",
      "Epoch 1001/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7662 - accuracy: 0.5707 - val_loss: 7.7639 - val_accuracy: 0.5012\n",
      "Epoch 1002/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7637 - accuracy: 0.5012 - val_loss: 7.7644 - val_accuracy: 0.5012\n",
      "Epoch 1003/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7627 - accuracy: 0.5012 - val_loss: 7.7638 - val_accuracy: 0.5012\n",
      "Epoch 1004/5000\n",
      "10780/10780 [==============================] - 0s 32us/sample - loss: 7.7643 - accuracy: 0.5012 - val_loss: 7.7738 - val_accuracy: 0.5012\n",
      "Epoch 1005/5000\n",
      "10780/10780 [==============================] - 0s 30us/sample - loss: 7.7653 - accuracy: 0.5012 - val_loss: 7.7622 - val_accuracy: 0.5012\n",
      "Epoch 1006/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7626 - accuracy: 0.5012 - val_loss: 7.7637 - val_accuracy: 0.5012\n",
      "Epoch 1007/5000\n",
      "10780/10780 [==============================] - 0s 29us/sample - loss: 7.7625 - accuracy: 0.5012 - val_loss: 7.7601 - val_accuracy: 0.5012\n",
      "Epoch 1008/5000\n",
      "10780/10780 [==============================] - 0s 30us/sample - loss: 7.7628 - accuracy: 0.5012 - val_loss: 7.7650 - val_accuracy: 0.5012\n",
      "Epoch 1009/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10780/10780 [==============================] - 0s 31us/sample - loss: 7.7631 - accuracy: 0.5247 - val_loss: 7.7628 - val_accuracy: 0.5012\n",
      "Epoch 1010/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7618 - accuracy: 0.5012 - val_loss: 7.7628 - val_accuracy: 0.5011\n",
      "Epoch 1011/5000\n",
      "10780/10780 [==============================] - 0s 29us/sample - loss: 7.7655 - accuracy: 0.5011 - val_loss: 7.7671 - val_accuracy: 0.5012\n",
      "Epoch 1012/5000\n",
      "10780/10780 [==============================] - 0s 32us/sample - loss: 7.7648 - accuracy: 0.5012 - val_loss: 7.7611 - val_accuracy: 0.5012\n",
      "Epoch 1013/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7619 - accuracy: 0.5012 - val_loss: 7.7633 - val_accuracy: 0.5012\n",
      "Epoch 1014/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7624 - accuracy: 0.5012 - val_loss: 7.7622 - val_accuracy: 0.5011\n",
      "Epoch 1015/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7628 - accuracy: 0.5012 - val_loss: 7.7612 - val_accuracy: 0.5012\n",
      "Epoch 1016/5000\n",
      "10780/10780 [==============================] - 0s 31us/sample - loss: 7.7629 - accuracy: 0.5012 - val_loss: 7.7637 - val_accuracy: 0.5011\n",
      "Epoch 1017/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7634 - accuracy: 0.5012 - val_loss: 7.7614 - val_accuracy: 0.5012\n",
      "Epoch 1018/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7631 - accuracy: 0.5012 - val_loss: 7.7616 - val_accuracy: 0.5012\n",
      "Epoch 1019/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7639 - accuracy: 0.5706 - val_loss: 7.7641 - val_accuracy: 0.5012\n",
      "Epoch 1020/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7634 - accuracy: 0.5709 - val_loss: 7.7618 - val_accuracy: 0.5012\n",
      "Epoch 1021/5000\n",
      "10780/10780 [==============================] - 0s 29us/sample - loss: 7.7616 - accuracy: 0.5840 - val_loss: 7.7617 - val_accuracy: 1.0000\n",
      "Epoch 1022/5000\n",
      "10780/10780 [==============================] - 0s 44us/sample - loss: 7.7652 - accuracy: 0.5244 - val_loss: 7.7625 - val_accuracy: 0.5012\n",
      "Epoch 1023/5000\n",
      "10780/10780 [==============================] - 0s 43us/sample - loss: 7.7629 - accuracy: 0.5012 - val_loss: 7.7635 - val_accuracy: 0.5011\n",
      "Epoch 1024/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7632 - accuracy: 0.5012 - val_loss: 7.7633 - val_accuracy: 0.5012\n",
      "Epoch 1025/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7618 - accuracy: 0.5481 - val_loss: 7.7621 - val_accuracy: 0.5012\n",
      "Epoch 1026/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7631 - accuracy: 0.5476 - val_loss: 7.7622 - val_accuracy: 0.5012\n",
      "Epoch 1027/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7633 - accuracy: 0.5370 - val_loss: 7.7646 - val_accuracy: 0.5012\n",
      "Epoch 1028/5000\n",
      "10780/10780 [==============================] - 0s 44us/sample - loss: 7.7645 - accuracy: 0.5242 - val_loss: 7.7618 - val_accuracy: 0.5011\n",
      "Epoch 1029/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7629 - accuracy: 0.6166 - val_loss: 7.7649 - val_accuracy: 0.5012\n",
      "Epoch 1030/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7652 - accuracy: 0.5012 - val_loss: 7.7698 - val_accuracy: 0.5011\n",
      "Epoch 1031/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7660 - accuracy: 0.5012 - val_loss: 7.7632 - val_accuracy: 0.5012\n",
      "Epoch 1032/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7650 - accuracy: 0.5012 - val_loss: 7.7623 - val_accuracy: 0.5012\n",
      "Epoch 1033/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7639 - accuracy: 0.5012 - val_loss: 7.7612 - val_accuracy: 0.5012\n",
      "Epoch 1034/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7644 - accuracy: 0.5012 - val_loss: 7.7625 - val_accuracy: 0.5011\n",
      "Epoch 1035/5000\n",
      "10780/10780 [==============================] - 1s 47us/sample - loss: 7.7628 - accuracy: 0.5011 - val_loss: 7.7619 - val_accuracy: 0.5012\n",
      "Epoch 1036/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7622 - accuracy: 0.5012 - val_loss: 7.7620 - val_accuracy: 0.5012\n",
      "Epoch 1037/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7624 - accuracy: 0.5012 - val_loss: 7.7710 - val_accuracy: 0.5013\n",
      "Epoch 1038/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7671 - accuracy: 0.5012 - val_loss: 7.7727 - val_accuracy: 0.5013\n",
      "Epoch 1039/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7640 - accuracy: 0.5012 - val_loss: 7.7623 - val_accuracy: 0.5011\n",
      "Epoch 1040/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7620 - accuracy: 0.5012 - val_loss: 7.7613 - val_accuracy: 0.5012\n",
      "Epoch 1041/5000\n",
      "10780/10780 [==============================] - 0s 30us/sample - loss: 7.7621 - accuracy: 0.5012 - val_loss: 7.7672 - val_accuracy: 0.5013\n",
      "Epoch 1042/5000\n",
      "10780/10780 [==============================] - 0s 32us/sample - loss: 7.7648 - accuracy: 0.5012 - val_loss: 7.7674 - val_accuracy: 0.5011\n",
      "Epoch 1043/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7669 - accuracy: 0.5011 - val_loss: 7.7648 - val_accuracy: 0.5012\n",
      "Epoch 1044/5000\n",
      "10780/10780 [==============================] - 0s 31us/sample - loss: 7.7666 - accuracy: 0.5012 - val_loss: 7.7625 - val_accuracy: 0.5012\n",
      "Epoch 1045/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7624 - accuracy: 0.5702 - val_loss: 7.7641 - val_accuracy: 0.5010\n",
      "Epoch 1046/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7625 - accuracy: 0.5012 - val_loss: 7.7621 - val_accuracy: 0.5012\n",
      "Epoch 1047/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7615 - accuracy: 0.5012 - val_loss: 7.7617 - val_accuracy: 0.5012\n",
      "Epoch 1048/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7634 - accuracy: 0.5012 - val_loss: 7.7654 - val_accuracy: 0.5012\n",
      "Epoch 1049/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7636 - accuracy: 0.5012 - val_loss: 7.7674 - val_accuracy: 0.5011\n",
      "Epoch 1050/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7639 - accuracy: 0.5012 - val_loss: 7.7640 - val_accuracy: 0.5012\n",
      "Epoch 1051/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7634 - accuracy: 0.5012 - val_loss: 7.7649 - val_accuracy: 0.5012\n",
      "Epoch 1052/5000\n",
      "10780/10780 [==============================] - 1s 54us/sample - loss: 7.7666 - accuracy: 0.5012 - val_loss: 7.7650 - val_accuracy: 0.5012\n",
      "Epoch 1053/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7627 - accuracy: 0.5012 - val_loss: 7.7638 - val_accuracy: 0.5012\n",
      "Epoch 1054/5000\n",
      "10780/10780 [==============================] - 0s 43us/sample - loss: 7.7623 - accuracy: 0.5012 - val_loss: 7.7626 - val_accuracy: 0.5012\n",
      "Epoch 1055/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7628 - accuracy: 0.5247 - val_loss: 7.7617 - val_accuracy: 0.5012\n",
      "Epoch 1056/5000\n",
      "10780/10780 [==============================] - 0s 44us/sample - loss: 7.7628 - accuracy: 0.5245 - val_loss: 7.7619 - val_accuracy: 0.5012\n",
      "Epoch 1057/5000\n",
      "10780/10780 [==============================] - 0s 44us/sample - loss: 7.7641 - accuracy: 0.5012 - val_loss: 7.7624 - val_accuracy: 0.5011\n",
      "Epoch 1058/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7627 - accuracy: 0.5012 - val_loss: 7.7611 - val_accuracy: 0.5012\n",
      "Epoch 1059/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7626 - accuracy: 0.5012 - val_loss: 7.7628 - val_accuracy: 0.5012\n",
      "Epoch 1060/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7628 - accuracy: 0.5468 - val_loss: 7.7637 - val_accuracy: 0.5012\n",
      "Epoch 1061/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7632 - accuracy: 0.5012 - val_loss: 7.7621 - val_accuracy: 0.5012\n",
      "Epoch 1062/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7619 - accuracy: 0.5012 - val_loss: 7.7625 - val_accuracy: 0.5012\n",
      "Epoch 1063/5000\n",
      "10780/10780 [==============================] - 0s 30us/sample - loss: 7.7624 - accuracy: 0.5012 - val_loss: 7.7611 - val_accuracy: 0.5012\n",
      "Epoch 1064/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7624 - accuracy: 0.5012 - val_loss: 7.7621 - val_accuracy: 0.5011\n",
      "Epoch 1065/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7629 - accuracy: 0.5012 - val_loss: 7.7616 - val_accuracy: 0.5012\n",
      "Epoch 1066/5000\n",
      "10780/10780 [==============================] - 0s 30us/sample - loss: 7.7630 - accuracy: 0.5012 - val_loss: 7.7621 - val_accuracy: 0.5012\n",
      "Epoch 1067/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7643 - accuracy: 0.5012 - val_loss: 7.7607 - val_accuracy: 0.5012\n",
      "Epoch 1068/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7620 - accuracy: 0.5012 - val_loss: 7.7622 - val_accuracy: 0.5012\n",
      "Epoch 1069/5000\n",
      "10780/10780 [==============================] - 0s 31us/sample - loss: 7.7620 - accuracy: 0.5012 - val_loss: 7.7620 - val_accuracy: 0.5012\n",
      "Epoch 1070/5000\n",
      "10780/10780 [==============================] - 0s 28us/sample - loss: 7.7635 - accuracy: 0.5012 - val_loss: 7.7611 - val_accuracy: 0.5012\n",
      "Epoch 1071/5000\n",
      "10780/10780 [==============================] - 0s 30us/sample - loss: 7.7637 - accuracy: 0.5012 - val_loss: 7.7635 - val_accuracy: 0.5012\n",
      "Epoch 1072/5000\n",
      "10780/10780 [==============================] - 0s 29us/sample - loss: 7.7630 - accuracy: 0.5012 - val_loss: 7.7667 - val_accuracy: 0.5012\n",
      "Epoch 1073/5000\n",
      "10780/10780 [==============================] - 0s 30us/sample - loss: 7.7634 - accuracy: 0.5708 - val_loss: 7.7642 - val_accuracy: 0.5012\n",
      "Epoch 1074/5000\n",
      "10780/10780 [==============================] - 0s 29us/sample - loss: 7.7628 - accuracy: 0.5012 - val_loss: 7.7626 - val_accuracy: 0.5012\n",
      "Epoch 1075/5000\n",
      "10780/10780 [==============================] - 0s 30us/sample - loss: 7.7622 - accuracy: 0.5012 - val_loss: 7.7621 - val_accuracy: 0.5012\n",
      "Epoch 1076/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7665 - accuracy: 0.5012 - val_loss: 7.7631 - val_accuracy: 0.5012\n",
      "Epoch 1077/5000\n",
      "10780/10780 [==============================] - 0s 45us/sample - loss: 7.7632 - accuracy: 0.5012 - val_loss: 7.7618 - val_accuracy: 0.5012\n",
      "Epoch 1078/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7623 - accuracy: 0.5012 - val_loss: 7.7620 - val_accuracy: 0.5012\n",
      "Epoch 1079/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7655 - accuracy: 0.5479 - val_loss: 7.7624 - val_accuracy: 0.5012\n",
      "Epoch 1080/5000\n",
      "10780/10780 [==============================] - 0s 30us/sample - loss: 7.7651 - accuracy: 0.5941 - val_loss: 7.7634 - val_accuracy: 0.5002\n",
      "Epoch 1081/5000\n",
      "10780/10780 [==============================] - 0s 30us/sample - loss: 7.7622 - accuracy: 0.5011 - val_loss: 7.7608 - val_accuracy: 0.5012\n",
      "Epoch 1082/5000\n",
      "10780/10780 [==============================] - 0s 30us/sample - loss: 7.7624 - accuracy: 0.5012 - val_loss: 7.7625 - val_accuracy: 0.5011\n",
      "Epoch 1083/5000\n",
      "10780/10780 [==============================] - 0s 30us/sample - loss: 7.7640 - accuracy: 0.5012 - val_loss: 7.7632 - val_accuracy: 0.5012\n",
      "Epoch 1084/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7623 - accuracy: 0.5012 - val_loss: 7.7615 - val_accuracy: 0.5012\n",
      "Epoch 1085/5000\n",
      "10780/10780 [==============================] - 0s 30us/sample - loss: 7.7622 - accuracy: 0.5012 - val_loss: 7.7656 - val_accuracy: 0.5011\n",
      "Epoch 1086/5000\n",
      "10780/10780 [==============================] - 0s 30us/sample - loss: 7.7675 - accuracy: 0.4783 - val_loss: 7.7643 - val_accuracy: 0.5012\n",
      "Epoch 1087/5000\n",
      "10780/10780 [==============================] - 0s 29us/sample - loss: 7.7640 - accuracy: 0.5012 - val_loss: 7.7624 - val_accuracy: 0.5013\n",
      "Epoch 1088/5000\n",
      "10780/10780 [==============================] - 0s 31us/sample - loss: 7.7625 - accuracy: 0.5012 - val_loss: 7.7624 - val_accuracy: 0.5012\n",
      "Epoch 1089/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7639 - accuracy: 0.5012 - val_loss: 7.7654 - val_accuracy: 0.5012\n",
      "Epoch 1090/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7641 - accuracy: 0.5012 - val_loss: 7.7654 - val_accuracy: 0.5012\n",
      "Epoch 1091/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7651 - accuracy: 0.5012 - val_loss: 7.7642 - val_accuracy: 0.5012\n",
      "Epoch 1092/5000\n",
      "10780/10780 [==============================] - 0s 32us/sample - loss: 7.7655 - accuracy: 0.5012 - val_loss: 7.7651 - val_accuracy: 0.5011\n",
      "Epoch 1093/5000\n",
      "10780/10780 [==============================] - 0s 32us/sample - loss: 7.7638 - accuracy: 0.5473 - val_loss: 7.7613 - val_accuracy: 0.5011\n",
      "Epoch 1094/5000\n",
      "10780/10780 [==============================] - 0s 32us/sample - loss: 7.7624 - accuracy: 0.5012 - val_loss: 7.7624 - val_accuracy: 0.5012\n",
      "Epoch 1095/5000\n",
      "10780/10780 [==============================] - 0s 31us/sample - loss: 7.7626 - accuracy: 0.5012 - val_loss: 7.7629 - val_accuracy: 0.5011\n",
      "Epoch 1096/5000\n",
      "10780/10780 [==============================] - 0s 30us/sample - loss: 7.7621 - accuracy: 0.5012 - val_loss: 7.7615 - val_accuracy: 0.5012\n",
      "Epoch 1097/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7624 - accuracy: 0.5012 - val_loss: 7.7618 - val_accuracy: 0.5011\n",
      "Epoch 1098/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7624 - accuracy: 0.5937 - val_loss: 7.7630 - val_accuracy: 0.5012\n",
      "Epoch 1099/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7625 - accuracy: 0.6862 - val_loss: 7.7635 - val_accuracy: 0.5012\n",
      "Epoch 1100/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7625 - accuracy: 0.5012 - val_loss: 7.7632 - val_accuracy: 0.5012\n",
      "Epoch 1101/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7621 - accuracy: 0.5010 - val_loss: 7.7623 - val_accuracy: 0.5012\n",
      "Epoch 1102/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7622 - accuracy: 0.5012 - val_loss: 7.7648 - val_accuracy: 0.5012\n",
      "Epoch 1103/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7623 - accuracy: 0.5012 - val_loss: 7.7668 - val_accuracy: 0.5012\n",
      "Epoch 1104/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7639 - accuracy: 0.5012 - val_loss: 7.7654 - val_accuracy: 0.5012\n",
      "Epoch 1105/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7624 - accuracy: 0.5012 - val_loss: 7.7627 - val_accuracy: 0.5012\n",
      "Epoch 1106/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7648 - accuracy: 0.5012 - val_loss: 7.7666 - val_accuracy: 0.5012\n",
      "Epoch 1107/5000\n",
      "10780/10780 [==============================] - 0s 32us/sample - loss: 7.7628 - accuracy: 0.5012 - val_loss: 7.7677 - val_accuracy: 0.5011\n",
      "Epoch 1108/5000\n",
      "10780/10780 [==============================] - 0s 32us/sample - loss: 7.7652 - accuracy: 0.5012 - val_loss: 7.7647 - val_accuracy: 0.5013\n",
      "Epoch 1109/5000\n",
      "10780/10780 [==============================] - 0s 30us/sample - loss: 7.7627 - accuracy: 0.5474 - val_loss: 7.7606 - val_accuracy: 0.5012\n",
      "Epoch 1110/5000\n",
      "10780/10780 [==============================] - 0s 31us/sample - loss: 7.7626 - accuracy: 0.5477 - val_loss: 7.7624 - val_accuracy: 0.5011\n",
      "Epoch 1111/5000\n",
      "10780/10780 [==============================] - 0s 30us/sample - loss: 7.7628 - accuracy: 0.5012 - val_loss: 7.7627 - val_accuracy: 0.5011\n",
      "Epoch 1112/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7619 - accuracy: 0.5245 - val_loss: 7.7614 - val_accuracy: 0.5012\n",
      "Epoch 1113/5000\n",
      "10780/10780 [==============================] - 0s 32us/sample - loss: 7.7627 - accuracy: 0.5012 - val_loss: 7.7627 - val_accuracy: 0.5012\n",
      "Epoch 1114/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7625 - accuracy: 0.5012 - val_loss: 7.7617 - val_accuracy: 0.5012\n",
      "Epoch 1115/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10780/10780 [==============================] - 0s 46us/sample - loss: 7.7645 - accuracy: 0.5012 - val_loss: 7.7620 - val_accuracy: 0.5012\n",
      "Epoch 1116/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7621 - accuracy: 0.5012 - val_loss: 7.7627 - val_accuracy: 0.5012\n",
      "Epoch 1117/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7619 - accuracy: 0.5012 - val_loss: 7.7623 - val_accuracy: 0.5012\n",
      "Epoch 1118/5000\n",
      "10780/10780 [==============================] - 0s 44us/sample - loss: 7.7618 - accuracy: 0.5012 - val_loss: 7.7620 - val_accuracy: 0.5012\n",
      "Epoch 1119/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7627 - accuracy: 0.5012 - val_loss: 7.7641 - val_accuracy: 0.5012\n",
      "Epoch 1120/5000\n",
      "10780/10780 [==============================] - 0s 32us/sample - loss: 7.7628 - accuracy: 0.5012 - val_loss: 7.7621 - val_accuracy: 0.5012\n",
      "Epoch 1121/5000\n",
      "10780/10780 [==============================] - 0s 32us/sample - loss: 7.7660 - accuracy: 0.5012 - val_loss: 7.7643 - val_accuracy: 0.5012\n",
      "Epoch 1122/5000\n",
      "10780/10780 [==============================] - 0s 30us/sample - loss: 7.7638 - accuracy: 0.5012 - val_loss: 7.7675 - val_accuracy: 0.5012\n",
      "Epoch 1123/5000\n",
      "10780/10780 [==============================] - 0s 44us/sample - loss: 7.7659 - accuracy: 0.5012 - val_loss: 7.7670 - val_accuracy: 0.5012\n",
      "Epoch 1124/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7636 - accuracy: 0.5012 - val_loss: 7.7624 - val_accuracy: 0.5012\n",
      "Epoch 1125/5000\n",
      "10780/10780 [==============================] - 0s 31us/sample - loss: 7.7623 - accuracy: 0.5012 - val_loss: 7.7660 - val_accuracy: 0.5012\n",
      "Epoch 1126/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7666 - accuracy: 0.5012 - val_loss: 7.7659 - val_accuracy: 0.5011\n",
      "Epoch 1127/5000\n",
      "10780/10780 [==============================] - 1s 47us/sample - loss: 7.7673 - accuracy: 0.5245 - val_loss: 7.7702 - val_accuracy: 0.5011\n",
      "Epoch 1128/5000\n",
      "10780/10780 [==============================] - 0s 45us/sample - loss: 7.7666 - accuracy: 0.5012 - val_loss: 7.7621 - val_accuracy: 0.5012\n",
      "Epoch 1129/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7631 - accuracy: 0.5012 - val_loss: 7.7611 - val_accuracy: 0.5011\n",
      "Epoch 1130/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7621 - accuracy: 0.5475 - val_loss: 7.7625 - val_accuracy: 0.5012\n",
      "Epoch 1131/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7625 - accuracy: 0.5012 - val_loss: 7.7642 - val_accuracy: 0.5011\n",
      "Epoch 1132/5000\n",
      "10780/10780 [==============================] - 0s 29us/sample - loss: 7.7644 - accuracy: 0.5012 - val_loss: 7.7623 - val_accuracy: 0.5012\n",
      "Epoch 1133/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7674 - accuracy: 0.5011 - val_loss: 7.7687 - val_accuracy: 0.5013\n",
      "Epoch 1134/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7649 - accuracy: 0.5012 - val_loss: 7.7616 - val_accuracy: 0.5012\n",
      "Epoch 1135/5000\n",
      "10780/10780 [==============================] - 0s 43us/sample - loss: 7.7639 - accuracy: 0.5012 - val_loss: 7.7636 - val_accuracy: 0.5012\n",
      "Epoch 1136/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7629 - accuracy: 0.5012 - val_loss: 7.7640 - val_accuracy: 0.5012\n",
      "Epoch 1137/5000\n",
      "10780/10780 [==============================] - 0s 43us/sample - loss: 7.7627 - accuracy: 0.5012 - val_loss: 7.7619 - val_accuracy: 0.5012\n",
      "Epoch 1138/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7620 - accuracy: 0.5012 - val_loss: 7.7634 - val_accuracy: 0.5012\n",
      "Epoch 1139/5000\n",
      "10780/10780 [==============================] - 0s 31us/sample - loss: 7.7625 - accuracy: 0.5012 - val_loss: 7.7616 - val_accuracy: 0.5012\n",
      "Epoch 1140/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7622 - accuracy: 0.5012 - val_loss: 7.7630 - val_accuracy: 0.5011\n",
      "Epoch 1141/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7628 - accuracy: 0.5012 - val_loss: 7.7628 - val_accuracy: 0.5012\n",
      "Epoch 1142/5000\n",
      "10780/10780 [==============================] - 0s 31us/sample - loss: 7.7621 - accuracy: 0.5012 - val_loss: 7.7612 - val_accuracy: 0.5012\n",
      "Epoch 1143/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7633 - accuracy: 0.5012 - val_loss: 7.7649 - val_accuracy: 0.5012\n",
      "Epoch 1144/5000\n",
      "10780/10780 [==============================] - 0s 29us/sample - loss: 7.7659 - accuracy: 0.5012 - val_loss: 7.7645 - val_accuracy: 0.5013\n",
      "Epoch 1145/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7625 - accuracy: 0.5012 - val_loss: 7.7633 - val_accuracy: 0.5012\n",
      "Epoch 1146/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7660 - accuracy: 0.5012 - val_loss: 7.7662 - val_accuracy: 0.5013\n",
      "Epoch 1147/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7622 - accuracy: 0.5012 - val_loss: 7.7668 - val_accuracy: 0.5012\n",
      "Epoch 1148/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7653 - accuracy: 0.5012 - val_loss: 7.7710 - val_accuracy: 0.5010\n",
      "Epoch 1149/5000\n",
      "10780/10780 [==============================] - 0s 46us/sample - loss: 7.7649 - accuracy: 0.5012 - val_loss: 7.7628 - val_accuracy: 0.5011\n",
      "Epoch 1150/5000\n",
      "10780/10780 [==============================] - 0s 31us/sample - loss: 7.7626 - accuracy: 0.5012 - val_loss: 7.7609 - val_accuracy: 0.5012\n",
      "Epoch 1151/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7620 - accuracy: 0.5707 - val_loss: 7.7615 - val_accuracy: 0.5012\n",
      "Epoch 1152/5000\n",
      "10780/10780 [==============================] - 0s 29us/sample - loss: 7.7626 - accuracy: 0.6164 - val_loss: 7.7632 - val_accuracy: 0.5011\n",
      "Epoch 1153/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7634 - accuracy: 0.5240 - val_loss: 7.7627 - val_accuracy: 0.5012\n",
      "Epoch 1154/5000\n",
      "10780/10780 [==============================] - 0s 43us/sample - loss: 7.7625 - accuracy: 0.5706 - val_loss: 7.7619 - val_accuracy: 0.5012\n",
      "Epoch 1155/5000\n",
      "10780/10780 [==============================] - 0s 32us/sample - loss: 7.7625 - accuracy: 0.5012 - val_loss: 7.7633 - val_accuracy: 0.5012\n",
      "Epoch 1156/5000\n",
      "10780/10780 [==============================] - 0s 31us/sample - loss: 7.7620 - accuracy: 0.5012 - val_loss: 7.7626 - val_accuracy: 0.5012\n",
      "Epoch 1157/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7623 - accuracy: 0.5012 - val_loss: 7.7644 - val_accuracy: 0.5011\n",
      "Epoch 1158/5000\n",
      "10780/10780 [==============================] - 0s 32us/sample - loss: 7.7622 - accuracy: 0.5012 - val_loss: 7.7620 - val_accuracy: 0.5012\n",
      "Epoch 1159/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7660 - accuracy: 0.5474 - val_loss: 7.7864 - val_accuracy: 0.5010\n",
      "Epoch 1160/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7703 - accuracy: 0.5012 - val_loss: 7.7644 - val_accuracy: 0.5012\n",
      "Epoch 1161/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7647 - accuracy: 0.5012 - val_loss: 7.7682 - val_accuracy: 0.5011\n",
      "Epoch 1162/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7653 - accuracy: 0.6400 - val_loss: 7.7683 - val_accuracy: 0.5012\n",
      "Epoch 1163/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7647 - accuracy: 0.5472 - val_loss: 7.7692 - val_accuracy: 0.5011\n",
      "Epoch 1164/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7633 - accuracy: 0.5012 - val_loss: 7.7626 - val_accuracy: 0.5012\n",
      "Epoch 1165/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7622 - accuracy: 0.5475 - val_loss: 7.7614 - val_accuracy: 0.5012\n",
      "Epoch 1166/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7614 - accuracy: 0.5012 - val_loss: 7.7634 - val_accuracy: 0.5012\n",
      "Epoch 1167/5000\n",
      "10780/10780 [==============================] - 0s 27us/sample - loss: 7.7622 - accuracy: 0.5139 - val_loss: 7.7619 - val_accuracy: 0.5012\n",
      "Epoch 1168/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10780/10780 [==============================] - 0s 32us/sample - loss: 7.7620 - accuracy: 0.5012 - val_loss: 7.7615 - val_accuracy: 0.5011\n",
      "Epoch 1169/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7620 - accuracy: 0.5012 - val_loss: 7.7631 - val_accuracy: 0.5012\n",
      "Epoch 1170/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7625 - accuracy: 0.5012 - val_loss: 7.7625 - val_accuracy: 0.5012\n",
      "Epoch 1171/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7631 - accuracy: 0.5012 - val_loss: 7.7638 - val_accuracy: 0.5012\n",
      "Epoch 1172/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7629 - accuracy: 0.5012 - val_loss: 7.7634 - val_accuracy: 0.5012\n",
      "Epoch 1173/5000\n",
      "10780/10780 [==============================] - 0s 30us/sample - loss: 7.7630 - accuracy: 0.5373 - val_loss: 7.7646 - val_accuracy: 1.0000\n",
      "Epoch 1174/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7625 - accuracy: 0.5241 - val_loss: 7.7648 - val_accuracy: 0.5012\n",
      "Epoch 1175/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7641 - accuracy: 0.5012 - val_loss: 7.7645 - val_accuracy: 0.5012\n",
      "Epoch 1176/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7627 - accuracy: 0.5012 - val_loss: 7.7630 - val_accuracy: 0.5012\n",
      "Epoch 1177/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7631 - accuracy: 0.5012 - val_loss: 7.7628 - val_accuracy: 0.5012\n",
      "Epoch 1178/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7622 - accuracy: 0.5012 - val_loss: 7.7610 - val_accuracy: 0.5012\n",
      "Epoch 1179/5000\n",
      "10780/10780 [==============================] - 0s 31us/sample - loss: 7.7618 - accuracy: 0.5012 - val_loss: 7.7621 - val_accuracy: 0.5011\n",
      "Epoch 1180/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7624 - accuracy: 0.5012 - val_loss: 7.7636 - val_accuracy: 0.5012\n",
      "Epoch 1181/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7631 - accuracy: 0.5012 - val_loss: 7.7672 - val_accuracy: 0.5012\n",
      "Epoch 1182/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7661 - accuracy: 0.5012 - val_loss: 7.7630 - val_accuracy: 0.5012\n",
      "Epoch 1183/5000\n",
      "10780/10780 [==============================] - 0s 45us/sample - loss: 7.7655 - accuracy: 0.5012 - val_loss: 7.7673 - val_accuracy: 0.5011\n",
      "Epoch 1184/5000\n",
      "10780/10780 [==============================] - 0s 44us/sample - loss: 7.7638 - accuracy: 0.5012 - val_loss: 7.7618 - val_accuracy: 0.5011\n",
      "Epoch 1185/5000\n",
      "10780/10780 [==============================] - 0s 44us/sample - loss: 7.7621 - accuracy: 0.5012 - val_loss: 7.7617 - val_accuracy: 0.5011\n",
      "Epoch 1186/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7630 - accuracy: 0.5012 - val_loss: 7.7632 - val_accuracy: 0.5012\n",
      "Epoch 1187/5000\n",
      "10780/10780 [==============================] - 0s 46us/sample - loss: 7.7627 - accuracy: 0.5012 - val_loss: 7.7626 - val_accuracy: 0.5012\n",
      "Epoch 1188/5000\n",
      "10780/10780 [==============================] - 0s 45us/sample - loss: 7.7623 - accuracy: 0.5012 - val_loss: 7.7625 - val_accuracy: 0.5012\n",
      "Epoch 1189/5000\n",
      "10780/10780 [==============================] - 0s 30us/sample - loss: 7.7646 - accuracy: 0.5012 - val_loss: 7.7639 - val_accuracy: 0.5012\n",
      "Epoch 1190/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7642 - accuracy: 0.5012 - val_loss: 7.7621 - val_accuracy: 0.5012\n",
      "Epoch 1191/5000\n",
      "10780/10780 [==============================] - 0s 45us/sample - loss: 7.7624 - accuracy: 0.5245 - val_loss: 7.7618 - val_accuracy: 0.5012\n",
      "Epoch 1192/5000\n",
      "10780/10780 [==============================] - 1s 47us/sample - loss: 7.7620 - accuracy: 0.5012 - val_loss: 7.7631 - val_accuracy: 0.5012\n",
      "Epoch 1193/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7627 - accuracy: 0.5012 - val_loss: 7.7716 - val_accuracy: 0.5013\n",
      "Epoch 1194/5000\n",
      "10780/10780 [==============================] - 1s 50us/sample - loss: 7.7649 - accuracy: 0.5012 - val_loss: 7.7617 - val_accuracy: 0.5012\n",
      "Epoch 1195/5000\n",
      "10780/10780 [==============================] - 1s 51us/sample - loss: 7.7622 - accuracy: 0.5240 - val_loss: 7.7610 - val_accuracy: 0.5012\n",
      "Epoch 1196/5000\n",
      "10780/10780 [==============================] - 1s 50us/sample - loss: 7.7629 - accuracy: 0.5012 - val_loss: 7.7660 - val_accuracy: 0.5012\n",
      "Epoch 1197/5000\n",
      "10780/10780 [==============================] - 1s 52us/sample - loss: 7.7622 - accuracy: 0.6064 - val_loss: 7.7608 - val_accuracy: 1.0000\n",
      "Epoch 1198/5000\n",
      "10780/10780 [==============================] - 1s 48us/sample - loss: 7.7611 - accuracy: 0.5243 - val_loss: 7.7611 - val_accuracy: 0.5012\n",
      "Epoch 1199/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7662 - accuracy: 0.5012 - val_loss: 7.7691 - val_accuracy: 0.5011\n",
      "Epoch 1200/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7667 - accuracy: 0.5012 - val_loss: 7.7702 - val_accuracy: 0.5011\n",
      "Epoch 1201/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7650 - accuracy: 0.5012 - val_loss: 7.7618 - val_accuracy: 0.5012\n",
      "Epoch 1202/5000\n",
      "10780/10780 [==============================] - 0s 29us/sample - loss: 7.7625 - accuracy: 0.5012 - val_loss: 7.7622 - val_accuracy: 0.5013\n",
      "Epoch 1203/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7631 - accuracy: 0.5012 - val_loss: 7.7673 - val_accuracy: 0.5011\n",
      "Epoch 1204/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7633 - accuracy: 0.5945 - val_loss: 7.7608 - val_accuracy: 0.5012\n",
      "Epoch 1205/5000\n",
      "10780/10780 [==============================] - 1s 47us/sample - loss: 7.7665 - accuracy: 0.5012 - val_loss: 7.7654 - val_accuracy: 0.5010\n",
      "Epoch 1206/5000\n",
      "10780/10780 [==============================] - 1s 47us/sample - loss: 7.7663 - accuracy: 0.5012 - val_loss: 7.7632 - val_accuracy: 0.5012\n",
      "Epoch 1207/5000\n",
      "10780/10780 [==============================] - 1s 48us/sample - loss: 7.7646 - accuracy: 0.5012 - val_loss: 7.7611 - val_accuracy: 0.5012\n",
      "Epoch 1208/5000\n",
      "10780/10780 [==============================] - 1s 47us/sample - loss: 7.7616 - accuracy: 0.5246 - val_loss: 7.7625 - val_accuracy: 0.5011\n",
      "Epoch 1209/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7643 - accuracy: 0.5012 - val_loss: 7.7619 - val_accuracy: 0.5012\n",
      "Epoch 1210/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7635 - accuracy: 0.5012 - val_loss: 7.7655 - val_accuracy: 0.5011\n",
      "Epoch 1211/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7651 - accuracy: 0.5012 - val_loss: 7.7640 - val_accuracy: 0.5012\n",
      "Epoch 1212/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7634 - accuracy: 0.5012 - val_loss: 7.7619 - val_accuracy: 0.5012\n",
      "Epoch 1213/5000\n",
      "10780/10780 [==============================] - 0s 31us/sample - loss: 7.7622 - accuracy: 0.5012 - val_loss: 7.7605 - val_accuracy: 0.5012\n",
      "Epoch 1214/5000\n",
      "10780/10780 [==============================] - 0s 30us/sample - loss: 7.7626 - accuracy: 0.5012 - val_loss: 7.7685 - val_accuracy: 0.5012\n",
      "Epoch 1215/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7665 - accuracy: 0.5012 - val_loss: 7.7657 - val_accuracy: 0.5011\n",
      "Epoch 1216/5000\n",
      "10780/10780 [==============================] - 0s 43us/sample - loss: 7.7653 - accuracy: 0.5012 - val_loss: 7.7639 - val_accuracy: 0.5012\n",
      "Epoch 1217/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7654 - accuracy: 0.5934 - val_loss: 7.7621 - val_accuracy: 0.5011\n",
      "Epoch 1218/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7635 - accuracy: 0.5012 - val_loss: 7.7637 - val_accuracy: 0.5012\n",
      "Epoch 1219/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7618 - accuracy: 0.5012 - val_loss: 7.7624 - val_accuracy: 0.5012\n",
      "Epoch 1220/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7627 - accuracy: 0.5243 - val_loss: 7.7621 - val_accuracy: 0.5012\n",
      "Epoch 1221/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7630 - accuracy: 0.5012 - val_loss: 7.7647 - val_accuracy: 0.5011\n",
      "Epoch 1222/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7634 - accuracy: 0.5477 - val_loss: 7.7613 - val_accuracy: 0.5012\n",
      "Epoch 1223/5000\n",
      "10780/10780 [==============================] - 0s 32us/sample - loss: 7.7619 - accuracy: 0.5609 - val_loss: 7.7629 - val_accuracy: 1.0000\n",
      "Epoch 1224/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7622 - accuracy: 0.5703 - val_loss: 7.7620 - val_accuracy: 0.5011\n",
      "Epoch 1225/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7618 - accuracy: 0.5012 - val_loss: 7.7649 - val_accuracy: 0.5012\n",
      "Epoch 1226/5000\n",
      "10780/10780 [==============================] - 0s 32us/sample - loss: 7.7628 - accuracy: 0.5012 - val_loss: 7.7627 - val_accuracy: 0.5012\n",
      "Epoch 1227/5000\n",
      "10780/10780 [==============================] - 0s 32us/sample - loss: 7.7628 - accuracy: 0.5012 - val_loss: 7.7608 - val_accuracy: 0.5012\n",
      "Epoch 1228/5000\n",
      "10780/10780 [==============================] - 0s 31us/sample - loss: 7.7623 - accuracy: 0.5012 - val_loss: 7.7654 - val_accuracy: 0.5012\n",
      "Epoch 1229/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7638 - accuracy: 0.5012 - val_loss: 7.7607 - val_accuracy: 0.5012\n",
      "Epoch 1230/5000\n",
      "10780/10780 [==============================] - 0s 39us/sample - loss: 7.7626 - accuracy: 0.5012 - val_loss: 7.7646 - val_accuracy: 0.5013\n",
      "Epoch 1231/5000\n",
      "10780/10780 [==============================] - 0s 33us/sample - loss: 7.7724 - accuracy: 0.4786 - val_loss: 7.7708 - val_accuracy: 0.5012\n",
      "Epoch 1232/5000\n",
      "10780/10780 [==============================] - 0s 35us/sample - loss: 7.7726 - accuracy: 0.5012 - val_loss: 7.7777 - val_accuracy: 0.5012\n",
      "Epoch 1233/5000\n",
      "10780/10780 [==============================] - 1s 49us/sample - loss: 7.7689 - accuracy: 0.5012 - val_loss: 7.7647 - val_accuracy: 0.5011\n",
      "Epoch 1234/5000\n",
      "10780/10780 [==============================] - 1s 49us/sample - loss: 7.7645 - accuracy: 0.5012 - val_loss: 7.7631 - val_accuracy: 0.5012\n",
      "Epoch 1235/5000\n",
      "10780/10780 [==============================] - 1s 49us/sample - loss: 7.7665 - accuracy: 0.5012 - val_loss: 7.7714 - val_accuracy: 0.5011\n",
      "Epoch 1236/5000\n",
      "10780/10780 [==============================] - 1s 49us/sample - loss: 7.7654 - accuracy: 0.5012 - val_loss: 7.7646 - val_accuracy: 0.5012\n",
      "Epoch 1237/5000\n",
      "10780/10780 [==============================] - 1s 48us/sample - loss: 7.7642 - accuracy: 0.5012 - val_loss: 7.7621 - val_accuracy: 1.0000\n",
      "Epoch 1238/5000\n",
      "10780/10780 [==============================] - 1s 49us/sample - loss: 7.7622 - accuracy: 0.6175 - val_loss: 7.7618 - val_accuracy: 0.5013\n",
      "Epoch 1239/5000\n",
      "10780/10780 [==============================] - 1s 49us/sample - loss: 7.7618 - accuracy: 0.5934 - val_loss: 7.7627 - val_accuracy: 0.5012\n",
      "Epoch 1240/5000\n",
      "10780/10780 [==============================] - 1s 48us/sample - loss: 7.7640 - accuracy: 0.5012 - val_loss: 7.7618 - val_accuracy: 0.5012\n",
      "Epoch 1241/5000\n",
      "10780/10780 [==============================] - 1s 49us/sample - loss: 7.7621 - accuracy: 0.5012 - val_loss: 7.7622 - val_accuracy: 0.5012\n",
      "Epoch 1242/5000\n",
      "10780/10780 [==============================] - 1s 49us/sample - loss: 7.7619 - accuracy: 0.5012 - val_loss: 7.7615 - val_accuracy: 0.5012\n",
      "Epoch 1243/5000\n",
      "10780/10780 [==============================] - 0s 43us/sample - loss: 7.7637 - accuracy: 0.5012 - val_loss: 7.7632 - val_accuracy: 0.5012\n",
      "Epoch 1244/5000\n",
      "10780/10780 [==============================] - 0s 30us/sample - loss: 7.7644 - accuracy: 0.5469 - val_loss: 7.7635 - val_accuracy: 0.5012\n",
      "Epoch 1245/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7630 - accuracy: 0.5012 - val_loss: 7.7614 - val_accuracy: 0.5012\n",
      "Epoch 1246/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7619 - accuracy: 0.5012 - val_loss: 7.7607 - val_accuracy: 0.5011\n",
      "Epoch 1247/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7641 - accuracy: 0.6175 - val_loss: 7.7645 - val_accuracy: 0.5012\n",
      "Epoch 1248/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7627 - accuracy: 0.5012 - val_loss: 7.7664 - val_accuracy: 0.5012\n",
      "Epoch 1249/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7631 - accuracy: 0.5012 - val_loss: 7.7620 - val_accuracy: 0.5012\n",
      "Epoch 1250/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7621 - accuracy: 0.5012 - val_loss: 7.7625 - val_accuracy: 0.5011\n",
      "Epoch 1251/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7620 - accuracy: 0.5012 - val_loss: 7.7604 - val_accuracy: 0.5012\n",
      "Epoch 1252/5000\n",
      "10780/10780 [==============================] - 1s 50us/sample - loss: 7.7629 - accuracy: 0.5012 - val_loss: 7.7620 - val_accuracy: 0.5013\n",
      "Epoch 1253/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7617 - accuracy: 0.5471 - val_loss: 7.7600 - val_accuracy: 0.5012\n",
      "Epoch 1254/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7643 - accuracy: 0.5012 - val_loss: 7.7623 - val_accuracy: 0.5012\n",
      "Epoch 1255/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7625 - accuracy: 0.5012 - val_loss: 7.7632 - val_accuracy: 0.5012\n",
      "Epoch 1256/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7634 - accuracy: 0.5012 - val_loss: 7.7618 - val_accuracy: 0.5012\n",
      "Epoch 1257/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7624 - accuracy: 0.5711 - val_loss: 7.7620 - val_accuracy: 0.5012\n",
      "Epoch 1258/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7621 - accuracy: 0.5243 - val_loss: 7.7631 - val_accuracy: 1.0000\n",
      "Epoch 1259/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7625 - accuracy: 0.5931 - val_loss: 7.7607 - val_accuracy: 0.5012\n",
      "Epoch 1260/5000\n",
      "10780/10780 [==============================] - 0s 38us/sample - loss: 7.7624 - accuracy: 0.5012 - val_loss: 7.7651 - val_accuracy: 0.5012\n",
      "Epoch 1261/5000\n",
      "10780/10780 [==============================] - 0s 34us/sample - loss: 7.7665 - accuracy: 0.5012 - val_loss: 7.7681 - val_accuracy: 0.5012\n",
      "Epoch 1262/5000\n",
      "10780/10780 [==============================] - 0s 36us/sample - loss: 7.7649 - accuracy: 0.5012 - val_loss: 7.7616 - val_accuracy: 0.5012\n",
      "Epoch 1263/5000\n",
      "10780/10780 [==============================] - 0s 37us/sample - loss: 7.7624 - accuracy: 0.5012 - val_loss: 7.7653 - val_accuracy: 0.5012\n",
      "Epoch 1264/5000\n",
      "10780/10780 [==============================] - 0s 31us/sample - loss: 7.7659 - accuracy: 0.5012 - val_loss: 7.7624 - val_accuracy: 0.5011\n",
      "Epoch 1265/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7623 - accuracy: 0.5012 - val_loss: 7.7610 - val_accuracy: 0.5012\n",
      "Epoch 1266/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7614 - accuracy: 0.5241 - val_loss: 7.7629 - val_accuracy: 0.5012\n",
      "Epoch 1267/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7642 - accuracy: 0.5012 - val_loss: 7.7635 - val_accuracy: 0.5011\n",
      "Epoch 1268/5000\n",
      "10780/10780 [==============================] - 0s 43us/sample - loss: 7.7653 - accuracy: 0.5012 - val_loss: 7.7642 - val_accuracy: 0.5012\n",
      "Epoch 1269/5000\n",
      "10780/10780 [==============================] - 1s 49us/sample - loss: 7.7648 - accuracy: 0.5012 - val_loss: 7.7621 - val_accuracy: 0.5012\n",
      "Epoch 1270/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7622 - accuracy: 0.5940 - val_loss: 7.7620 - val_accuracy: 0.5011\n",
      "Epoch 1271/5000\n",
      "10780/10780 [==============================] - 0s 43us/sample - loss: 7.7628 - accuracy: 0.5012 - val_loss: 7.7616 - val_accuracy: 0.5012\n",
      "Epoch 1272/5000\n",
      "10780/10780 [==============================] - 0s 45us/sample - loss: 7.7619 - accuracy: 0.5012 - val_loss: 7.7661 - val_accuracy: 0.5012\n",
      "Epoch 1273/5000\n",
      "10780/10780 [==============================] - 0s 40us/sample - loss: 7.7665 - accuracy: 0.5012 - val_loss: 7.7660 - val_accuracy: 0.5012\n",
      "Epoch 1274/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7648 - accuracy: 0.5012 - val_loss: 7.7614 - val_accuracy: 0.5012\n",
      "Epoch 1275/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7624 - accuracy: 0.5012 - val_loss: 7.7625 - val_accuracy: 0.5012\n",
      "Epoch 1276/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7635 - accuracy: 0.5012 - val_loss: 7.7632 - val_accuracy: 0.5012\n",
      "Epoch 1277/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7627 - accuracy: 0.5012 - val_loss: 7.7655 - val_accuracy: 0.5012\n",
      "Epoch 1278/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7686 - accuracy: 0.5012 - val_loss: 7.7658 - val_accuracy: 0.5012\n",
      "Epoch 1279/5000\n",
      "10780/10780 [==============================] - 0s 41us/sample - loss: 7.7649 - accuracy: 0.5012 - val_loss: 7.7629 - val_accuracy: 0.5012\n",
      "Epoch 1280/5000\n",
      "10780/10780 [==============================] - 0s 32us/sample - loss: 7.7628 - accuracy: 0.5012 - val_loss: 7.7624 - val_accuracy: 0.5012\n",
      "Epoch 1281/5000\n",
      "10780/10780 [==============================] - 0s 42us/sample - loss: 7.7619 - accuracy: 0.5012 - val_loss: 7.7610 - val_accuracy: 0.5012\n",
      "Epoch 1282/5000\n",
      " 8500/10780 [======================>.......] - ETA: 0s - loss: 7.7607 - accuracy: 0.5013"
     ]
    }
   ],
   "source": [
    "epochs = 5000\n",
    "batch_size = 500\n",
    "\n",
    "history = autoencoder.fit(X_exemplo,X_exemplo, epochs=epochs, batch_size=batch_size,shuffle=True,validation_data=(X_exemplo,X_exemplo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Passo 2: gerar uma representação comum entre ambas as modalidades\n",
    "* Treinar com a mesma rede para visual e auditivo\n",
    "* Objetivo é verificar se gera uma melhor representação comum entre as modalidades\n",
    "* Comparar o desempenho com a rede treinada em apenas uma modalidade\n",
    "* Treinar redes separadas para visual e auditivo, compartilhando a parte da codificação\n",
    "* Treinamento com exemplos de ambas as modalidades\n",
    "* Pode ser mais interessante, pois enfatiza uma codificação comum, mas permite diferenciações na decodificação\n",
    "\n",
    "### Passo 3: obter representações comuns entre sujeitos\n",
    "* Treinar a mesma rede para todos os participantes \n",
    "* Objetivo é gerar as codificações a partir de grandes quantidades de dados\n",
    "* Abordagem 1: Fazer para a rede uma rede codificação/decodificação comum a todos\n",
    "    * Depois pode ser afinada para cada participante individualmente\n",
    "* Abordagem 2: Usar apenas a parte de codificação em comum\n",
    "    * Enfatiza uma codificação comum, mas permite diferenciações na decodificação\n",
    "* Neste caso o classificador poderia ser comum também?\n",
    "\n",
    "Passo 4: capturar informação temporal (opcional)\n",
    "Repetir os passos anteriores, mas usando 5 valores para cada eletrodo (1 a cada 25 ms)\n",
    "Objetivo é verificar se mais detalhes temporais melhoram a representação do tempo\n",
    "Inicialmente utilizar uma arquitetura fully connected \n",
    "320(E) - 160 - 80 - 40 - 80 - 160 - 320(S)\n",
    "Outra possibilidade é colocar alguma estrutura\n",
    "Transformação é inicialmente realizada sobre a série temporal de cada eletrodo\n",
    "Poderia também juntar sinais de eletrodos vizinhos\n",
    "Isso permitiria diminuir o número de conexões"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AcrossModality",
   "language": "python",
   "name": "eeg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
