{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "baseline_methods_grilo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNWaPmdM/PpEwOQK8VRM2BW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bruAristimunha/Across-Modalities/blob/master/baseline_methods_grilo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mne pyriemann monai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxhcXMsscf6O",
        "outputId": "b01ffbc8-766f-463f-c4fa-cc38a8204375"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: mne in /usr/local/lib/python3.7/dist-packages (1.1.1)\n",
            "Requirement already satisfied: pyriemann in /usr/local/lib/python3.7/dist-packages (0.3)\n",
            "Requirement already satisfied: monai in /usr/local/lib/python3.7/dist-packages (0.9.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from mne) (2.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from mne) (4.64.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from mne) (1.7.3)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mne) (21.3)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from mne) (1.21.6)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.7/dist-packages (from mne) (1.6.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mne) (3.2.2)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.5->mne) (1.4.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.5->mne) (2.23.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->mne) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (1.24.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyriemann) (1.1.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyriemann) (1.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pyriemann) (1.3.5)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.7/dist-packages (from monai) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7->monai) (4.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->mne) (2.0.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mne) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mne) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mne) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->mne) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pyriemann) (2022.2.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyriemann) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import mne\n",
        "from tqdm import tqdm\n",
        "\n",
        "from numpy import array, float32, float64, savez\n",
        "\n",
        "from mne.decoding import CSP as mneCSP, Vectorizer\n",
        "\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.linear_model import LogisticRegression, RidgeClassifierCV\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from pyriemann.classification import MDM\n",
        "from pyriemann.estimation import Covariances, ERPCovariances, XdawnCovariances\n",
        "from pyriemann.spatialfilters import CSP, Xdawn\n",
        "from pyriemann.tangentspace import TangentSpace\n",
        "\n",
        "from monai.utils import set_determinism\n",
        "\n",
        "mne.set_log_level(\"CRITICAL\")"
      ],
      "metadata": {
        "id": "ykhdMCw2c4_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    average_precision_score,\n",
        "    balanced_accuracy_score,\n",
        "    cohen_kappa_score,\n",
        "    confusion_matrix,\n",
        "    f1_score,\n",
        "    make_scorer,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    roc_auc_score,\n",
        ")\n",
        "\n",
        "\n",
        "def true_positive(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Returning true positive.\n",
        "    Parameters\n",
        "    ----------\n",
        "    y_true : array-like of shape (n_samples,)\n",
        "        Ground truth (correct) target values.\n",
        "\n",
        "    y_pred : array-like of shape (n_samples,)\n",
        "        Estimated targets as returned by a classifier.\n",
        "    \"\"\"\n",
        "    return confusion_matrix(y_true, y_pred)[0, 0]\n",
        "\n",
        "\n",
        "def true_negative(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Returning true negative.\n",
        "    Parameters\n",
        "    ----------\n",
        "    y_true : array-like of shape (n_samples,)\n",
        "        Ground truth (correct) target values.\n",
        "\n",
        "    y_pred : array-like of shape (n_samples,)\n",
        "        Estimated targets as returned by a classifier.\n",
        "    \"\"\"\n",
        "    return confusion_matrix(y_true, y_pred)[1, 1]\n",
        "\n",
        "\n",
        "def false_positive(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Returning false positive.\n",
        "    Parameters\n",
        "    ----------\n",
        "    y_true : array-like of shape (n_samples,)\n",
        "        Ground truth (correct) target values.\n",
        "\n",
        "    y_pred : array-like of shape (n_samples,)\n",
        "        Estimated targets as returned by a classifier.\n",
        "    \"\"\"\n",
        "    return confusion_matrix(y_true, y_pred)[1, 0]\n",
        "\n",
        "\n",
        "def false_negative(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Returning false negative.\n",
        "    Parameters\n",
        "    ----------\n",
        "    y_true : array-like of shape (n_samples,)\n",
        "        Ground truth (correct) target values.\n",
        "\n",
        "    y_pred : array-like of shape (n_samples,)\n",
        "        Estimated targets as returned by a classifier.\n",
        "    \"\"\"\n",
        "    return confusion_matrix(y_true, y_pred)[0, 1]\n",
        "\n",
        "\n",
        "def tp_n(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    True Positive Normalized\n",
        "    Parameters\n",
        "    ----------\n",
        "    y_true : array-like of shape (n_samples,)\n",
        "        Ground truth (correct) target values.\n",
        "\n",
        "    y_pred : array-like of shape (n_samples,)\n",
        "        Estimated targets as returned by a classifier.\n",
        "    \"\"\"\n",
        "    conf_ma = confusion_matrix(y_true, y_pred)\n",
        "    conf_ma = conf_ma.astype(\"float\") / conf_ma.sum(axis=1)[:, np.newaxis]\n",
        "    return conf_ma[0, 0]\n",
        "\n",
        "\n",
        "def tn_n(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    True Negative Normalized\n",
        "    Parameters\n",
        "    ----------\n",
        "    y_true : array-like of shape (n_samples,)\n",
        "        Ground truth (correct) target values.\n",
        "\n",
        "    y_pred : array-like of shape (n_samples,)\n",
        "        Estimated targets as returned by a classifier.\n",
        "    \"\"\"\n",
        "    conf_ma = confusion_matrix(y_true, y_pred)\n",
        "    conf_ma = conf_ma.astype(\"float\") / conf_ma.sum(axis=1)[:, np.newaxis]\n",
        "    return conf_ma[1, 1]\n",
        "\n",
        "\n",
        "def fp_n(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    False Positive Normalized\n",
        "    Parameters\n",
        "    ----------\n",
        "    y_true : array-like of shape (n_samples,)\n",
        "        Ground truth (correct) target values.\n",
        "\n",
        "    y_pred : array-like of shape (n_samples,)\n",
        "        Estimated targets as returned by a classifier.\n",
        "    \"\"\"\n",
        "    conf_ma = confusion_matrix(y_true, y_pred)\n",
        "    conf_ma = conf_ma.astype(\"float\") / conf_ma.sum(axis=1)[:, np.newaxis]\n",
        "    return conf_ma[1, 0]\n",
        "\n",
        "\n",
        "def fn_n(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    False Negative Normalized\n",
        "    Parameters\n",
        "    ----------\n",
        "    y_true : array-like of shape (n_samples,)\n",
        "        Ground truth (correct) target values.\n",
        "\n",
        "    y_pred : array-like of shape (n_samples,)\n",
        "        Estimated targets as returned by a classifier.\n",
        "    \"\"\"\n",
        "    conf_ma = confusion_matrix(y_true, y_pred)\n",
        "    conf_ma = conf_ma.astype(\"float\") / conf_ma.sum(axis=1)[:, np.newaxis]\n",
        "    return conf_ma[0, 1]\n",
        "\n",
        "\n",
        "scoring = {\n",
        "    \"acc\": make_scorer(accuracy_score),\n",
        "    \"kappa\": make_scorer(cohen_kappa_score),\n",
        "    \"average_precision\": make_scorer(average_precision_score),\n",
        "    \"balanced_accuracy\": make_scorer(balanced_accuracy_score),\n",
        "    \"roc_auc\": make_scorer(roc_auc_score),\n",
        "    \"f1\": make_scorer(f1_score),\n",
        "    \"recall_binary\": make_scorer(recall_score),\n",
        "    \"f1_weighted\": make_scorer(f1_score, average=\"weighted\"),\n",
        "    \"precision\": make_scorer(precision_score, average=\"weighted\"),\n",
        "    \"recall\": make_scorer(recall_score, average=\"weighted\"),\n",
        "    \"tp\": make_scorer(true_positive),\n",
        "    \"tn\": make_scorer(true_positive),\n",
        "    \"fp\": make_scorer(false_positive),\n",
        "    \"fn\": make_scorer(false_negative),\n",
        "    \"tp_n\": make_scorer(tp_n),\n",
        "    \"tn_n\": make_scorer(tn_n),\n",
        "    \"fp_n\": make_scorer(fp_n),\n",
        "    \"fn_n\": make_scorer(fn_n),\n",
        "}\n"
      ],
      "metadata": {
        "id": "lWAacUaJc_yp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwJnQtCtcdU7",
        "outputId": "15b7dbf1-f399-48d6-c27a-4742f92a633a"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The run_dir is runs/baseline_emotions-baseline\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing method CSP_LDA: 100%|██████████| 12/12 [02:29<00:00, 12.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Authors: Bruno Aristimunha <b.aristimunha@gmail.com>\n",
        "\n",
        "Baseline script to analyse the EEG Dataset.\n",
        "\n",
        "\"\"\"\n",
        "seed=46\n",
        "path_output=\".\"\n",
        "n_cv=5\n",
        "n_jobs=7\n",
        "experiment_name=\"baseline_emotions\"\n",
        "\n",
        "# Setting run information\n",
        "\n",
        "set_determinism(seed=seed)\n",
        "\n",
        "output_dir = Path(f\"{path_output}/runs/\")\n",
        "output_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "experiment_name = (\n",
        "    experiment_name + \"-baseline\"\n",
        ")\n",
        "\n",
        "run_dir = output_dir / (experiment_name)\n",
        "print(f\"The run_dir is {run_dir}\")\n",
        "if run_dir.exists():\n",
        "    pass\n",
        "else:\n",
        "    print(\"First time running, creating folder\")\n",
        "    run_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "###################################################################\n",
        "\n",
        "# Code to read your dataset\n",
        "# You will need to replace with part\n",
        "# Here we are creating fake EEG data.\n",
        "\n",
        "fs=250\n",
        "n_trial=1152\n",
        "n_channels=22\n",
        "\n",
        "signal_len=4 #in seconds\n",
        "n_points = fs * signal_len\n",
        "t = np.arange(n_points) / fs\n",
        "x_eeg = np.random.rand(n_trial, n_channels, n_points)\n",
        "y_label = np.random.choice([0, 1], size=(n_trial,))\n",
        "\n",
        "\n",
        "###################################################################\n",
        "\n",
        "\n",
        "# build your pipeline\n",
        "pipelines = {}\n",
        "\n",
        "pipelines[\"Dummy\"] = make_pipeline(\n",
        "    DummyClassifier(\n",
        "        strategy=\"most_frequent\", random_state=seed\n",
        "    )\n",
        ")\n",
        "\n",
        "pipelines[\"Vect_LR\"] = make_pipeline(\n",
        "    Vectorizer(), StandardScaler(), LogisticRegression()\n",
        ")\n",
        "\n",
        "pipelines[\"ERPCov_TS\"] = make_pipeline(\n",
        "    ERPCovariances(estimator=\"oas\"), TangentSpace(), LogisticRegression()\n",
        ")\n",
        "pipelines[\"ERPCov_MDM\"] = make_pipeline(\n",
        "    ERPCovariances(estimator=\"oas\"), MDM()\n",
        ")\n",
        "pipelines[\"XdawnCov_TS\"] = make_pipeline(\n",
        "    XdawnCovariances(estimator=\"oas\"), TangentSpace(), LogisticRegression()\n",
        ")\n",
        "pipelines[\"XdawnCov_MDM\"] = make_pipeline(\n",
        "    XdawnCovariances(estimator=\"oas\"), MDM()\n",
        ")\n",
        "pipelines[\"Xdawn_RegLDA\"] = make_pipeline(\n",
        "    Xdawn(2, classes=[1]),\n",
        "    Vectorizer(),\n",
        "    LDA(shrinkage=\"auto\", solver=\"eigen\"),\n",
        ")\n",
        "\n",
        "pipelines[\"TGSP_SVM\"] = make_pipeline(\n",
        "    Covariances(\"oas\"),\n",
        "    TangentSpace(metric=\"riemann\"),\n",
        "    SVC(kernel=\"linear\"),\n",
        ")\n",
        "\n",
        "pipelines[\"MDM\"] = make_pipeline(Covariances(\"oas\"), \n",
        "                                 MDM(metric=\"riemann\"))\n",
        "pipelines[\"CO_CSP_LDA\"] = make_pipeline(\n",
        "    Covariances(\"oas\"), CSP(nfilter=4), LDA()\n",
        ")\n",
        "pipelines[\"CSP_LOGISTICREG\"] = make_pipeline(\n",
        "    mneCSP(), LogisticRegression()\n",
        ")\n",
        "pipelines[\"CSP_LDA\"] = make_pipeline(mneCSP(), LDA())\n",
        "\n",
        "# cross validation\n",
        "with tqdm(pipelines) as pbar:\n",
        "  for name in pbar:\n",
        "      file_save_name = experiment_name +\"-\"+ name\n",
        "      pbar.set_description(f\"Processing method {name}\")\n",
        "\n",
        "      if name.upper() in [\"CSP_LDA\", \"CSP_LOGISTICREG\"]:\n",
        "\n",
        "          x_eeg = x_eeg.astype(float64)\n",
        "      else:\n",
        "          x_eeg = x_eeg.astype(float32)\n",
        "\n",
        "\n",
        "      metrics = cross_validate(\n",
        "          pipelines[name],\n",
        "          x_eeg,\n",
        "          y_label,\n",
        "          cv=n_cv,\n",
        "          scoring=scoring,\n",
        "          n_jobs=n_jobs,\n",
        "      )\n",
        "\n",
        "      savez(\n",
        "          run_dir / (file_save_name + \".npz\"),\n",
        "          metrics=metrics,\n",
        "          model_name=name.lower(),\n",
        "      )\n",
        "\n",
        "\n",
        "print(\"---------------------------------------\")"
      ]
    }
  ]
}